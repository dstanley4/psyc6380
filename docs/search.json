[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 6380 Psychological Applications of Multivariate Analysis",
    "section": "",
    "text": "Preface\nThis is a Quarto book designed to supplement PSYC 6380.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "1  An Emphasis on Workflow",
    "section": "",
    "text": "1.1 Required Packages\nThe data files below are used in this chapter.\nThe following CRAN packages must be installed:\nImportant Note: You should NOT use library(psych) at any point! There are major conflicts between the psych package and the tidyverse. We will access the psych package commands by preceding each command with psych:: instead of using library(psych).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>An Emphasis on Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#required-packages",
    "href": "workflow.html#required-packages",
    "title": "1  An Emphasis on Workflow",
    "section": "",
    "text": "Required Data\n\n\n\n\ndata_ex_between.csv\n\n\ndata_ex_within.csv\n\n\ndata_item_scoring.csv\n\n\n\n\n\n\n\nRequired CRAN Packages\n\n\n\n\napaTables\n\n\nHmisc\n\n\njanitor\n\n\npsych\n\n\nskimr\n\n\ntidyverse",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>An Emphasis on Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#objective",
    "href": "workflow.html#objective",
    "title": "1  An Emphasis on Workflow",
    "section": "1.2 Objective",
    "text": "1.2 Objective\nDue to a number of high profile failures to replicate study results (Nosek 2015) it has become increasingly clear that there is a general crisis of confidence in many areas of science (Baker 2016). Statistical (and other) explanations have been offered (Simmons, Nelson, and Simonsohn 2011) for why it’s hard to replicate results across different sets of data. However, scientists are also finding it challenging to recreate the numbers in their own papers using their own data. Indeed, the editor of Molecular Brain asked authors to submit the data used to create the numbers in published papers and found that the wrong data was submitted for 40 out of 41 papers (Miyakawa 2020).\nConsequently, some researchers have suggested that it is critical to distinguish between replication and reproducibility (Patil P. 2019). Replication refers to trying to obtain the same results from a different data set. Reproducibility refers to trying to obtain the same results from the same data set. Unfortunately, some authors use these two terms interchangeably and fail to make any distinction between them. I encourage you to make the distinction and the use the terms consist with use suggested by (Patil P. 2019).\nIt may seem that reproducibility should be a given - but it’s not. Correspondingly, there is a trend for journals and authors to adopt Transparency and Openness Promotion (TOP) guidelines. These guidelines involve such things as making your materials, data, code, and analysis scripts available on public repositories so anyone can check your data. A new open science journal rating system has even emerged called the TOP Factor.\nThe idea is not that open science articles are more trustworthy than other types of articles – the idea is that trust doesn’t play a role. Anyone can inspect the data using the scripts and data provided by authors. It’s really just the same as making your science available for auditing the way financial records can be audited. But just like in the world of business, some people don’t like the idea of making it possible for others to audit their work. The problems reported in Molecular Brain (doubtless common to many journals) are likely avoided with open science - because the data and scripts needed to reproduce the statistics in the articles are uploaded prior to publication.\nThe TOP open science guidelines have made an impact and some newer journals, such as Meta Psychology, have fully embraced open science. Figure 1.1 shows the header from an article in Meta Psychology that clearly delineates the open science attributes of the article that used computer simulations (instead of participant data). Take note that the header even indicates who verified that the analyses in the article were reproducible.\n\n\n\n\n\n\n\n\nFigure 1.1: Open science in an article header\n\n\n\n\n\nIn Canada, the majority of university research is funded by the Federal Government’s Tri-Agency (i.e., NSERC, SSHRC, CIHR). The agency has a new Data Management Policy in which they state that “The agencies believe that research data collected through the use of public funds should be responsibly and securely managed and be, where ethical, legal and commercial obligations allow, available for reuse by others. To this end, the agencies support the FAIR (Findable, Accessible, Interoperable, and Reusable) guiding principles for research data management and stewardship.” [emphasis added] The perspective of the funding agency on data ownership differs substantially from that of some researchers who incorrectly believe “they own their data”. In Canada at least, the government makes it clear that when tax payers fund research (through the Tri-Agency) the research data is public property. Additionally the Tri-Agency Data Management Statement of Principles clearly indicates the responsibilities of funded researchers:\n“Responsibilities of researchers include:\n\nincorporating data management best practices into their research;\ndeveloping data management plans to guide the responsible collection, formatting, preservation and sharing of their data throughout the entire lifecycle of a research project and beyond;\nfollowing the requirements of applicable institutional and/or funding agency policies and professional or disciplinary standards;\nacknowledging and citing datasets that contribute to their research; and\nstaying abreast of standards and expectations of their disciplinary community.”\n\nAs a result of this perspective on data, it’s important that you think about structuring your data for reuse by yourself and others before you collect it. Toward this end, properly documenting your data file and analysis scripts is critical.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>An Emphasis on Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#begin-with-the-end-in-mind",
    "href": "workflow.html#begin-with-the-end-in-mind",
    "title": "1  An Emphasis on Workflow",
    "section": "1.3 Begin with the end in mind",
    "text": "1.3 Begin with the end in mind\nIn this chapter we will walk you through the steps from data collection, data entry, loading raw data, and the creation of data you will analyze (analytic data) via pre-processing scripts. These steps are outlined in Figure 1.2. This figure makes a clear distinction between raw data and analytic data. Raw data refers to the data as you entered it into a spreadsheet or received it from survey software. Analytic data is the data that has been structured and processed so that it is ready for analysis. This pre-processing could include such things as identifying categorical variables to the computer, averaging multiple items into a scale score, and other tasks.\nIt’s critical that you don’t think of the analysis of your data as being completely removed from the data collection and data entry choices you make. Poor choices at the data collection and data entry stage can make your life substantially more complicated when it comes time to write the pre-processing script that will convert your raw data to analytic data. The mantra of this chapter is begin with the end in mind.\n\n\n\n\n\n\n\n\nFigure 1.2: Data science pipeline by Roger Peng\n\n\n\n\n\nIt’s difficult to begin with the end in mind when you haven’t read later chapters. So, here we will be providing you with some general thoughts around different approaches to structuring data files and the naming conventions you can use when creating those data files.\nIndeed, in this chapter we strongly advocate that you use a naming convention for file, variable, and column names. This convention will save you hours of hassles and permit easy application of certain tidyverse commands. However, we must stress that although the naming convention we advocate is based on the tidyverse style guide, it is not “right” or “correct” - there are other naming conventions you can use. Any naming convention is better than no naming convention. The naming convention we advocate here will solve many problems. We encourage to use this system for weeks or months over many projects - until you see the benefits of this system, and correspondingly its shortcomings. After you are well versed in the strengths/weaknesses of the naming conventions used here you may choose to create your own naming convention system.\n\n1.3.1 Structuring data: Obtaining tidy data\nWhen conducting analyses in R it is typically necessary to have data in a format called tidy data (Wickham 2014). Tidy data, as defined by Hadley, involves (among other requirements) that:\n\nEach variable forms a column.\nEach observation forms a row.\n\nThe tidy data format can be initially challenging for some researchers to understand because it is based on thinking about, and structuring data, in terms of observations/measurements instead of participants. In this section we will describe common approaches to entering animal and human participant data and how they can be done keeping the tidy data requirement in mind. It’s not essential that data be entered in a tidy data format but it is essential that you enter data in a manner that makes it easy to later convert data to a tidy data format. When dealing with animal or human participant data it’s common to enter data into a spreadsheet. Each row of the spreadsheet is typically used to represent a single participant and each column of the spreadsheet is used to represent a variable.\nBetween participant data. Consider Table 1.1 which illustrates between participant data for six human participants running 5 kilometers. The first column is id, which indicates there are six unique participants and provides and identification number for each of them. The second column is sex, which is a variable, and there is one observation per row, so sex also conforms to the tidy data specification. Finally, there is a last column elapsed_time which is a variable with one observation per row – also conforming to tidy data specification. Thus, single occasion between subject data like this conforms to the tidy data specification. There is usually nothing you need to do to convert between-participant data (or cross-sectional data) to be in a tidy data format.\n\n\n\n\nTable 1.1: Between participant data entered one row per participant\n\n\n\n\n\n\nid\nsex\nelapsed_time\n\n\n\n\n1\nmale\n40\n\n\n2\nfemale\n35\n\n\n3\nmale\n38\n\n\n4\nfemale\n33\n\n\n5\nmale\n42\n\n\n6\nfemale\n36\n\n\n\n\n\n\n\n\nWithin participant data. Consider Table 1.2 which illustrates within participant data for six human participants running 5 kilometers - but on three different occasions. The first column is id, which indicates there are six unique participants and provides an identification number for each of them. The second column is sex, which is a variable, and there is one observation per row, so sex also conforms to the tidy data specification. Next, there are three different columns (march, may, july) each of which contains elapsed time (in minutes) for the runner in a different month. Elapsed run times are spread out over three columns so elapse_time is not in a tidy data format. Moreover, it’s not clear from the data file that march, may, and july are levels of a variable called occasion. Nor is it clear that elapsed_times are recorded in each of those columns (i.e., the dependent variable is unknown/not labeled). Although this format is fine as a data entry format it clearly has problems associated with it when it comes time to analyze your data.\n\n\n\n\nTable 1.2: Within participant data entered one row per participant\n\n\n\n\n\n\nid\nsex\nmarch\nmay\njuly\n\n\n\n\n1\nmale\n40\n37\n35\n\n\n2\nfemale\n35\n32\n30\n\n\n3\nmale\n38\n35\n33\n\n\n4\nfemale\n33\n30\n28\n\n\n5\nmale\n42\n39\n37\n\n\n6\nfemale\n36\n33\n31\n\n\n\n\n\n\n\n\n\n\n\n\nTable 1.3: A tidy data version of the within participant data\n\n\n\n\n\n\nid\nsex\noccasion\nelapsed_time\n\n\n\n\n1\nmale\nmarch\n40\n\n\n1\nmale\nmay\n37\n\n\n1\nmale\njuly\n35\n\n\n2\nfemale\nmarch\n35\n\n\n2\nfemale\nmay\n32\n\n\n2\nfemale\njuly\n30\n\n\n3\nmale\nmarch\n38\n\n\n3\nmale\nmay\n35\n\n\n3\nmale\njuly\n33\n\n\n4\nfemale\nmarch\n33\n\n\n4\nfemale\nmay\n30\n\n\n4\nfemale\njuly\n28\n\n\n5\nmale\nmarch\n42\n\n\n5\nmale\nmay\n39\n\n\n5\nmale\njuly\n37\n\n\n6\nfemale\nmarch\n36\n\n\n6\nfemale\nmay\n33\n\n\n6\nfemale\njuly\n31\n\n\n\n\n\n\n\n\nThus, a major problem with entering repeated measures data in the one row per person format is that there are hidden variables in the data and you need insider knowledge to know what the columns represent. That said, this is not necessarily a terrible way to enter your data as long as you have all of this missing information documented in a data code book.\n\n\n\n\n\n\n\nDisadvantages one row per participant\nAdvantages one row per participant\n\n\n\n\n1) Predictor variable (occasion) is hidden and spread over multiple columns\n1) Easy to enter this way\n\n\n2) Unclear that each month is a level of the predictor variable occasion\n\n\n\n3) Dependent variable (elapsed_time) is not indicated\n\n\n\n4) Unclear that elapsed_time is the measurement in each month column\n\n\n\n\n\nFortunately, the problems with Table 1.2 can be largely resolved by converting the data to a tidy data format. This can be done with the pivot_long() command that we will learn about in the Cookbook chapter. Thus, we can enter the data in the format of Table 1.2 and later convert it to a tidy data format. After this conversion the data will be appear as in Table 1.3. For elapsed_time variable this data is now in the tidy data format. Each row corresponds to a single elapsed_time observed. Each column corresponds to a single variable. Somewhat problematically, however, sex is repeated three times for each person (i.e., over the three rows) - and this can be confusing. However, if the focus in on analyzing elapsed time this tidy data format makes sense. Importantly, there is an id column for each participant so R knows that this information is repeated for each participant and is not confused by repeating the sex designation over three rows. Indirectly, this illustrates the importance of having an id column to indicate each unique participant.\nWhy did we walk you through this technical treatment of structuring data at this point in time - so that you pay attention to the advice that follows. You can see at this point that you may well need to restructure your data for certain analyses. The ability to do so quickly and easily depends upon following the advice in this chapter around naming conventions for variables and other aspects of your analyses. You can imagine the challenges for converting the data in Table 1.2 to the data in Table 1.3 by hand. You want to be able to automate that process and others - which is made substantially easier if you follow the forthcoming advice about naming conventions in the tidyverse.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>An Emphasis on Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#data-collection-considerations",
    "href": "workflow.html#data-collection-considerations",
    "title": "1  An Emphasis on Workflow",
    "section": "1.4 Data collection considerations",
    "text": "1.4 Data collection considerations\nData can be collected in a wide variety of ways. Regardless of the method of data collection researchers typically come to data in one of two ways: 1) a research assistant enters the data into a spreadsheet type interface, or 2) the data is obtained as the output from computer software (e.g., Qualtrics, SurveyMonkey, Noldus, etc.).\nRegardless of the approach, it is critical to name your variables appropriately. For those using software, such as Qualtrics, this means setting up the software to use appropriate variable names PRIOR to data collection - so the exported file has desirable column names. For spreadsheet users, this means setting up the spreadsheet in which the data will be recorded with column names that are amenable to the future analyses you want to conduct.\nAlthough failure to take this thoughtful approach at the data collection stage can be overcome - it is only overcome with substantial manual effort. Therefore, as noted previously, we strongly encourage you to follow the naming conventions we espouse here when you set up your data recording regime. Additionally, we encourage you to give careful thought in advance to the codes you will use to record missing data.\n\n1.4.1 File naming conventions\nI strongly suggest you check out these excellent slides by Danielle Navarro on file name convention best practices.\n\n\n1.4.2 Data column naming conventions\nTo make your life easier down the road, it is critical you set up your spreadsheet or online survey such that it uses a naming convention prior to data collection. The naming conventions suggested here are adapted from the tidyverse style guide.\n\nLowercase letters only\nIf using multiple words in a name (a good idea), only use the underscore (“_”) character to separate words in the name.\nAvoid short decontextualized variable names like q1, q2, q3, etc.\nDo use moderate length column names. Aim to achieve a unique prefix for related columns so that those columns can be selected using the starts_with() command discussed in the previous chapter. Be sure to avoid short two or three letter prefixes for item names. Instead, use unique moderate length item prefixes so that it will be easy to select those columns using start_with() such that you don’t accidentally get additionally columns you don’t want - that have a similar prefix.\nLikert items. Be sure to indicate the following information in the name of each Likert item or you will make your life substantially more complicated when you start to analyze your data. The information to include: a) the name of the measure, b) the item number for the measure, c) that it is a Likert item, d) the number of Likert response options, and e) whether the item is reverse keyed. That’s five things to include in each Likert item name. But it’s easy to do so. Consider two “affective commitment” items, the 2nd and 3rd items on scale. Both items use a 5-point Likert response format. However, item 3 is reverse keyed. Names that conform to this convention are: aff_com3_likert5, aff_com3_likert5rev. Using this naming convention ensures you can easily select and convert the items later. You can select by “likert5”, “likert5rev” or select by “aff_com”.\nIf you have a column name that represents the levels of two repeated measures variables only use the underscore character to separate the levels of the different variables. See within-participant ANOVA section below for details.\nColumn content. Avoid numerical representation of categorical variables. Don’t use 1 or 2 to represent a variable like sex. Use male and female in your spreadsheet - likewise in your survey program. Similarly, for between participant variables like drug_condition don’t use 1 or 2 use “drug” and “placebo” but the actual drug name would be even better than the word “drug.” Following this approach ensure the data can “stand alone” for resuse by others (especially if a data codebook (example) is not provided.) Note you will covert categorical variables such as sex (male/female) to numeric representations in your script - but then it will be clear what each value means.\n\n\n\n1.4.3 Likert-type items\nA Likert-type item is typically composed of a statement with which participants are asked to agree or disagree. For example, participants could be asked to indicate the extent to which they agree with a number of statements such as “I like my job”. Then they would be presented with response scale such as: 1 - Strongly Disagree, 2 - Moderately Disagree, 3 - Neutral, 4, Moderately Agree, 5 - Strongly Agree. A common question is, how should I enter the data?\nExport text responses not numbers Software such as Qualtrics gives you the option of exporting the label (e.g., “Strongly Agree”) or a value (e.g., 1). Make sure you export the text lable (“Strongly Agree). That way, the data file stands alone - and doesn’t require additional knowledge to know what 1 means. You can easily convert the labels to numbers later.\n\nHigh numbers should be associated with more of the construct being measured. When designing your survey or data collection tools, it is important that you set the response options appropriately. If your scale measures job satisfaction, it is important that you collect data in a manner that ensures high numbers on the job satisfaction scale indicate high levels of job satisfaction. Therefore, assigning numbers makes sense using the 5-point scale: 1 - Strongly Disagree, 2 - Moderately Disagree, 3 - Neutral, 4, Moderately Agree, 5 - Strongly Agree. With this approach high response numbers indicate more job satisfaction. However, using the opposite scale would not make sense: 1 - Strongly Agree, 2 - Moderately Agree, 3 - Neutral, 4, Moderately Disagree, 5 - Strongly Disagree. With this opposite scale high numbers on a job satisfaction scale would indicate lower levels of job satisfaction - a very confusing situation. Avoid this situation, assign numbers so that higher numbers are associated with more of the construct being measured.\nUse appropriate item names. As described in the naming convention section, use moderate length names with different labels for each subscale.\nUse moderate length column names unique to each subscale. Imagine you have a survey with an 18-item commitment scale (Meyer, Allen, and Smith 1993) composed of three 6-item subscales: affective, normative, and continuance commitment. It would be a poor choice to prefix the labels of all 18 columns in your data with “commit” such that the names would be commit1, commit2, commit3, etc. The problem with this approach is that it fails to distinguish among the three subscales in naming convention; making it impossible to select the items for a single subscale using starts_with(). A better, but still poor choice for a naming convention would be use use a two letter prefix for the three scale such ac, nc, and cc. This would result in names for the columns like ac1, ac2, ac3, etc. This is an improvement because you could apparently (but likely not) select the columns using starts_with(“ac”). The problem with these short names is that there could be many columns in data set that start with “ac” beside the affective commitment items. You might want to select the affective commitment items using starts_with(“ac”); but you would get all the affective commitment item columns; but also all the columns measuring other variables that also start with “ac”. Therefore, it’s a good idea to use a moderate length unique prefix for column names. For example, you might use prefixes like affect_com, norm_com, and contin_com for the three subscales. But see below because you need to include more than this in each name.\nIndicate these 5 things in each Likert item name. Be sure to indicate the following information in the name of each Likert item or you will make your life substantially more complicated when you start to analyze your data. The information to include: 1) the name of the measure, 2) the item number for the measure, 3) that it is a Likert item, 4) the number of Likert response options, and 5) whether the item is reverse keyed. That’s five things to include in each Likert item name. But it’s easy to do so. Consider two “affective commitment” items, the 2nd and 3rd items on scale. Both items use a 5-point Likert response format. However, item 3 is reverse keyed. Names that conform to this convention are: aff_com2_likert5, aff_com3_likert5rev. Using this naming convention ensure you can easily select and convert the items later. You can select by “likert5”, “likert5rev” or select by “aff_com” (or both).\n\nIndicate in the item name if the item is reversed keyed. Sometimes with Likert-type items, an item is reverse keyed. For example, on a job satisfaction scale, participants will typically respond to items that reflect job satisfaction using the scale: 1 - Strongly Disagree, 2 - Moderately Disagree, 3 - Neutral, 4, Moderately Agree, 5 - Strongly Agree. Higher numbers indicate more job satisfaction. Sometimes, however, some items will use the same 1 to 5 response scale but be worded in the opposite manner such as “I hate my job”. Responding with a 5 to this item would indicate high job dissatisfaction. But the columns for job satisfaction items should have high values that indicate high job satisfaction not high job dissatifaction. Consequently, we flag the names of columns with reversed responses (i.e., reverse-key items) so that we know to treat those column differently later. Columns with reverse-keyed items need to be processed by a script so that the values are flipped and scored in the right direction. The procedure for doing so is outlined in the next point.\nIndicate in the item name the range for reverse-key items. If an item is reverse keyed, the process for the flipping the scores depends upon the range of a scale. Although 5-point scales are common, any number of points are possible. The process for correcting a reverse-key item depends upon: 1) the number of points on the scale, and 2) the range of the points on the scale. The reverse-key item correction process is different for an item that uses a 5-point scale ranging from 1 to 5 versus from 0 to 4. Both are 5-point scales but your correction process will be different. Therefore, for reverse-key items add a suffix at the end of each item name that indicates an item is reverse keyed and the range of the item. For example, if the third job satisfaction item was reversed keyed on scale using a 1 to 5 response format you might name the item: job_sat3_likert5rev. The suffix “_likert5rev” indicates the item is Likert item that is reverse keyed and the range of responses used on the item is 1 to 5. Be sure to set up your survey with this naming convention when you collect your data.\n\nIf you collect items over multiple time points use a prefix with a short code to indicate the time followed by an underscore. For example, if you had a multi-item self-esteem scale you might call the column for the first time “t1_esteem1_likert5rev”. This indicate that you have for time 1 (t1), the first self-esteem item (esteem1) and that item is a likert item that is reverse keyed on a 1 to 5 scale.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>An Emphasis on Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#example-single-occassion-survey",
    "href": "workflow.html#example-single-occassion-survey",
    "title": "1  An Emphasis on Workflow",
    "section": "1.5 Example: Single Occassion Survey",
    "text": "1.5 Example: Single Occassion Survey\nThis section outlines a workflow appropriate for when you have cross-sectional single occasion survey data. Examples for other designs are presented in the Cookbook chapter. The data corresponds to a design where the researcher has measured, age, sex, eye color, self-esteem, and job satisfaction. Two of these, self-esteem and job satisfaction, were measured with multi-item scales with reverse-keyed items.\nTo Begin:\n\nUse the Files tab to confirm you have the data: data_item_scoring.csv\nStart a new script for this example. Don’t forget to start the script name with “script_”.\n\n\n# Date: YYYY-MM-DD\n# Name: your name here\n# Example: Single occasion survey\n\n# Load data\nlibrary(tidyverse)\n\nmy_missing_value_codes &lt;- c(\"-999\", \"\", \"NA\")\n\nraw_data_survey &lt;- read_csv(file = \"data_item_scoring.csv\",\n                     na = my_missing_value_codes)\n\nRows: 300 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): sex, eye_color\ndbl (12): id, age, esteem1_likert5, esteem2_likert5, esteem3_likert5, esteem...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe load the initial data into a raw_data_survey but immediately make a copy we will work with called analytic_data_survey. It’s good to keep a copy of the raw data for reference if you encounter problems.\n\nanalytic_data_survey &lt;- raw_data_survey\n\nRemove empty row and columns from your data using the remove_empty_cols() and remove_empty_rows(), respectively. As well, clean the names of your columns to ensure they conform to tidyverse naming conventions.\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n# Initial cleaning\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  remove_empty(\"rows\") %&gt;%\n  remove_empty(\"cols\") %&gt;%\n  clean_names()\n\nYou can confirm the column names following our naming convention with the glimpse command - and see the data type for each column.\n\nglimpse(analytic_data_survey)\n\nRows: 300\nColumns: 14\n$ id                 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ age                &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, NA, 20, 17, 24,…\n$ sex                &lt;chr&gt; \"male\", \"female\", \"male\", \"female\", \"male\", \"female…\n$ eye_color          &lt;chr&gt; \"blue\", \"brown\", \"hazel\", \"blue\", NA, \"hazel\", \"blu…\n$ esteem1_likert5    &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3…\n$ esteem2_likert5    &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2,…\n$ esteem3_likert5    &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, …\n$ esteem4_likert5    &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3…\n$ esteem5_likert5rev &lt;dbl&gt; 2, 2, 2, 2, 2, NA, NA, 2, 2, 2, 3, 2, 2, 3, 3, NA, …\n$ jobsat1_likert5    &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, …\n$ jobsat2_likert5rev &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2,…\n$ jobsat3_likert5    &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2,…\n$ jobsat4_likert5    &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, …\n$ jobsat5_likert5    &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4…\n\n\n\n1.5.1 Creating factors\nFollowing initial cleaning, we identify categorical variables as factors. If you plan to conduct an ANOVA - it’s critical that all predictor variables are converted to factors. Inspect the glimpse() output - if you followed our data entry naming conventions, categorical variables should be of the type character.\n\nglimpse(analytic_data_survey)\n\nRows: 300\nColumns: 14\n$ id                 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ age                &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, NA, 20, 17, 24,…\n$ sex                &lt;chr&gt; \"male\", \"female\", \"male\", \"female\", \"male\", \"female…\n$ eye_color          &lt;chr&gt; \"blue\", \"brown\", \"hazel\", \"blue\", NA, \"hazel\", \"blu…\n$ esteem1_likert5    &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3…\n$ esteem2_likert5    &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2,…\n$ esteem3_likert5    &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, …\n$ esteem4_likert5    &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3…\n$ esteem5_likert5rev &lt;dbl&gt; 2, 2, 2, 2, 2, NA, NA, 2, 2, 2, 3, 2, 2, 3, 3, NA, …\n$ jobsat1_likert5    &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, …\n$ jobsat2_likert5rev &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2,…\n$ jobsat3_likert5    &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2,…\n$ jobsat4_likert5    &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, …\n$ jobsat5_likert5    &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4…\n\n\nWe have two variables, sex and eye_color, that are categorical variable of type character (i.e., chr). The participant id column is categorical as well, but of type double (i.e., dbl) which is a numeric column. You can quickly convert all character columns to factors using the code below:\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(.cols = c(sex, eye_color),\n                .fns = as_factor))\n\nThe participant identification number in the id column is a numeric column, so we have to handle that column on its own.\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(id = as_factor(id))\n\nYou can ensure all of these columns are now factors using the glimpse() command.\n\nglimpse(analytic_data_survey)\n\nRows: 300\nColumns: 14\n$ id                 &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …\n$ age                &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, NA, 20, 17, 24,…\n$ sex                &lt;fct&gt; male, female, male, female, male, female, male, fem…\n$ eye_color          &lt;fct&gt; blue, brown, hazel, blue, NA, hazel, blue, brown, h…\n$ esteem1_likert5    &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3…\n$ esteem2_likert5    &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2,…\n$ esteem3_likert5    &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, …\n$ esteem4_likert5    &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3…\n$ esteem5_likert5rev &lt;dbl&gt; 2, 2, 2, 2, 2, NA, NA, 2, 2, 2, 3, 2, 2, 3, 3, NA, …\n$ jobsat1_likert5    &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, …\n$ jobsat2_likert5rev &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2,…\n$ jobsat3_likert5    &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2,…\n$ jobsat4_likert5    &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, …\n$ jobsat5_likert5    &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4…\n\n\nInspect the output of the glimpse() command and make sure you have converted all categorical variables to factors - especially those you will use as predictors.\nNote: If you have factors like sex that have numeric data in the column (e.g, 1 and 2) instead of male/female you need to handle the situation differently. The preceding section, Experiment: Within N-way, illustrates how to handle this scenario.\n\n\n1.5.2 Factor screening\nInspect the levels of each factor carefully. Make sure the factor levels of each variable are correct. Examine spelling and look for additional unwanted levels. For example, you wouldn’t want to have the following levels for sex: male, mmale, female. Obviously, mmale is an incorrectly typed version of male. Scan all the factors in your data for erroneous factor levels. The code below displays the factor levels:\n\nanalytic_data_survey %&gt;%\n  select(where(is.factor)) %&gt;%\n  summary()\n\n       id            sex      eye_color  \n 1      :  1   male    :147   blue : 99  \n 2      :  1   female  :149   brown: 98  \n 3      :  1   intersex:  2   hazel:100  \n 4      :  1   NA's    :  2   NA's :  3  \n 5      :  1                             \n 6      :  1                             \n (Other):294                             \n\n\nAlso inspect the output of the above summary() command paying attention to the order of the levels in the factors. The order influences how text output and graphs are generated. In these data, the sex column has two levels: male and female in that order. Below we adjust the order of the sex variable because we want the x-axis of a future graph to display columns in the left to right order: female, male.\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(sex = fct_relevel(sex,\n                           \"intersex\",\n                           \"female\",\n                           \"male\"))\n\nFor eye color, we want a future graph to have the most common eye colors on the left so we reorder the factor levels:\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(eye_color = fct_infreq(eye_color))\n\nYou can see the new order of the factor levels with summary():\n\nanalytic_data_survey %&gt;%\n  select(where(is.factor)) %&gt;%\n  summary()\n\n       id            sex      eye_color  \n 1      :  1   intersex:  2   hazel:100  \n 2      :  1   female  :149   blue : 99  \n 3      :  1   male    :147   brown: 98  \n 4      :  1   NA's    :  2   NA's :  3  \n 5      :  1                             \n 6      :  1                             \n (Other):294                             \n\n\n\n\n1.5.3 Numeric screening\nFor numeric variables, it’s important to find and remove impossible values. For example, in the context of this example you want to ensure none of the Likert responses are impossible (e.g., outside the 1- to 5-point rating scale) or clearly data entry errors.\nBecause we have several numeric columns that we are screening, we use the skim() command from the skimr package. The skim() command quickly provides basic descriptive statistics. In the output for this command there are also several columns that begin with p: p0, p25, p50, p75, and p100 (p25 and p75 omitted in output due to space). These columns correspond to the 0th, 25th, 50th, 75th, and 100th percentiles, respectively. The minimum and maximum values for the data column are indicated under the p0 and p100 labels. The median is the 50th percentile (p50). The interquartile range is the range between p25 and p75.\nStart by examining the range of non-scale items. In this case it’s only age. Examine the output to see if any of the age values are unreasonable. As noted, in the output p0 and p100 indicate the 0th percentile and the 100th percentile; that is the minimum and maximum values for the variable. Check to make sure none of the age values are unreasonably low or high. If they are, you may need to check the original data source or replace them with missing values.\n\nlibrary(skimr)\nanalytic_data_survey %&gt;%\n  select(age) %&gt;%\n  skim()\n\n\n\n  skim_variable n_missing  mean   sd p0 p50 p100\n1           age         3 20.52 2.05 17  20   24\n\n\nWith respect to the multi-item scales, it makes sense to look at sets of items rather than all of the items at once. This is because sometimes items from different scales use different response ranges. For example, one measure might use a response scale with a range from 1 to 5; whereas another measure might use a response scale with a range from 1 to 7. This is undesirable from a psychometric point of view, as discussed previously, but if it happens in your data - look at the scale items separately to make it easy to see out of range values.\nWe begin by looking at the items in the first scale, self-esteem. Possible items responses for this scale range from 1 to 5; make sure all responses are in this range. If any values fall outside this range, you may need to check the original data source or replace them with missing values - as described previously.\n\nanalytic_data_survey %&gt;%\n  select(starts_with(\"esteem\")) %&gt;%\n  skim()\n\n\n\n       skim_variable n_missing mean   sd p0 p50 p100\n1    esteem1_likert5        24 3.39 0.54  3   3    5\n2    esteem2_likert5        28 2.35 0.48  2   2    3\n3    esteem3_likert5        31 3.96 0.37  3   4    5\n4    esteem4_likert5        15 3.54 0.50  3   4    4\n5 esteem5_likert5rev        35 2.22 0.47  1   2    3\n\n\nFollow the same process for the job satisfaction items. Write that code on your own now.\nPossible item responses for the job satisfaction scale range from 1 to 5, make sure all responses are in this range. If any values fall outside this range, you may need to check the original data source or replace them with missing values - as described previously.\n\nanalytic_data_survey %&gt;%\n  select(starts_with(\"jobsat\")) %&gt;%\n  skim()\n\n\n\n       skim_variable n_missing mean   sd p0 p50 p100\n1    jobsat1_likert5        25 3.34 0.51  3   3    5\n2 jobsat2_likert5rev        27 1.51 0.61  1   1    3\n3    jobsat3_likert5        28 2.84 0.37  2   3    3\n4    jobsat4_likert5        35 4.29 0.70  3   4    5\n5    jobsat5_likert5        24 4.57 0.61  3   5    5\n\n\n\n\n1.5.4 Scale scores\nFor each person, scale scores involve averaging scores from several items to create an overall score. The first step in the creation of scales is correcting the values of any reverse-keyed items.\n\n1.5.4.1 Reverse-key items\nThe way you deal with reverse-keyed items depends on how you scored them. Imagine you had a 5-point scale. You could have scored the scale with the values 1, 2, 3, 4, and 5. Alternatively, you could have scored the scale with the values 0, 1, 2, 3, and 4. The mathematical approach you use to correcting reverse-keyed items depends upon whether the scale starts with 1 or 0.\nIn this example, we scored the data using the value 1 to 5; so that is the approach illustrated here. See the extra information box for details on how to fixed reverse-keyed items when the scale begins with zero.\nIn this data file all the reverse-keyed items were identified with the suffix “_likert5rev” in the column names. This suffix indicates the item was reverse keyed and that the original scale used the response points 1 to 5. We can see those items with the glimpse() command below. Notice that there are two reverse-keyed items - each on difference scales.\n\nanalytic_data_survey %&gt;%\n  select(ends_with(\"_likert5rev\")) %&gt;%\n  glimpse()\n\nRows: 300\nColumns: 2\n$ esteem5_likert5rev &lt;dbl&gt; 2, 2, 2, 2, 2, NA, NA, 2, 2, 2, 3, 2, 2, 3, 3, NA, …\n$ jobsat2_likert5rev &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2,…\n\n\nTo correct a reverse-keyed item where the lowest possible rating is 1 (i.e, 1 on a 1 to 5 scale), we simply subtract all the scores from a value one more than the highest point possible on the scale (i.e., one more than 5). For example, if a 1 to 5 response scale was used we subtract each response from 6 to obtain the recoded value.\n\n\n\nOriginal value\nMath\nRecoded value\n\n\n\n\n1\n6 - 1\n5\n\n\n2\n6 - 2\n4\n\n\n3\n6 - 3\n3\n\n\n4\n6 - 4\n2\n\n\n5\n6 - 5\n1\n\n\n\nThe code below:\n\nselects columns that end with “_likert5rev” (i.e., both esteem and jobsat scales)\nsubtracts the values in those columns from 6\nrenames the columns by removing “_likert5rev” from the name because the reverse coding is complete\n\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;% \n  mutate(6 - across(.cols = ends_with(\"_likert5rev\")) ) %&gt;% \n  rename_with(.fn = str_replace,\n              .cols = ends_with(\"_likert5rev\"),\n              pattern = \"_likert5rev\",\n              replacement = \"_likert5\")\n\nYou can use the glimpse() command to see the result of your work. If you compare these new values to those obtained from the previous glimpse() command you can see they have changed. Also notice the column names no longer indicate the items are reverse keyed.\n\nglimpse(analytic_data_survey)\n\nRows: 300\nColumns: 14\n$ id              &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ age             &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, NA, 20, 17, 24, 17…\n$ sex             &lt;fct&gt; male, female, male, female, male, female, male, female…\n$ eye_color       &lt;fct&gt; blue, brown, hazel, blue, NA, hazel, blue, brown, haze…\n$ esteem1_likert5 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3…\n$ esteem2_likert5 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2,…\n$ esteem3_likert5 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA,…\n$ esteem4_likert5 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3…\n$ esteem5_likert5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, …\n$ jobsat1_likert5 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, …\n$ jobsat2_likert5 &lt;dbl&gt; 5, 5, 5, NA, 5, 5, 4, 5, 4, 4, 3, 5, 3, 4, 5, 5, 4, 3,…\n$ jobsat3_likert5 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2,…\n$ jobsat4_likert5 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, …\n$ jobsat5_likert5 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4…\n\n\n\n\n\n\n\n\nCaution\n\n\n\nIf your scale had used response options numbered 0 to 4 the math is different. For each item you would use subtract values from the highest possible point (i.e, 4) instead of one larger than the highest possible point.\n\n\n\nOriginal value\nMath\nRecoded value\n\n\n\n\n0\n4 - 0\n4\n\n\n1\n4 - 1\n3\n\n\n2\n4 - 2\n2\n\n\n3\n4 - 3\n1\n\n\n4\n4 - 4\n0\n\n\n\nThus, the mutate command would instead be:\nmutate(4 - across(.cols = ends_with(“_likert5rev”)) )\n\n\n\n\n1.5.4.2 Creating scores\nThe process we use for creating scale scores deletes item-level data from analytic_data_survey. This is a desirable aspect of the process because it removes information that we are no longer interested in from our analytic data. That said, before we create scale score, we create a backup on the item-level data called analytic_data_survey_items. We will need to use this backup later to compute the reliability of the scales we are creating.\n\nanalytic_data_survey_items &lt;- analytic_data_survey\n\nWe want to make a self_esteem scale and plan to select items using starts_with(“esteem”). But prior to doing this we make sure the start_with() command only gives us the items we want - and not additional unwanted items. The output below confirms there are not problems associated with using starts_with(“esteem”).\n\nanalytic_data_survey %&gt;%\n  select(starts_with(\"esteem\")) %&gt;%\n  glimpse()\n\nRows: 300\nColumns: 5\n$ esteem1_likert5 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3…\n$ esteem2_likert5 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2,…\n$ esteem3_likert5 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA,…\n$ esteem4_likert5 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3…\n$ esteem5_likert5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, …\n\n\nLikewise, we want to make a job_sat scale and plan to select items using starts_with(“jobsat”). The code and output below using starts_with(“jobsat”) only returns the items we are interested in.\n\nanalytic_data_survey %&gt;%\n  select(starts_with(\"jobsat\")) %&gt;%\n  glimpse()\n\nRows: 300\nColumns: 5\n$ jobsat1_likert5 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, …\n$ jobsat2_likert5 &lt;dbl&gt; 5, 5, 5, NA, 5, 5, 4, 5, 4, 4, 3, 5, 3, 4, 5, 5, 4, 3,…\n$ jobsat3_likert5 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2,…\n$ jobsat4_likert5 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, …\n$ jobsat5_likert5 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4…\n\n\nWe calculate the scale scores using the rowwise() command. The mean() command provides the mean of columns by default - not people. We use the rowwise() command in the code below to make the mean() command work across columns (within participants) rather than within columns. The mutate command calculates the scale score for each person. The c_across() command combined with the starts_with() command ensures the items we want averaged together are the items that are averaged together. Notice there is a separate mutate line for each scale. The ungroup() command turns off the rowwise() command. We end the code block by removing the item-level data from the data set.\nImportant: Take note of how we name the scale variables (e.g., self_esteem, job_sat). We use a slightly different convention than our items. That is, these scale labels were picked so that they would not be selected by a starts_with(“esteem”) or starts_with(“jobsat”). Why - because we later use those commands to remove the item-level data. We would not want the command designed to remove the item-level data to also remove the scale we just calculated! This example illustrates how carefully you need to think about your naming conventions.\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;% \n  rowwise() %&gt;% \n  mutate(self_esteem = mean(c_across(starts_with(\"esteem\")),\n                               na.rm = TRUE)) %&gt;%\n  mutate(job_sat = mean(c_across(starts_with(\"jobsat\")),\n                               na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  select(-starts_with(\"esteem\")) %&gt;%\n  select(-starts_with(\"jobsat\")) \n\nWe can see our data now has the self_esteem column, a job_sat column, and that all of the item-level data has been removed.\n\nglimpse(analytic_data_survey)\n\nRows: 300\nColumns: 6\n$ id          &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ age         &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, NA, 20, 17, 24, 17, NA…\n$ sex         &lt;fct&gt; male, female, male, female, male, female, male, female, ma…\n$ eye_color   &lt;fct&gt; blue, brown, hazel, blue, NA, hazel, blue, brown, hazel, b…\n$ self_esteem &lt;dbl&gt; 3.200000, 3.800000, 3.800000, 3.000000, 3.400000, 3.500000…\n$ job_sat     &lt;dbl&gt; 4.000000, 5.000000, 4.400000, 3.500000, 4.000000, 3.800000…\n\n\nYou now have two data sets analytic_data_survey and analytic_data_survey_items. You can calculate descriptive statistics, correlations and most analyses using the analytic_data_survey. To obtain the reliability of the scales you just created though you will need to use the analytic_data_survey_items. Both sets of data are ready for analysis.\n\n\n\n\nBaker, M. 2016. “1500 Scientists Lift the Lid on Reproducibility.” Nature 533. https://doi.org/10.1038/533452a.\n\n\nMeyer, John P, Natalie J Allen, and Catherine A Smith. 1993. “Commitment to Organizations and Occupations: Extension and Test of a Three-Component Conceptualization.” Journal of Applied Psychology 78 (4): 538.\n\n\nMiyakawa, T. 2020. “No Raw Data, No Science: Another Possible Source of the Reproducibility Crisis.” Mol Brain 13 (24). https://doi.org/10.1186/s13041-020-0552-2.\n\n\nNosek. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349. http://doi.org/10.1126/science.aac4716.\n\n\nPatil P., & Leek J. T, Peng R. D. 2019. “A Visual Tool for Defining Reproducibility and Replicability.” Nat Hum Behav 3: 650–52. https://doi.org/10.1038/s41562-019-0629-z.\n\n\nSimmons, Joseph P, Leif D Nelson, and Uri Simonsohn. 2011. “False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant.” Psychological Science 22 (11): 1359–66.\n\n\nWickham, Hadley. 2014. “Tidy Data.” The Journal of Statistical Software 59. http://www.jstatsoft.org/v59/i10/.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>An Emphasis on Workflow</span>"
    ]
  },
  {
    "objectID": "qualtrics.html",
    "href": "qualtrics.html",
    "title": "2  Qualtrics",
    "section": "",
    "text": "2.1 Survey Response\nDesigning a survey process in way that ensure a high response rate is crucial to obtaining quality data. A low response rate can be problematic for many reasons. I encourage you to check out the resource below to help you design a survey process that maximizes your response rate.\nInternet, Phone, Mail, and Mixed-Mode Surveys: The Tailored Design Method",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Qualtrics</span>"
    ]
  },
  {
    "objectID": "qualtrics.html#overview",
    "href": "qualtrics.html#overview",
    "title": "2  Qualtrics",
    "section": "2.2 Overview",
    "text": "2.2 Overview\nThere are two tasks covered in this chapter: 1) importing surveys into Qualtrics and 2) moving data from Qualtrics to R. An overview of each process is below.\n1. Importing items into Qualtrics\n\nCreate a survey codebook in Excel (or similar program) that has each item and the response options for it\nConvert the survey codebook to Qualtrics Advanced Text Format\nImport the items\nTweak the survey after import\n\n2. Qualtrics Data to R\n\nExport the raw data from Qualtrics with maximal information in the data file\nLoad the raw data into R\nConvert the raw data to analytic data. This conversion includes: assigning values to response options (e.g., “Strongly Disagree” to a numeric value), flipping response for reverse-worded (i.e., reverse-keyed) items, and creating scale scores.\n\nThe overall steps are quite simple and I walk you through each step in detail below.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Qualtrics</span>"
    ]
  },
  {
    "objectID": "qualtrics.html#required",
    "href": "qualtrics.html#required",
    "title": "2  Qualtrics",
    "section": "2.3 Required",
    "text": "2.3 Required\nThe files below are used in this chapter. Right click to save each file.\n\n\n\nRelevant files\n\n\n\n\nsurvey_codebook.csv\n\n\nitems_qualtrics_format.txt\n\n\ndata_qualtrics.csv\n\n\nscript_qualtrics.R\n\n\n\nThe following CRAN packages must be installed:\n\n\n\nRequired CRAN Packages\n\n\n\n\ntidyverse\n\n\njanitor\n\n\nremotes\n\n\n\nThe following GitHub packages must be installed:\n\n\n\nRequired GitHub Packages\n\n\n\n\ndstanley4/qualtricsMaker\n\n\n\nA GitHub package can be installed using the code below:\n\nremotes::install_github(\"dstanley4/qualtricsMaker\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Qualtrics</span>"
    ]
  },
  {
    "objectID": "qualtrics.html#items-to-qualtrics",
    "href": "qualtrics.html#items-to-qualtrics",
    "title": "2  Qualtrics",
    "section": "2.4 Items to Qualtrics",
    "text": "2.4 Items to Qualtrics\nThere are two approaches to entering survey items into Qualtrics.\n\nEnter the items one at a time using the Qualtrics web interface.\nCreate a text file in the Qualtrics Advanced Text Format and import the items. Be warned though a bit of tweaking is often still needed using the web interface.\n\nHere we focus only on the second approach to entering items into Qualtrics.\n\n2.4.1 Create survey codebook\nThe easy way to create items in the Advanced Text Format is to use the qualtricsMaker package. With this package you create a spreadsheet with the items and then convert that spreadsheet to the Advanced Text Format.\nConsider a scenario where we want to create a survey that contains 2 demographics items, 18 commitment items, and 4 job satisfaction items. The three-component model of commitment items are from (Meyer, Allen, and Smith 1993) and the job satisfaction items are from (Thompson and Phua 2012).\nWe begin by creating a survey codebook spreadsheet in Excel (or similar program). The spreadsheet should have the columns with the names: block, item_name, item_text, type, response_options. The completed file ( survey_codebook.csv) is illustrated below. I provide a detailed description of what should be placed in each column after the figure. Remember to work from the guiding principle that one row is used for one item/question.\n\n\n\n\n\n\n\n\n\n\n2.4.1.1 block column\nEnter any text you wish to use as a label for a block of items.\n\n\n2.4.1.2 item_name column\nTo make your life easier down the road, it is critical you set up your spreadsheet or online survey such that it uses a naming convention prior to data collection. Recall the naming convention from the previous chapter.\n\n\n2.4.1.3 item_text column\nThe item_text column contains the text for each item. Note that if you use commas in your item text do not save this file as a .csv file - it will not work. Rather save it as .tsv file (tab separated values). Then use read_tsv command instead of the read_csv command in the code that follows later.\n\n\n2.4.1.4 type column\n\n\n\n\n\n\n\n\nCode for type column\nQualtrics Item Type\nAdditional Information\n\n\n\n\nmatrix\nmatrix\nIf the first item in a block has type matrix all items in the block will be used to construct the matrix question. Unfortunately, importing item_names for matrix questions is not supported by Qualtrics. You will need to manually restore your item_names following the directions below for matrix items.\n\n\nMC\nmultiple choice vertical format\n\n\n\nMC_horizontal\nmultiple choice horizontal format\n\n\n\nMC_multi_horizontal\nmultiple choice horizontal format multiple answers\n\n\n\nMC_select\nselect box\n\n\n\nMC_multi_select\nselect multiple boxes\n\n\n\nMC_dropdown\ndropdown\n\n\n\n\n\n\n2.4.1.5 response_options column\nThe Likert items for the different blocks use different response options. The commitment items use a 7-point response option whereas the job satisfaction items use a 5-point response option.\n\n2.4.1.5.1 Year of birth\nWe used a number of response options to indicate Year of Birth. We entered them as per below. Each response option is separated by a semi-colon. Each of the years below will be in the dropdown button.\nEntered in the response_option column as below. Each option separated by a semicolon.\n1940;1941;1942;1943;1944;1945;1946;1947;1948;1949;1950;1951;1952;1953;1954;1955;1956;1957;1958;1959;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010\n\n\n2.4.1.5.2 Sex 3 points\nPlease note that in psychology we distinguish between sex and gender. We use the term “sex” to refer to underlying biology. In contrast, we use the term “gender” to refer a psychological construct (i.e., gender identity). A person’s sex and gender may be quite different. Depending on the theory used in a study, you might be interested in sex or gender or both. In this example, we are using sex but not gender. If you were asking about gender - you would have a much longer (and quite different) list of options.\nEntered in the response_option column as below. Each option separated by a semicolon.\nmale; female; intersex\n\n\n2.4.1.5.3 Commitment 7 points\nEntered in the response_option column as below. Each option separated by a semicolon.\nStrongly Disagree;Moderately Disagree;Slightly Disagree;Neither Agree nor Disagree;Slightly Agree;Moderately Agree;Strongly Agree\n\n\n2.4.1.5.4 Job Satisfaction 5 points\nEntered in the response_option column as below. Each option separated by a semicolon.\nStrongly Disagree; Disagree; Neutral; Agree; Strongly Agree\n\n\n\n\n2.4.2 Convert to Qualtrics format\n\n2.4.2.1 Create TXT file\nOnce you have the survey codebook above, you need to convert it to an Advanced Text Format .txt file. We can do so by following the steps below. The instructions differ slightly for RStudio Cloud and RStudio - both are presented.\n\n2.4.2.1.1 RStudio on your computer\n\nCreate a folder on your computer called “new_survey” with the survey_codebook.csv file in it.\nOpen RStudio. Then go to File &gt; New Project… and select Existing Directory.\n\n\n\n\n\n\n\n\n\n\n\nThen find and select the “new_survey” folder on your hard drive and click the Create Project button.\n\n\n\n\n\n\n\n\n\n\n\nYou should previously have installed the remotes and tidyverse packages from the CRAN and the qualtricsMaker package from GitHub. If you haven’t done this already type the commands below into the Console.\n\nInstalling Packages from the CRAN\n\ninstall.packages(\"tidyverse\", dep = TRUE)\ninstall.packages(\"remotes\", dep = TRUE)\n\nInstalling Package from GitHub\nThen install the qualtricsMaker package from GitHub:\n\nremotes::install_github(\"dstanley4/qualtricsMaker\")\n\n\nCreate a new script by going to File &gt; New File &gt; R Script. A new script will appear in RStudio. Immediately press Control-S to save the script. Call it “script_convert.R”.\n\n\n\n\n\n\n\n\n\n\n\nPlace the code below into the script and press Control-S to save your work.\n\n\nlibrary(tidyverse)\nlibrary(qualtricsMaker)\n\nsurvey_codebook &lt;- read_csv(\"survey_codebook.csv\",\n                            show_col_types = FALSE)\n\nmake_survey(survey_codebook,\n            filename = \"items_qualtrics_format.txt\")\n\n\nRun the script by pressing the Source button in the top right of the the Script window. Doing so will create the items_qualtrics_format.txt file that you will import into Qualtrics. You can see the file after it has been created in the Files tab below.\n\n\n\n\n\n\n\n\n\n\nCongratulations - your items are ready to be imported into Qualtrics. Move on to the “Import the items” section.\n\n\n2.4.2.1.2 RStudio Cloud\n\nOpen a new project in RStudio Cloud\nYou should previously have installed the remote and tidyverse package from the CRAN and the qualtricsMaker package from GitHub. If you haven’t done this already type the commands below into the Console.However, if you are working from a class project I created these packages will have been installed already for you.\n\n\ninstall.packages(\"tidyverse\", dep = TRUE)\ninstall.packages(\"remotes\", dep = TRUE)\n\nThen install the qualtricsMaker package from GitHub:\n\nremotes::install_github(\"dstanley4/qualtricsMaker\")\n\n\nImport the survey_codebook.csv file by using the Upload button in the Files tab in the lower right panel.\n\n\n\n\n\n\n\n\n\n\n\nClick the Choose File button and select the survey_codebook.csv file on your hard drive. Then click OK. The survey_codebook.csv file will then appear on the Files tab within RStudio Cloud.\n\n\n\n\n\n\n\n\n\n\n\nCreate a new script by going to File &gt; New File &gt; R Script. A new script will appear in RStudio. Immediately press Control-S to save the script. Call it “script_convert.R”.\n\n\n\n\n\n\n\n\n\n\n\nPlace the code below into the script and press Control-S to save your work.\n\n\nlibrary(tidyverse)\nlibrary(qualtricsMaker)\n\nsurvey_codebook &lt;- read_csv(\"survey_codebook.csv\",\n                            show_col_types = FALSE)\n\nmake_survey(survey_codebook,\n            filename = \"items_qualtrics_format.txt\")\n\n\nRun the script by pressing the Source button in the top right of the the Script window. Doing so will create the items_qualtrics_format.txt file that you will import into Qualtrics. You can see the file after it has been created in the Files tab below.\n\n\n\n\n\n\n\n\n\n\n\nSelect the checkbox beside the file you just created: items_qualtrics_format.txt\n\n\n\n\n\n\n\n\n\n\n\nSelect Export from the More menu.\n\n\n\n\n\n\n\n\n\n\n\nLeave the filename as it appears and click the Download button. The file will appear in the Downloads directory on your computer.\n\n\n\n\n\n\n\n\n\n\n\nMove the file (items_qualtrics_format.txt) from the Download folder to an easy to access place (e.g. the Desktop).\n\nCongratulation - your items are ready to be imported into Qualtrics. Move on to the “Import the items” section.\n\n\n\n\n2.4.3 Import the items\nIn the previous step you created items_qualtrics_format.txt. This file is illustrated below - well the middle of the file is illustrated below. You can think of the file created by the survey_maker command above as a starting point. You could open up this file in a text editor and make further modifications or additions based on learning the Advanced Text Format. For example, you might not want the matrix items to be in their own block. If so, you would simply remove the block text [[Block:Commitment]] from the text file prior to following the directions below. If you’re a Mac user you might find the text editor BBEdit helpful for this purpose – the free version is sufficient. After you download BBEdit you have access to all of its features. Once the free trial ends - the core features are still free. You only need to purchase it if you want the advanced features (and you won’t need the advanced features).\n\n\n\n\n\n\n\n\n\n\n2.4.3.0.1 Begin the import by logging into Qualtrics\nBegin by logging into Qualtrics via the University of Guelph site for Data Collection & Surveys. After you log in, continue below.\n\n\n2.4.3.0.2 Click the Create New Project button in the top right of the page.\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.1 Under Projects from Scratch select “Survey” by clicking on it.\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.2 Click the Get Started button in the lower right of the page.\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.3 Enter project name, click Create Project\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.4 Use the Tools menu to import the items\nSelect the Import option and then specify the filename (items_qualtrics_format.txt) for the Advanced Text import file with the items in it.\n\n\n\n\n\n\n\n\n\nCongratulation - your items have been imported into Qualtrics.\n\n\n2.4.3.5 Remove the default Empty Question block at the top of the survey\nScroll to the top of the survey and you will see a Default Question Block above your first block. Click on the three dots “…” in the top right of this block and select Delete to remove it.\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.4 Tweak survey in Qualtrics\nNow you need to tweak the survey using the Qualtrics interface. Recall that when you import items into Qualtrics, matrix-style questions will loose their item names. You need to manually restore the item names for matrix questions now.\n\nBegin by scrolling down to a block of matrix-style questions. Select the block so it gets a blue rectangle around it.\n\n\n\n\n\n\n\n\n\n\n\nOn the left side menu go the “Question Behaviour” menu and select “Recode values”\n\n\n\n\n\n\n\n\n\n\n\nClick the Export Question Tags check box. You will see the default names for the items (instead of the ones you indicated in the codebook). Click the Close button in the lower right when you’re done.\n\n\n\n\n\n\n\n\n\n\n\nManually restore the item names from the survey codebook by clicking the blue name for each item and fixing it. Don’t forget to use proper item naming formats and include the reverse-key status of each item.\n\n\n\n\n\n\n\n\n\n\n\nCollect your data!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Qualtrics</span>"
    ]
  },
  {
    "objectID": "qualtrics.html#qualtrics-data-to-r",
    "href": "qualtrics.html#qualtrics-data-to-r",
    "title": "2  Qualtrics",
    "section": "2.5 Qualtrics data to R",
    "text": "2.5 Qualtrics data to R\nFollowing data collection, you can obtain your data from Qualtrics. As of 2021, Tri-Agency (NSERC, SSHRC, CIHR) policy is that data collected with Tri-Agency funded research must be available for reuse by others. The data should follow the FAIR (Findable, Accessible, Interoperable, and Reusable) principle. Consequently, when you export the data from Qualtrics (and eventually post it) we want to ensure it has as much information in it as possible. This principle guides the options we select below.\n\n2.5.1 Export from Qualtrics\n\n2.5.1.1 Click the Data & Analysis tab\n\n\n\n\n\n\n\n\n\n\n\n2.5.1.2 Click the Export & Import button\nThen click the Export Data… option.\n\n\n\n\n\n\n\n\n\n\n\n2.5.1.3 Click Use Choice Text\nTo ensure the data can be used by others, as per the FAIR policy described above, we SELECT the “Use Choice Text” option when exporting data. If you were to (non-optimally) select “Use numeric value” as an export option then the resulting data file would be missing information that make it difficult for others to use. Then click the Download button.\n\n\n\n\n\n\n\n\n\nThe file will appear in your downloads directory.\n\nIt will likely be a zipped filed. Unzip the file before proceeding. On a Mac, you can just double click the file to do so.\nRename the file to data_qualtrics.csv\n\n\n\n\n2.5.2 Load data in R\nTo load the data in R follow the steps below\n\nCreate a new folder called “survey_data”\nDrag the data_qualtrics.csv file to the survey_data folder.\nUse the steps described previously on this page, use RStudio to create project for this data.\nYou may be tempted to load the data using the usual read_csv() process. This will be problematic due to the way the data is formatted in the .csv file. (see image below.)\n\n\n\n\n\n\n\n\n\n\n\nYou can see by inspecting the data screenshot above that a variety of columns have been included before our first data column (year_of_birth) which appears on the far right of screenshot. Also note that there are three header rows at the top of the file before the data which starts on row 4. So there are few problems that need to be addressed when we load data from Qualtrics.\n\n\nObtain the names from the first header row but read the data from row 4 on.\nRemove some, or all, of the additional columns on the left side of data set added by Qualtrics\nEnsure our variable names follow the tidyverse style guide\nEnsure we DO NOT modify the data_qualtrics.csv file in Excel or other program. That would destroy the reproducibility of our work in the very first step.\n\n\n\n2.5.3 Convert to analytic data\nThe issues described above are all solved with the script below.\nAdditionally, in the script we also:\n\nConvert categorical variable to factors\nScreen both numeric variables and factors for impossible values\nConvert Likert items from labels (e.g., “Strongly Disagree”) to numbers (e.g., 1)\nFlip reverse-key (i.e., reverse worded items) so they are scored in the right direction\nCombine items (e.g., aff_com1_likert7) for the same measure into a single scale score (e.g., affective_commitment)\nRemove item columns (e.g., aff_com1_likert7) after that have been combined into the scale score while retaining the scale score column column (e.g., affective_commitment)\n\n\n2.5.3.1 Load Data\n\n# Date: YYYY-MM-DD\n# Name: your name here\n# Example: Single occasion survey\n\n# Load data\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(skimr)\n\n# read the file in the normal way and get just the names of the columns.\n# put the names into the col_names\nsurvey_file &lt;- \"data_qualtrics.csv\"\ncol_names &lt;- names(read_csv(survey_file,\n                            n_max = 0,\n                            show_col_types = FALSE))\n\n# skip the first 3 rows than read in the data and use names from above\nraw_data &lt;- read_csv(survey_file,\n                  col_names = col_names, \n                  skip = 3,\n                  show_col_types = FALSE)\n\nRemove the Qualtrics columns you probably don’t want:\n\n# Qualtrics columns to remove (any_of() ignores names not present)\ncols_to_remove &lt;- c(\"StartDate\",\n                    \"EndDate\",\n                    \"Status\",\n                    \"IPAddress\",\n                    \"Progress\",\n                    \"Finished\",\n                    \"RecordedDate\",\n                    \"ResponseId\",\n                    \"RecipientLastName\",\n                    \"RecipientFirstName\",\n                    \"RecipientEmail\",\n                    \"ExternalReference\",\n                    \"LocationLatitude\",\n                    \"LocationLongitude\",\n                    \"DistributionChannel\",\n                    \"UserLanguage\")\n\n# remove the unwanted Qualtrics columns\nraw_data &lt;- raw_data |&gt; \n  select(!any_of(cols_to_remove))\n\nWe make a copy of the data called analytic_data_survey since the goals of the next several steps are to prepare the data for analysis.\n\nanalytic_data_survey &lt;- raw_data\n\nIn the command below, we ensure our column names follow the tidyverse style guide by using the clean_names() command from the janitor package. Additionally, we remove empty row and columns from the data using the remove_empty_cols() and remove_empty_rows(), respectively.\n\n# Initial cleaning\n## Convert column names to tidyverse style guide\n## Remove empty rows and columns\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  remove_empty(\"rows\") %&gt;%\n  remove_empty(\"cols\") %&gt;%\n  clean_names()\n\nYou can confirm the column names following our naming convention with the glimpse command - and see the data type for each column.\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 25\n$ duration_in_seconds  &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262, …\n$ year_of_birth        &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970, 1…\n$ sex                  &lt;chr&gt; \"female\", \"female\", \"female\", \"male\", \"intersex\",…\n$ aff_com1_likert7     &lt;chr&gt; \"Slightly Agree\", \"Neither Agree nor Disagree\", \"…\n$ aff_com2_likert7     &lt;chr&gt; \"Slightly Agree\", \"Slightly Disagree\", \"Neither A…\n$ aff_com3_likert7rev  &lt;chr&gt; \"Strongly Disagree\", \"Neither Agree nor Disagree\"…\n$ aff_com4_likert7rev  &lt;chr&gt; \"Moderately Disagree\", \"Strongly Agree\", \"Moderat…\n$ aff_com5_likert7rev  &lt;chr&gt; \"Strongly Disagree\", \"Neither Agree nor Disagree\"…\n$ aff_com6_likert7     &lt;chr&gt; \"Moderately Agree\", \"Strongly Agree\", \"Strongly D…\n$ contin_com1_likert7  &lt;chr&gt; \"Strongly Agree\", \"Neither Agree nor Disagree\", \"…\n$ contin_com2_likert7  &lt;chr&gt; \"Slightly Agree\", \"Slightly Agree\", \"Slightly Dis…\n$ contin_com3_likert7  &lt;chr&gt; \"Strongly Disagree\", \"Slightly Disagree\", \"Strong…\n$ contin_com4_likert7  &lt;chr&gt; \"Moderately Agree\", \"Neither Agree nor Disagree\",…\n$ contin_com5_likert7  &lt;chr&gt; \"Slightly Agree\", \"Slightly Agree\", \"Strongly Dis…\n$ contin_com6_likert7  &lt;chr&gt; \"Moderately Disagree\", \"Moderately Disagree\", \"St…\n$ norm_com1_likert7rev &lt;chr&gt; \"Neither Agree nor Disagree\", \"Slightly Disagree\"…\n$ norm_com2_likert7    &lt;chr&gt; \"Moderately Disagree\", \"Moderately Agree\", \"Stron…\n$ norm_com3_likert7    &lt;chr&gt; \"Neither Agree nor Disagree\", \"Neither Agree nor …\n$ norm_com4_likert7    &lt;chr&gt; \"Moderately Disagree\", \"Moderately Disagree\", \"St…\n$ norm_com5_likert7    &lt;chr&gt; \"Strongly Disagree\", \"Strongly Disagree\", \"Strong…\n$ norm_com6_likert7    &lt;chr&gt; \"Strongly Agree\", \"Strongly Disagree\", \"Moderatel…\n$ job_aff1_likert5     &lt;chr&gt; \"Strongly Agree\", \"Strongly Agree\", \"Neutral\", \"S…\n$ job_aff2_likert5     &lt;chr&gt; \"Strongly Disagree\", \"Strongly Agree\", \"Strongly …\n$ job_aff3_likert5     &lt;chr&gt; \"Neutral\", \"Strongly Disagree\", \"Disagree\", \"Stro…\n$ job_aff4_likert5     &lt;chr&gt; \"Disagree\", \"Strongly Agree\", \"Agree\", \"Strongly …\n\n\n\n\n2.5.3.2 Creating factors\nFollowing initial cleaning, we identify categorical variables as factors.\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 25\n$ duration_in_seconds  &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262, …\n$ year_of_birth        &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970, 1…\n$ sex                  &lt;chr&gt; \"female\", \"female\", \"female\", \"male\", \"intersex\",…\n$ aff_com1_likert7     &lt;chr&gt; \"Slightly Agree\", \"Neither Agree nor Disagree\", \"…\n$ aff_com2_likert7     &lt;chr&gt; \"Slightly Agree\", \"Slightly Disagree\", \"Neither A…\n$ aff_com3_likert7rev  &lt;chr&gt; \"Strongly Disagree\", \"Neither Agree nor Disagree\"…\n$ aff_com4_likert7rev  &lt;chr&gt; \"Moderately Disagree\", \"Strongly Agree\", \"Moderat…\n$ aff_com5_likert7rev  &lt;chr&gt; \"Strongly Disagree\", \"Neither Agree nor Disagree\"…\n$ aff_com6_likert7     &lt;chr&gt; \"Moderately Agree\", \"Strongly Agree\", \"Strongly D…\n$ contin_com1_likert7  &lt;chr&gt; \"Strongly Agree\", \"Neither Agree nor Disagree\", \"…\n$ contin_com2_likert7  &lt;chr&gt; \"Slightly Agree\", \"Slightly Agree\", \"Slightly Dis…\n$ contin_com3_likert7  &lt;chr&gt; \"Strongly Disagree\", \"Slightly Disagree\", \"Strong…\n$ contin_com4_likert7  &lt;chr&gt; \"Moderately Agree\", \"Neither Agree nor Disagree\",…\n$ contin_com5_likert7  &lt;chr&gt; \"Slightly Agree\", \"Slightly Agree\", \"Strongly Dis…\n$ contin_com6_likert7  &lt;chr&gt; \"Moderately Disagree\", \"Moderately Disagree\", \"St…\n$ norm_com1_likert7rev &lt;chr&gt; \"Neither Agree nor Disagree\", \"Slightly Disagree\"…\n$ norm_com2_likert7    &lt;chr&gt; \"Moderately Disagree\", \"Moderately Agree\", \"Stron…\n$ norm_com3_likert7    &lt;chr&gt; \"Neither Agree nor Disagree\", \"Neither Agree nor …\n$ norm_com4_likert7    &lt;chr&gt; \"Moderately Disagree\", \"Moderately Disagree\", \"St…\n$ norm_com5_likert7    &lt;chr&gt; \"Strongly Disagree\", \"Strongly Disagree\", \"Strong…\n$ norm_com6_likert7    &lt;chr&gt; \"Strongly Agree\", \"Strongly Disagree\", \"Moderatel…\n$ job_aff1_likert5     &lt;chr&gt; \"Strongly Agree\", \"Strongly Agree\", \"Neutral\", \"S…\n$ job_aff2_likert5     &lt;chr&gt; \"Strongly Disagree\", \"Strongly Agree\", \"Strongly …\n$ job_aff3_likert5     &lt;chr&gt; \"Neutral\", \"Strongly Disagree\", \"Disagree\", \"Stro…\n$ job_aff4_likert5     &lt;chr&gt; \"Disagree\", \"Strongly Agree\", \"Agree\", \"Strongly …\n\n\n\n2.5.3.2.1 Sex\nThere is only one variable that we will convert to a factor and that’s the sex variable. We convert it to a factor with the command below.\n\n# Convert variables to factors as needed\n## Convert sex to factor\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(sex = as_factor(sex))\n\n\n\n2.5.3.2.2 Participant identification\nIn many analyses we will need a column with a unique identification number that is a factor. We don’t see one in this data set so we create it with the name participant_id.\n\n## Participant identification to factor\n## Participant identification column must be created first\n## get the number of rows in the data set\nN &lt;- dim(analytic_data_survey)[1] \n\n## create set of factor levels\nparticipant_id_levels &lt;- factor(seq(1, N))\n\n## put the factor levels into a column called participant_id\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(participant_id = participant_id_levels)\n\nYou can ensure all of these columns are now factors using the glimpse() command.\n\nanalytic_data_survey %&gt;%\n  select(sex, participant_id) %&gt;%\n  glimpse()\n\nRows: 150\nColumns: 2\n$ sex            &lt;fct&gt; female, female, female, male, intersex, intersex, inter…\n$ participant_id &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n\n\n\n\n\n2.5.3.3 Factor screening\nInspect the levels of each factor carefully. Make sure the factor levels of each variable are correct. Examine spelling and look for additional unwanted levels. For example, you wouldn’t want to have the following levels for sex: male, mmale, female. Obviously, mmale is an incorrectly typed version of male. Scan all the factors in your data for erroneous factor levels. The code below displays the factor levels for sex:\n\n# Screen factors\n## screen\nanalytic_data_survey %&gt;%\n  select(sex) %&gt;%\n  summary()\n\n       sex    \n female  :43  \n male    :49  \n intersex:58  \n\n\nYou can see in the above output there are three levels for sex in this data set: female, male and intersex. You can also see beside each of these labels the number of participants for each category.\nNotice the order of the factor levels: female, male, and intersex. This will be the order they appear in graphs and tables. We might want another order. If we did want another order, we could use the code below to establish the custom order for graphs and tables: female, intersex, male. Of course, you can use any order you want that makes sense for the context and your research question.\n\n## change to desired order\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(sex = fct_relevel(sex,\n                           \"female\",\n                           \"intersex\",\n                           \"male\"))\n\n\n\n2.5.3.4 Numeric screening\nFor numeric variables, it’s important to find and remove impossible values. We only have year_of_birth as a numeric column - so we can easily check for nonsense values with the code below:\n\n# Screen numeric variables\nanalytic_data_survey %&gt;%\n  select(year_of_birth) %&gt;%\n  skim()\n\n\n\n  skim_variable n_missing    mean    sd   p0  p50 p100\n1 year_of_birth         0 1973.88 20.06 1940 1970 2010\n\n\n\n\n2.5.3.5 Item values from labels\nRecall that when we obtained our data from Qualtrics we selected “Use Choice Text”. That means that, as desired, we didn’t get values for our Likert items - we obtained labels. Now we need to switch the Likert responses to numeric values. The advantage of handling our data in this way is that anyone examining our data and code in an open access repository can see exactly what options survey participants were provided with for each question.\nBut prior to beginning check out the type for each Likert column below using the glimpse() command notice that are all of type “chr”.\n\nanalytic_data_survey %&gt;% glimpse()\n\nRows: 150\nColumns: 26\n$ duration_in_seconds  &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262, …\n$ year_of_birth        &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970, 1…\n$ sex                  &lt;fct&gt; female, female, female, male, intersex, intersex,…\n$ aff_com1_likert7     &lt;chr&gt; \"Slightly Agree\", \"Neither Agree nor Disagree\", \"…\n$ aff_com2_likert7     &lt;chr&gt; \"Slightly Agree\", \"Slightly Disagree\", \"Neither A…\n$ aff_com3_likert7rev  &lt;chr&gt; \"Strongly Disagree\", \"Neither Agree nor Disagree\"…\n$ aff_com4_likert7rev  &lt;chr&gt; \"Moderately Disagree\", \"Strongly Agree\", \"Moderat…\n$ aff_com5_likert7rev  &lt;chr&gt; \"Strongly Disagree\", \"Neither Agree nor Disagree\"…\n$ aff_com6_likert7     &lt;chr&gt; \"Moderately Agree\", \"Strongly Agree\", \"Strongly D…\n$ contin_com1_likert7  &lt;chr&gt; \"Strongly Agree\", \"Neither Agree nor Disagree\", \"…\n$ contin_com2_likert7  &lt;chr&gt; \"Slightly Agree\", \"Slightly Agree\", \"Slightly Dis…\n$ contin_com3_likert7  &lt;chr&gt; \"Strongly Disagree\", \"Slightly Disagree\", \"Strong…\n$ contin_com4_likert7  &lt;chr&gt; \"Moderately Agree\", \"Neither Agree nor Disagree\",…\n$ contin_com5_likert7  &lt;chr&gt; \"Slightly Agree\", \"Slightly Agree\", \"Strongly Dis…\n$ contin_com6_likert7  &lt;chr&gt; \"Moderately Disagree\", \"Moderately Disagree\", \"St…\n$ norm_com1_likert7rev &lt;chr&gt; \"Neither Agree nor Disagree\", \"Slightly Disagree\"…\n$ norm_com2_likert7    &lt;chr&gt; \"Moderately Disagree\", \"Moderately Agree\", \"Stron…\n$ norm_com3_likert7    &lt;chr&gt; \"Neither Agree nor Disagree\", \"Neither Agree nor …\n$ norm_com4_likert7    &lt;chr&gt; \"Moderately Disagree\", \"Moderately Disagree\", \"St…\n$ norm_com5_likert7    &lt;chr&gt; \"Strongly Disagree\", \"Strongly Disagree\", \"Strong…\n$ norm_com6_likert7    &lt;chr&gt; \"Strongly Agree\", \"Strongly Disagree\", \"Moderatel…\n$ job_aff1_likert5     &lt;chr&gt; \"Strongly Agree\", \"Strongly Agree\", \"Neutral\", \"S…\n$ job_aff2_likert5     &lt;chr&gt; \"Strongly Disagree\", \"Strongly Agree\", \"Strongly …\n$ job_aff3_likert5     &lt;chr&gt; \"Neutral\", \"Strongly Disagree\", \"Disagree\", \"Stro…\n$ job_aff4_likert5     &lt;chr&gt; \"Disagree\", \"Strongly Agree\", \"Agree\", \"Strongly …\n$ participant_id       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n\n\nWhen you have type chr for a column the computer sees the content of each column as text that is different for each participant. It doesn’t even realize that two people who both responded “Slightly Agree” responded the same way. It sees every response in the column as unique. Check that out for the aff_com1_likert7 item.\n\nanalytic_data_survey %&gt;% \n    select(aff_com1_likert7) %&gt;%\n    summary()\n\n aff_com1_likert7  \n Length:150        \n Class :character  \n Mode  :character  \n\n\n\n2.5.3.5.1 Commitment Items\nTo convert a column from a character column to factor column we need know the exact labels used in that column. We can obtain those with the code below. In this code, we use just one item aff_com1_likert7. We determine the response options for that one item and will apply them to all the commitment items. We use the pull() command to obtain all the participant responses from the aff_com1_likert7. column. Then we use the unique() command to give use just one instance of each response.\n\n# Convert Commitment items to numeric  values\n## Check levels for a likert7 item\nanalytic_data_survey %&gt;%\n  pull(aff_com1_likert7) %&gt;%\n  unique()\n\n[1] \"Slightly Agree\"             \"Neither Agree nor Disagree\"\n[3] \"Moderately Disagree\"        \"Strongly Agree\"            \n[5] \"Strongly Disagree\"          \"Moderately Agree\"          \n[7] \"Slightly Disagree\"         \n\n\nNow that we know the labels used in that column (and all the commitment columns that end in likert7) we create an ordered version of those labels with the code below. I copied and pasted the text (e.g., “Strongly Disagree”) from the above output to avoid typos.\n\n## write code to create ordered factor labels/levels\nlikert7_factor &lt;- c(\"Strongly Disagree\",\n                    \"Moderately Disagree\",\n                    \"Slightly Disagree\",\n                    \"Neither Agree nor Disagree\",\n                    \"Slightly Agree\",\n                    \"Moderately Agree\",\n                    \"Strongly Agree\")\n\nNow we turn each column of text (i.e., type chr) into a factor column using the factor levels/labels we created:\n\n## assign factor levels\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(.cols = contains(\"likert7\"), \n                .fns = ~ factor(.x, levels = likert7_factor)))\n\nIn this code we use the mutate() command to modify columns. We use the across() command to have the single mutate command apply to several columns. Within the across() command we use contains(“likert7”) to apply the mutate() command only to columns with likert7 in the name. You can see why column naming conventions are so important! Next, within the across() command, we specify .fns. This indicate the function/command that will apply to the columns selected. The ~ before “factor” just warns the computer that what comes next is a function/command name. The factor() command is what will be applied to the columns. The .x within the factor command is a placeholder for each column name that will be obtained by the previous contains() command.\nAfter this mutate() command is used you can see the columns with likert7 in the name are now factors.\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 26\n$ duration_in_seconds  &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262, …\n$ year_of_birth        &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970, 1…\n$ sex                  &lt;fct&gt; female, female, female, male, intersex, intersex,…\n$ aff_com1_likert7     &lt;fct&gt; Slightly Agree, Neither Agree nor Disagree, Moder…\n$ aff_com2_likert7     &lt;fct&gt; Slightly Agree, Slightly Disagree, Neither Agree …\n$ aff_com3_likert7rev  &lt;fct&gt; Strongly Disagree, Neither Agree nor Disagree, Mo…\n$ aff_com4_likert7rev  &lt;fct&gt; Moderately Disagree, Strongly Agree, Moderately A…\n$ aff_com5_likert7rev  &lt;fct&gt; Strongly Disagree, Neither Agree nor Disagree, Mo…\n$ aff_com6_likert7     &lt;fct&gt; Moderately Agree, Strongly Agree, Strongly Disagr…\n$ contin_com1_likert7  &lt;fct&gt; Strongly Agree, Neither Agree nor Disagree, Stron…\n$ contin_com2_likert7  &lt;fct&gt; Slightly Agree, Slightly Agree, Slightly Disagree…\n$ contin_com3_likert7  &lt;fct&gt; Strongly Disagree, Slightly Disagree, Strongly Ag…\n$ contin_com4_likert7  &lt;fct&gt; Moderately Agree, Neither Agree nor Disagree, Sli…\n$ contin_com5_likert7  &lt;fct&gt; Slightly Agree, Slightly Agree, Strongly Disagree…\n$ contin_com6_likert7  &lt;fct&gt; Moderately Disagree, Moderately Disagree, Strongl…\n$ norm_com1_likert7rev &lt;fct&gt; Neither Agree nor Disagree, Slightly Disagree, Mo…\n$ norm_com2_likert7    &lt;fct&gt; Moderately Disagree, Moderately Agree, Strongly D…\n$ norm_com3_likert7    &lt;fct&gt; Neither Agree nor Disagree, Neither Agree nor Dis…\n$ norm_com4_likert7    &lt;fct&gt; Moderately Disagree, Moderately Disagree, Strongl…\n$ norm_com5_likert7    &lt;fct&gt; Strongly Disagree, Strongly Disagree, Strongly Di…\n$ norm_com6_likert7    &lt;fct&gt; Strongly Agree, Strongly Disagree, Moderately Dis…\n$ job_aff1_likert5     &lt;chr&gt; \"Strongly Agree\", \"Strongly Agree\", \"Neutral\", \"S…\n$ job_aff2_likert5     &lt;chr&gt; \"Strongly Disagree\", \"Strongly Agree\", \"Strongly …\n$ job_aff3_likert5     &lt;chr&gt; \"Neutral\", \"Strongly Disagree\", \"Disagree\", \"Stro…\n$ job_aff4_likert5     &lt;chr&gt; \"Disagree\", \"Strongly Agree\", \"Agree\", \"Strongly …\n$ participant_id       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n\n\nNow examine aff_com1_likert7 again - you can see it has levels:\n\nanalytic_data_survey %&gt;% \n    select(aff_com1_likert7) %&gt;%\n    summary()\n\n                   aff_com1_likert7\n Strongly Disagree         :21     \n Moderately Disagree       :21     \n Slightly Disagree         :21     \n Neither Agree nor Disagree:18     \n Slightly Agree            :28     \n Moderately Agree          :21     \n Strongly Agree            :20     \n\n\nThe second step in our conversion process is converting each column from a factor to the numeric value associated with the factor level (i.e. Strongly Disagree becomes 1). We do so with the code below:\n\n## covert factor levels to numeric values\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(.cols = contains(\"likert7\"), \n                .fns = as.numeric))\n\nYou can see there are numeric values with the code below. Notice the column types for likert7 items is now dbl (short for double - a type of high precision number.)\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 26\n$ duration_in_seconds  &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262, …\n$ year_of_birth        &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970, 1…\n$ sex                  &lt;fct&gt; female, female, female, male, intersex, intersex,…\n$ aff_com1_likert7     &lt;dbl&gt; 5, 4, 2, 7, 1, 6, 6, 2, 4, 2, 5, 4, 7, 3, 1, 7, 3…\n$ aff_com2_likert7     &lt;dbl&gt; 5, 3, 4, 2, 6, 7, 2, 3, 2, 7, 3, 4, 4, 1, 6, 2, 5…\n$ aff_com3_likert7rev  &lt;dbl&gt; 1, 4, 2, 5, 7, 2, 6, 3, 5, 4, 3, 3, 2, 2, 6, 2, 7…\n$ aff_com4_likert7rev  &lt;dbl&gt; 2, 7, 6, 6, 3, 5, 7, 6, 7, 2, 7, 2, 5, 6, 1, 4, 4…\n$ aff_com5_likert7rev  &lt;dbl&gt; 1, 4, 6, 5, 3, 7, 5, 7, 5, 5, 4, 5, 3, 1, 3, 2, 4…\n$ aff_com6_likert7     &lt;dbl&gt; 6, 7, 1, 7, 5, 6, 5, 7, 4, 2, 7, 7, 5, 3, 2, 4, 4…\n$ contin_com1_likert7  &lt;dbl&gt; 7, 4, 1, 3, 2, 1, 1, 6, 7, 3, 6, 2, 2, 5, 5, 3, 5…\n$ contin_com2_likert7  &lt;dbl&gt; 5, 5, 3, 2, 7, 6, 1, 3, 5, 2, 4, 5, 1, 6, 6, 6, 2…\n$ contin_com3_likert7  &lt;dbl&gt; 1, 3, 7, 7, 5, 2, 7, 2, 7, 1, 4, 2, 4, 5, 6, 1, 6…\n$ contin_com4_likert7  &lt;dbl&gt; 6, 4, 3, 7, 7, 5, 4, 5, 3, 2, 2, 4, 2, 7, 3, 7, 5…\n$ contin_com5_likert7  &lt;dbl&gt; 5, 5, 1, 4, 4, 6, 5, 5, 5, 2, 5, 6, 3, 5, 2, 7, 6…\n$ contin_com6_likert7  &lt;dbl&gt; 2, 2, 1, 4, 7, 7, 6, 6, 4, 5, 2, 5, 5, 5, 5, 5, 3…\n$ norm_com1_likert7rev &lt;dbl&gt; 4, 3, 6, 3, 3, 6, 5, 7, 3, 7, 5, 1, 5, 3, 5, 4, 2…\n$ norm_com2_likert7    &lt;dbl&gt; 2, 6, 1, 5, 3, 2, 3, 1, 7, 1, 1, 6, 6, 6, 7, 6, 4…\n$ norm_com3_likert7    &lt;dbl&gt; 4, 4, 7, 3, 1, 1, 4, 3, 3, 5, 3, 5, 2, 3, 2, 3, 1…\n$ norm_com4_likert7    &lt;dbl&gt; 2, 2, 1, 6, 4, 6, 1, 1, 5, 5, 5, 3, 2, 3, 3, 5, 5…\n$ norm_com5_likert7    &lt;dbl&gt; 1, 1, 1, 5, 7, 4, 3, 6, 4, 4, 1, 3, 3, 1, 6, 1, 7…\n$ norm_com6_likert7    &lt;dbl&gt; 7, 1, 2, 4, 6, 6, 1, 4, 6, 2, 1, 4, 1, 5, 6, 3, 4…\n$ job_aff1_likert5     &lt;chr&gt; \"Strongly Agree\", \"Strongly Agree\", \"Neutral\", \"S…\n$ job_aff2_likert5     &lt;chr&gt; \"Strongly Disagree\", \"Strongly Agree\", \"Strongly …\n$ job_aff3_likert5     &lt;chr&gt; \"Neutral\", \"Strongly Disagree\", \"Disagree\", \"Stro…\n$ job_aff4_likert5     &lt;chr&gt; \"Disagree\", \"Strongly Agree\", \"Agree\", \"Strongly …\n$ participant_id       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n\n\nIf you run the summary() command on the aff_com1_likert7 you see we have values now.\n\nanalytic_data_survey %&gt;% \n    select(aff_com1_likert7) %&gt;%\n    summary()\n\n aff_com1_likert7\n Min.   :1.000   \n 1st Qu.:2.000   \n Median :4.000   \n Mean   :4.027   \n 3rd Qu.:6.000   \n Max.   :7.000   \n\n\nSide note: We did a lot of explaining as we went through the steps above. But it’s not as long as it seems. Some of the steps can even be combined. See the concise version of the code we used repeated below:\n\n# Convert Commitment items to numeric  values\n## Check levels for a likert7 item\nanalytic_data_survey %&gt;%\n  pull(aff_com1_likert7) %&gt;%\n  unique()\n\n## write code to create ordered factor labels/levels\nlikert7_factor &lt;- c(\"Strongly Disagree\",\n                    \"Moderately Disagree\",\n                    \"Slightly Disagree\",\n                    \"Neither Agree nor Disagree\",\n                    \"Slightly Agree\",\n                    \"Moderately Agree\",\n                    \"Strongly Agree\")\n\n\n## assign factor levels and then covert to numeric\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(.cols = contains(\"likert7\"), \n                .fns = ~ factor(.x, levels = likert7_factor))) %&gt;%\n  mutate(across(.cols = contains(\"likert7\"), \n                .fns = as.numeric))\n\n\n\n2.5.3.5.2 Job Satisfaction Conversion\nWe’ll skip all the explanation steps for Job Satisfaction and just show you the essentials. First, get the labels for the items:\n\n# Convert Job Satisfaction items to numeric  values\n## Check levels for a likert5 item\nanalytic_data_survey %&gt;%\n  pull(job_aff1_likert5) %&gt;%\n  unique()\n\n[1] \"Strongly Agree\"    \"Neutral\"           \"Strongly Disagree\"\n[4] \"Agree\"             \"Disagree\"         \n\n\nSecond, create the ordered factor labels:\n\n## write code to create ordered factor labels/levels\nlikert5_factor &lt;- c(\"Strongly Disagree\",\n                    \"Disagree\",\n                    \"Neutral\",\n                    \"Agree\",\n                    \"Strongly Agree\")\n\nThird, convert the columns to a factor and then to numbers.\n\n## assign factor levels and then covert to numeric\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(.cols = contains(\"likert5\"), \n                .fns = ~ factor(.x, levels = likert5_factor))) %&gt;%\n  mutate(across(.cols = contains(\"likert5\"), \n                .fns = as.numeric))\n\n\n\n\n2.5.3.6 Scale scores\nFor each person, scale scores involve averaging scores from several items to create an overall score. The first step in the creation of scales is correcting the values of any reverse-keyed items.\n\n2.5.3.6.1 Reverse-key items\nA complete discussion of the logic for flipping reverse-key (i.e., reverse worded) items is provide the previous chapter in the Scale Scores section. We use that logic in the script below.\n\n# Reverse key items\n## Reverse key likert7 items\nanalytic_data_survey &lt;- analytic_data_survey %&gt;% \n  mutate(8 - across(.cols = ends_with(\"_likert7rev\")) ) %&gt;% \n  rename_with(.fn = str_replace,\n              .cols = ends_with(\"_likert7rev\"),\n              pattern = \"_likert7rev\",\n              replacement = \"_likert7\")\n\nYou can see that are all keyed in the right direction now.\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 26\n$ duration_in_seconds &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262, 3…\n$ year_of_birth       &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970, 19…\n$ sex                 &lt;fct&gt; female, female, female, male, intersex, intersex, …\n$ aff_com1_likert7    &lt;dbl&gt; 5, 4, 2, 7, 1, 6, 6, 2, 4, 2, 5, 4, 7, 3, 1, 7, 3,…\n$ aff_com2_likert7    &lt;dbl&gt; 5, 3, 4, 2, 6, 7, 2, 3, 2, 7, 3, 4, 4, 1, 6, 2, 5,…\n$ aff_com3_likert7    &lt;dbl&gt; 7, 4, 6, 3, 1, 6, 2, 5, 3, 4, 5, 5, 6, 6, 2, 6, 1,…\n$ aff_com4_likert7    &lt;dbl&gt; 6, 1, 2, 2, 5, 3, 1, 2, 1, 6, 1, 6, 3, 2, 7, 4, 4,…\n$ aff_com5_likert7    &lt;dbl&gt; 7, 4, 2, 3, 5, 1, 3, 1, 3, 3, 4, 3, 5, 7, 5, 6, 4,…\n$ aff_com6_likert7    &lt;dbl&gt; 6, 7, 1, 7, 5, 6, 5, 7, 4, 2, 7, 7, 5, 3, 2, 4, 4,…\n$ contin_com1_likert7 &lt;dbl&gt; 7, 4, 1, 3, 2, 1, 1, 6, 7, 3, 6, 2, 2, 5, 5, 3, 5,…\n$ contin_com2_likert7 &lt;dbl&gt; 5, 5, 3, 2, 7, 6, 1, 3, 5, 2, 4, 5, 1, 6, 6, 6, 2,…\n$ contin_com3_likert7 &lt;dbl&gt; 1, 3, 7, 7, 5, 2, 7, 2, 7, 1, 4, 2, 4, 5, 6, 1, 6,…\n$ contin_com4_likert7 &lt;dbl&gt; 6, 4, 3, 7, 7, 5, 4, 5, 3, 2, 2, 4, 2, 7, 3, 7, 5,…\n$ contin_com5_likert7 &lt;dbl&gt; 5, 5, 1, 4, 4, 6, 5, 5, 5, 2, 5, 6, 3, 5, 2, 7, 6,…\n$ contin_com6_likert7 &lt;dbl&gt; 2, 2, 1, 4, 7, 7, 6, 6, 4, 5, 2, 5, 5, 5, 5, 5, 3,…\n$ norm_com1_likert7   &lt;dbl&gt; 4, 5, 2, 5, 5, 2, 3, 1, 5, 1, 3, 7, 3, 5, 3, 4, 6,…\n$ norm_com2_likert7   &lt;dbl&gt; 2, 6, 1, 5, 3, 2, 3, 1, 7, 1, 1, 6, 6, 6, 7, 6, 4,…\n$ norm_com3_likert7   &lt;dbl&gt; 4, 4, 7, 3, 1, 1, 4, 3, 3, 5, 3, 5, 2, 3, 2, 3, 1,…\n$ norm_com4_likert7   &lt;dbl&gt; 2, 2, 1, 6, 4, 6, 1, 1, 5, 5, 5, 3, 2, 3, 3, 5, 5,…\n$ norm_com5_likert7   &lt;dbl&gt; 1, 1, 1, 5, 7, 4, 3, 6, 4, 4, 1, 3, 3, 1, 6, 1, 7,…\n$ norm_com6_likert7   &lt;dbl&gt; 7, 1, 2, 4, 6, 6, 1, 4, 6, 2, 1, 4, 1, 5, 6, 3, 4,…\n$ job_aff1_likert5    &lt;dbl&gt; 5, 5, 3, 1, 1, 3, 4, 4, 1, 4, 3, 5, 5, 1, 2, 1, 3,…\n$ job_aff2_likert5    &lt;dbl&gt; 1, 5, 5, 2, 3, 1, 3, 3, 5, 5, 4, 3, 1, 1, 5, 3, 5,…\n$ job_aff3_likert5    &lt;dbl&gt; 3, 1, 2, 5, 5, 3, 3, 1, 5, 2, 3, 4, 5, 4, 2, 3, 3,…\n$ job_aff4_likert5    &lt;dbl&gt; 2, 5, 4, 1, 5, 3, 1, 3, 3, 5, 2, 5, 2, 3, 1, 5, 5,…\n$ participant_id      &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…\n\n\nNone of the job satisfaction items were reverse-keyed.\n\n\n2.5.3.6.2 Creating scores\nImportant: Take note of how we name the scale variables (e.g., affective_commitment) with a different prefix than the items (e..g, aff_com1_likert7). This allows us to delete the items (i.e., columns that start with aff_com) but not the final scale score (i.e., a column starts with affective_commitment). This example again illustrates how carefully you need to think about your column and scale naming conventions.\n\n# Create scale scores\n## mutate commands create scale scores\n## select commands with \"-\" remove items after scale creation\nanalytic_data_survey &lt;- analytic_data_survey %&gt;% \n  rowwise() %&gt;% \n  mutate(affective_commitment = mean(c_across(starts_with(\"aff_com\")),\n                                     na.rm = TRUE)) %&gt;%\n  mutate(continuance_commitment = mean(c_across(starts_with(\"contin_com\")),\n                                       na.rm = TRUE)) %&gt;%\n  mutate(normative_commitment = mean(c_across(starts_with(\"norm_com\")),\n                                     na.rm = TRUE)) %&gt;%\n  mutate(job_satisfaction = mean(c_across(starts_with(\"job_aff\")),\n                                 na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  select(-starts_with(\"aff_com\")) %&gt;%\n  select(-starts_with(\"contin_com\")) %&gt;%\n  select(-starts_with(\"norm_com\")) %&gt;%\n  select(-starts_with(\"job_aff\")) \n\nWe can see our data now has the columns: affective_commitment, continuance_commitment, normative_commitment, job satisfaction.\nAs well, all of the items used to create the scale scores have been removed.\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 8\n$ duration_in_seconds    &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262…\n$ year_of_birth          &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970,…\n$ sex                    &lt;fct&gt; female, female, female, male, intersex, interse…\n$ participant_id         &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ affective_commitment   &lt;dbl&gt; 6.000000, 3.833333, 2.833333, 4.000000, 3.83333…\n$ continuance_commitment &lt;dbl&gt; 4.333333, 3.833333, 2.666667, 4.500000, 5.33333…\n$ normative_commitment   &lt;dbl&gt; 3.333333, 3.166667, 2.333333, 4.666667, 4.33333…\n$ job_satisfaction       &lt;dbl&gt; 2.75, 4.00, 3.50, 2.25, 3.50, 2.50, 2.75, 2.75,…\n\n\n\n\n2.5.3.6.3 Removing fast responders\nYou might be interested in removing people who responded to the survey too quickly. Notice two things when we glimpse the ananlytic_data_survey data below.\n\nglimpse(analytic_data_survey)\n\nRows: 150\nColumns: 8\n$ duration_in_seconds    &lt;dbl&gt; 244, 134, 237, 110, 151, 92, 393, 165, 315, 262…\n$ year_of_birth          &lt;dbl&gt; 1961, 2006, 2008, 1985, 1953, 1957, 1998, 1970,…\n$ sex                    &lt;fct&gt; female, female, female, male, intersex, interse…\n$ participant_id         &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ affective_commitment   &lt;dbl&gt; 6.000000, 3.833333, 2.833333, 4.000000, 3.83333…\n$ continuance_commitment &lt;dbl&gt; 4.333333, 3.833333, 2.666667, 4.500000, 5.33333…\n$ normative_commitment   &lt;dbl&gt; 3.333333, 3.166667, 2.333333, 4.666667, 4.33333…\n$ job_satisfaction       &lt;dbl&gt; 2.75, 4.00, 3.50, 2.25, 3.50, 2.50, 2.75, 2.75,…\n\n\nFirst, there are 150 rows so there are 150 participants in this data set. Second, there is a column called duration_in_seconds. You can use this column to remove people who responded too quickly. For example, you might decide that anyone who responded in less than 120 seconds (i.e., 2 minutes) should be removed from the data set. You can do so with the code below:\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  filter(duration_in_seconds &gt;= 120)\n\nglimpse(analytic_data_survey)\n\nRows: 129\nColumns: 8\n$ duration_in_seconds    &lt;dbl&gt; 244, 134, 237, 151, 393, 165, 315, 262, 370, 20…\n$ year_of_birth          &lt;dbl&gt; 1961, 2006, 2008, 1953, 1998, 1970, 1983, 1959,…\n$ sex                    &lt;fct&gt; female, female, female, intersex, intersex, mal…\n$ participant_id         &lt;fct&gt; 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17…\n$ affective_commitment   &lt;dbl&gt; 6.000000, 3.833333, 2.833333, 3.833333, 3.16666…\n$ continuance_commitment &lt;dbl&gt; 4.333333, 3.833333, 2.666667, 5.333333, 4.00000…\n$ normative_commitment   &lt;dbl&gt; 3.333333, 3.166667, 2.333333, 4.333333, 2.50000…\n$ job_satisfaction       &lt;dbl&gt; 2.75, 4.00, 3.50, 3.50, 2.75, 2.75, 3.50, 4.00,…\n\n\nThis reduces the data set to the 129 people who took at least 2 minutes (i.e., 120 seconds) to complete the survey.\n\n\n\n\n2.5.4 Complete script\nThe complete script script_qualtrics.R for the data file data_qualtrics.csv is presented below.\n\n# Date: YYYY-MM-DD\n# Name: your name here\n# Example: Single occasion survey\n# Load data\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(skimr)\n\n# read just the header row to get column names\nsurvey_file &lt;- \"data_qualtrics.csv\"\ncol_names &lt;- names(read_csv(survey_file,\n                            n_max = 0,\n                            show_col_types = FALSE))\n\n# skip the first 3 rows, read data using names from above\nraw_data &lt;- read_csv(survey_file,\n                     col_names = col_names, \n                     skip = 3,\n                     show_col_types = FALSE)\n\n# Qualtrics columns to remove (any_of() ignores names not present)\ncols_to_remove &lt;- c(\"StartDate\",\n                    \"EndDate\",\n                    \"Status\",\n                    \"IPAddress\",\n                    \"Progress\",\n                    \"Finished\",\n                    \"RecordedDate\",\n                    \"ResponseId\",\n                    \"RecipientLastName\",\n                    \"RecipientFirstName\",\n                    \"RecipientEmail\",\n                    \"ExternalReference\",\n                    \"LocationLatitude\",\n                    \"LocationLongitude\",\n                    \"DistributionChannel\",\n                    \"UserLanguage\")\n\n# remove the unwanted Qualtrics columns\nraw_data &lt;- raw_data |&gt; \n  select(!any_of(cols_to_remove))\n\nanalytic_data_survey &lt;- raw_data\n\n# Initial cleaning\n## Convert column names to tidyverse style guide\n## Remove empty rows and columns\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  remove_empty(\"rows\") %&gt;%\n  remove_empty(\"cols\") %&gt;%\n  clean_names()\n\nglimpse(analytic_data_survey)\n\n# Convert variables to factors as needed\n## Convert sex to factor\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(sex = as_factor(sex))\n\n\n## Participant identification to factor\n## Participant identification column must be created first\n## get the number of rows in the data set\nN &lt;- dim(analytic_data_survey)[1] \n\n## create set of factor levels\nparticipant_id_levels &lt;- factor(seq(1, N))\n\n## put the factor levels into a column called participant_id\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(participant_id = participant_id_levels)\n\n# Screen factors\n## screen\nanalytic_data_survey %&gt;%\n  select(sex) %&gt;%\n  summary()\n\n# Check existing levels (a different way than lines above)\nlevels(analytic_data_survey$sex)\n\n## change to desired order\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(sex = fct_relevel(sex,\n                           \"female\",\n                           \"intersex\",\n                           \"male\"))\n\n# Check for unexpected levels\nexpected_sex &lt;- c(\"female\", \"intersex\", \"male\")\nunexpected &lt;- setdiff(levels(analytic_data_survey$sex), expected_sex)\nif (length(unexpected) &gt; 0) {\n  warning(\"Unexpected sex levels found: \", paste(unexpected, collapse = \", \"))\n}\n\n\n# Screen numeric variables\nanalytic_data_survey %&gt;%\n  select(year_of_birth) %&gt;%\n  skim()\n\n \n# Convert Commitment items to numeric  values\n## Check levels for a likert7 item\nanalytic_data_survey %&gt;%\n  pull(aff_com1_likert7) %&gt;%\n  unique()\n\n## Define word-to-number mapping 7-\nlikert7_recode &lt;- c(\n  \"Strongly Disagree\" = 1,\n  \"Moderately Disagree\" = 2,\n  \"Slightly Disagree\" = 3,\n  \"Neither Agree nor Disagree\" = 4,\n  \"Slightly Agree\" = 5,\n  \"Moderately Agree\" = 6,\n  \"Strongly Agree\" = 7\n)\n\n## Convert text responses to numeric values\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(\n    .cols = contains(\"likert7\"), \n    .fns = ~ likert7_recode[.x]\n  ))\n\n\n\n# Convert Job Satisfaction items to numeric  values\n## Check levels for a likert5 item\nanalytic_data_survey %&gt;%\n  pull(job_aff1_likert5) %&gt;%\n  unique()\n\n## Define word-to-number mapping 5-point scale\nlikert5_recode &lt;- c(\n  \"Strongly Disagree\" = 1,\n  \"Disagree\" = 2,\n  \"Neutral\" = 3,\n  \"Agree\" = 4,\n  \"Strongly Agree\" = 5\n)\n\n## Convert text responses to numeric values\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(\n    .cols = contains(\"likert5\"), \n    .fns = ~ likert5_recode[.x]\n  ))\n\n\n# Reverse key items\n## Reverse key likert7 items\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(\n    .cols = ends_with(\"_likert7rev\"),\n    .fns = ~ (7 + 1) - .x\n  )) %&gt;%\n  rename_with(\n    .fn = ~ str_replace(.x, \"_likert7rev\", \"_likert7\"),\n    .cols = ends_with(\"_likert7rev\")\n  )\n\n\n## No likert5 items are reverse-keyed but if they were\n## You would adapt the code above replacing 8 (one higher than 7) to 6 (one higher than 5)\n\n\n# Create scale scores\n## mutate commands create scale scores\n## select commands with \"-\" remove items after scale creation\nanalytic_data_survey &lt;- analytic_data_survey %&gt;% \n  rowwise() %&gt;% \n  mutate(affective_commitment = mean(c_across(starts_with(\"aff_com\")),\n                                     na.rm = TRUE)) %&gt;%\n  mutate(continuance_commitment = mean(c_across(starts_with(\"contin_com\")),\n                                       na.rm = TRUE)) %&gt;%\n  mutate(normative_commitment = mean(c_across(starts_with(\"norm_com\")),\n                                     na.rm = TRUE)) %&gt;%\n  mutate(job_satisfaction = mean(c_across(starts_with(\"job_aff\")),\n                                 na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  select(-starts_with(\"aff_com\")) %&gt;%\n  select(-starts_with(\"contin_com\")) %&gt;%\n  select(-starts_with(\"norm_com\")) %&gt;%\n  select(-starts_with(\"job_aff\")) \n\n\nglimpse(analytic_data_survey)\n\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  filter(duration_in_seconds &gt;= 120)\n\nglimpse(analytic_data_survey)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Qualtrics</span>"
    ]
  },
  {
    "objectID": "qualtrics.html#extra-help",
    "href": "qualtrics.html#extra-help",
    "title": "2  Qualtrics",
    "section": "2.6 Extra Help",
    "text": "2.6 Extra Help\n\n2.6.1 Qualtrics\n\nUniversity of Guelph Qualtrics Login page\nUniversity of Guelph Qualtrics FAQ page\n\n\n\n2.6.2 Surveys\n\nDillman Method book can be found here\nDuke University Survey site\n\n\n\n\n\nMeyer, John P, Natalie J Allen, and Catherine A Smith. 1993. “Commitment to Organizations and Occupations: Extension and Test of a Three-Component Conceptualization.” Journal of Applied Psychology 78 (4): 538.\n\n\nThompson, Edmund R, and Florence TT Phua. 2012. “A Brief Index of Affective Job Satisfaction.” Group & Organization Management 37 (3): 275–307.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Qualtrics</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html",
    "href": "data-pipeline.html",
    "title": "3  Data Science Pipelines in R",
    "section": "",
    "text": "3.1 Introduction\nIn the previous chapter, you learned how to read Qualtrics data and prepare it for analysis using a single R script. That approach works well for learning—but as your projects grow more complex, a single script becomes unwieldy. In this tutorial, you’ll learn how to organize your work into a data science pipeline: a series of modular scripts that each handle one specific task.\nRecall we first saw the pipeline in this figure in a previous chapter. Today we will create a series of scripts. Most of these scripts correspond to the “Processing Code” step in the above figure. That is, we have expanded the Processing Code to have its own multi-step pipeline. In this chapter, we walk you through creating that pipeline.\nNote that that data set we use in this chapter is not the same as the one in the previous chapter. The data set for this chapter has been modified to include missing data to illustrate how to evaluate and handle missing data in a pipeline.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#why-use-a-pipeline",
    "href": "data-pipeline.html#why-use-a-pipeline",
    "title": "3  Data Science Pipelines in R",
    "section": "3.2 Why Use a Pipeline?",
    "text": "3.2 Why Use a Pipeline?\nConsider the single-script approach you’ve been using. It might look something like this:\n\n# Everything in one file...\nlibrary(tidyverse)\nlibrary(janitor)\n\n# Import\nraw_data &lt;- read_csv(\"data-qualtrics.csv\", skip = 3)\n\n# Clean\nanalytic_data &lt;- raw_data |&gt;\n  select(-StartDate, -EndDate, ...) |&gt;\n  clean_names()\n\n# Recode Likert scales\n# ... 50 more lines ...\n\n# Create scales\n# ... 30 more lines ...\n\n# Exclusions\n# ... 20 more lines ...\n\n# Analysis\n# ... and so on\n\nThis approach has several problems:\n\nDifficult to debug: When something goes wrong on line 247, finding the cause is tedious.\nHard to modify: Changing one part risks breaking another.\nPoor collaboration: Lab members can’t work on different sections simultaneously.\nNo checkpoints: If you make a mistake, you must re-run everything from scratch.\n\nA pipeline solves these problems by breaking your workflow into discrete, manageable steps.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#the-pipeline-structure",
    "href": "data-pipeline.html#the-pipeline-structure",
    "title": "3  Data Science Pipelines in R",
    "section": "3.3 The Pipeline Structure",
    "text": "3.3 The Pipeline Structure\nOur data science pipeline uses a specific file and folder structure to keep everything organized. Here’s an overview of the structure. We will recreate this structure in this chapter. You will create each file and folder as we go. Then you will paste the code for each step into the appropriate script file. Alternatively, you can download the completed project from the associated files at the top of this page.\nMy Project/\n├── 00-script-master.R      # Runs the entire pipeline     (Preprocessing Code)\n├── 01-import.R             # Load and initial setup       (Preprocessing Code)\n├── 02-clean-recode.R       # Factors and Likert recoding  (Preprocessing Code)\n├── 03-missing-data.R       # Evaluate missingness         (Preprocessing Code)\n├── 04-create-scales.R      # Compute scale scores         (Preprocessing Code)\n├── 05-exclusions.R         # Apply exclusion criteria     (Preprocessing Code)\n├── 06-analysis-wrapper.R   # Analysis and visualization   (Analytic Code)\n├── 07-analysis.R           # Analysis and visualization   (Analytic Code)\n├── data-raw/                # Folder: Original data (NEVER modify)\n├── data-interim/            # Folder: Checkpoint files between steps\n├── data-processed/          # Folder: Final analytic dataset\n└── output/                  # Folder: Analysis output, tables, figures, etc.\nThis structure follows the principle of separating raw data, interim data, processed data, and output. Each script reads from the previous step and writes to the next.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#output-naming-conventions",
    "href": "data-pipeline.html#output-naming-conventions",
    "title": "3  Data Science Pipelines in R",
    "section": "3.4 Output naming conventions",
    "text": "3.4 Output naming conventions\nWe use clear, consistent naming conventions for files we create. For examples figures will begin with figure-, tables with table-, and data files with data-. This makes it easy to identify file types at a glance.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#create-required-folders",
    "href": "data-pipeline.html#create-required-folders",
    "title": "3  Data Science Pipelines in R",
    "section": "3.5 Create Required Folders",
    "text": "3.5 Create Required Folders\nBegin by creating the necessary folders in your project directory. You can do this manually or with R code. But we will begin mannually for clarity.\nFirst, create a folder with the name of your project. This folder might be called “My-Thesis” or something similar. Today we will call this folder “My Project”.\nSecond, create empty R script files inside “My Project” folder named as follows:\n\n00-script-master.R\n01-import.R\n02-clean-recode.R\n03-missing-data.R\n04-create-scales.R\n05-exclusions.R\n06-analysis-wrapper.R\n07-analysis.R\n\nThird, inside “My Project”, create the following folders:\n\ndata-raw/\ndata-interim/\ndata-processed/\noutput/\n\nNext, place your raw data file (e.g., data-qualtrics.csv) inside the data-raw/ folder. This file should never be modified.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#the-master-script",
    "href": "data-pipeline.html#the-master-script",
    "title": "3  Data Science Pipelines in R",
    "section": "3.6 The Master Script",
    "text": "3.6 The Master Script\nThe master script is the conductor of your pipeline. It loads all necessary packages once, then calls each step in order.\n\n# 00-script-master.R\n\n# Date: 2026-01-15 (Use YYYY-MM-DD format)\n# Name: [Your Name]\n# Purpose: Master - Runs all data preparation steps in order\n\n# 1. Setup Environment ----------------------------------------------------\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(skimr)\nlibrary(naniar) # Package for missing data visualization\n\n# Clear memory to ensure reproducibility\nrm(list = ls()) \n\n# Create directories if they don't exist (helpful for students)\nif(!dir.exists(\"data-interim\")) dir.create(\"data-interim\")\nif(!dir.exists(\"data-processed\")) dir.create(\"data-processed\")\nif(!dir.exists(\"output\")) dir.create(\"output\")\n\n\n# 2. Execute Pipeline -----------------------------------------------------\n\n# Step 1: Import and Anonymize\nmessage(\"--- Running Step 1: Import ---\")\nsource(\"01-import.R\", echo = TRUE)\n\n# Step 2: Cleaning and Recoding\nmessage(\"--- Running Step 2: Cleaning ---\")\nsource(\"02-clean-recode.R\", echo = TRUE)\n\n# Step 3: Evaluate missing data\nmessage(\"--- Running Step 3: Evaluate missing data ---\")\nsource(\"03-missing-data.R\", echo = TRUE)\n\n# Step 4: Create scales\nmessage(\"--- Running Step 4: Create scales ---\")\nsource(\"04-create-scales.R\", echo = TRUE)\n\n# Step 5: Exclusions\nmessage(\"--- Running Step 5: Excluding participants ---\")\nsource(\"05-Exclusions.R\", echo = TRUE)\n\n# Step 6: Analysis Wraper\nmessage(\"--- Running Step 6: Analysis and Visualization ---\")\nsource(\"06-analysis-wrapper.R\", echo = TRUE)\n\n\nmessage(\"--- Pipeline Complete! ---\")\n\nNotice several important features:\n\nsource() with echo = TRUE shows you what each script is doing\nmessage() calls provide clear progress indicators\nAll packages are loaded once at the beginning",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-1-import",
    "href": "data-pipeline.html#step-1-import",
    "title": "3  Data Science Pipelines in R",
    "section": "3.7 Step 1: Import",
    "text": "3.7 Step 1: Import\nThe import script handles loading raw data and initial cleanup. This is essentially the first part of your single script, isolated:\n\n# 01-import.R\n\n# Step 1: Import and Initial Setup\n\n# Load Data ---------------------------------------------------------------\nsurvey_file &lt;- \"data-raw/data-qualtrics.csv\"\n\n# Read header row for names\ncol_names &lt;- names(read_csv(survey_file, n_max = 0, show_col_types = FALSE))\n\n# Read data (skipping Qualtrics header rows 2 and 3)\nraw_data &lt;- read_csv(survey_file, \n                     col_names = col_names, \n                     skip = 3, \n                     show_col_types = FALSE,\n                     na = c(\"\", \"NA\",\"999\")) # Treat blank cells as NA\n                    \n\n# Select Columns ----------------------------------------------------------\n# NOTE: We comment out \"Duration\" so we can use it for exclusions later!\ncols_to_remove &lt;- c(\"StartDate\", \"EndDate\", \"Status\", \"IPAddress\", \"Progress\",\n                    \"Finished\", \"RecordedDate\", \"ResponseId\", \"RecipientLastName\",\n                    \"RecipientFirstName\", \"RecipientEmail\", \"ExternalReference\",\n                    \"LocationLatitude\", \"LocationLongitude\", \"DistributionChannel\",\n                    \"UserLanguage\")\n\nanalytic_data_survey &lt;- raw_data |&gt; \n  select(!any_of(cols_to_remove)) |&gt; \n  clean_names() |&gt;        \n  remove_empty(\"rows\") |&gt; \n  remove_empty(\"cols\")\n\n# Create Participant ID ---------------------------------------------------\n# Best practice: Create ID immediately so we can track rows if order changes\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(participant_id = row_number()) %&gt;% \n  relocate(participant_id) # Move to first column\n\n# Save Interim File -------------------------------------------------------\n# We use .rds because it preserves R formatting (unlike CSV)\nwrite_rds(analytic_data_survey, \"data-interim/01-imported.rds\")\n\nKey insight: We save using .rds format, not .csv. The RDS format preserves R data types (factors, dates, etc.) exactly as they are. CSV files lose this information.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-2-clean-and-recode",
    "href": "data-pipeline.html#step-2-clean-and-recode",
    "title": "3  Data Science Pipelines in R",
    "section": "3.8 Step 2: Clean and Recode",
    "text": "3.8 Step 2: Clean and Recode\nThis script handles factor creation and Likert scale recoding:\n\n# 02-clean-recode.R\n\n# Step 2: Cleaning, Factors, and Recoding\n\n# Load Previous Step ------------------------------------------------------\nanalytic_data_survey &lt;- read_rds(\"data-interim/01-imported.rds\")\n\n# Factor Handling ---------------------------------------------------------\n# Convert sex to factor and fix levels\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(sex = as_factor(sex)) %&gt;% \n  mutate(sex = fct_relevel(sex, \"female\", \"intersex\", \"male\"))\n\n# Safety Check: Warn if new genders appear\nexpected_sex &lt;- c(\"female\", \"intersex\", \"male\")\nunexpected &lt;- setdiff(levels(analytic_data_survey$sex), expected_sex)\nif (length(unexpected) &gt; 0) {\n  warning(\"Check Data! Unexpected sex levels found: \", paste(unexpected, collapse = \", \"))\n}\n\n# Likert Recoding (Text to Numbers) ---------------------------------------\n\n# Define Mappings\nlikert7_recode &lt;- c(\n  \"Strongly Disagree\" = 1,\n  \"Moderately Disagree\" = 2,\n  \"Slightly Disagree\" = 3,\n  \"Neither Agree nor Disagree\" = 4,\n  \"Slightly Agree\" = 5,\n  \"Moderately Agree\" = 6,\n  \"Strongly Agree\" = 7\n)\n\nlikert5_recode &lt;- c(\n  \"Strongly Disagree\" = 1,\n  \"Disagree\" = 2,\n  \"Neutral\" = 3, \n  \"Agree\" = 4,\n  \"Strongly Agree\" = 5\n)\n\n# Apply Mappings\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  # Recode 7-point scales\n  mutate(across(\n    .cols = contains(\"likert7\"), \n    .fns = ~ likert7_recode[.x]\n  )) %&gt;%\n  # Recode 5-point scales\n  mutate(across(\n    .cols = contains(\"likert5\"), \n    .fns = ~ likert5_recode[.x]\n  ))\n\n# Reverse Keying ----------------------------------------------------------\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  mutate(across(\n    .cols = ends_with(\"_likert7rev\"),\n    .fns = ~ (7 + 1) - .x\n  )) %&gt;%\n  # Rename columns to remove the 'rev' suffix now that they are fixed\n  rename_with(\n    .fn = ~ str_replace(.x, \"_likert7rev\", \"_likert7\"),\n    .cols = ends_with(\"_likert7rev\")\n  )\n\n# Save Interim File -------------------------------------------------------\nwrite_rds(analytic_data_survey, \"data-interim/02-cleaned.rds\")\n\nNotice how our naming conventions (likert7, likert7rev, likert5) make it possible to apply recoding to multiple columns at once using contains() and ends_with(). This is why consistent naming matters.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-3-missing-data-evaluation",
    "href": "data-pipeline.html#step-3-missing-data-evaluation",
    "title": "3  Data Science Pipelines in R",
    "section": "3.9 Step 3: Missing Data Evaluation",
    "text": "3.9 Step 3: Missing Data Evaluation\nBefore creating scales, we should understand our missing data. This step generates reports but doesn’t modify the data. Importantly, we need to check the reports it creates in the output directory after we run this code. The amount and location of the missing data may suggest a different course of action than the default approach used in these scripts.\n\n# 03-missing-data.R\n\n# Step 3: Missing Data Evaluation \n\n# Load Previous Step ------------------------------------------------------\nanalytic_data_survey &lt;- read_rds(\"data-interim/02-cleaned.rds\")\n\n\n# Define Scale Items ------------------------------------------------------\n# We select the columns relevant for scoring to check them specifically\nscale_items &lt;- analytic_data_survey %&gt;%\n  select(starts_with(\"aff_com\"),\n         starts_with(\"contin_com\"),\n         starts_with(\"norm_com\"),\n         starts_with(\"job_aff\"))\n\n# Missing Data Diagnosis --------------------------------------------------\n\n# 1. Text Report: Items with the most missing data\nmessage(\"--- Missing Data Report by Item ---\")\nmissing_summary &lt;- scale_items %&gt;%\n  miss_var_summary() %&gt;%  # From naniar\n  filter(n_miss &gt; 0) \n\nprint(missing_summary)\nwrite_csv(missing_summary, \"output/data-table-missing-by-item.csv\")\n\n# 2. Text Report: Participants with too much missing data\n# Check if any participant is missing more than 20% of the scale items\nmessage(\"--- Participants with &gt; 20% Missing Data ---\")\nhigh_missing_participants &lt;- analytic_data_survey %&gt;%\n  rowwise() %&gt;%\n  mutate(pct_missing = mean(is.na(c_across(c(starts_with(\"aff_com\"),\n                                             starts_with(\"contin_com\"),\n                                             starts_with(\"norm_com\"),\n                                             starts_with(\"job_aff\"))))) * 100) %&gt;%\n  ungroup() %&gt;%\n  filter(pct_missing &gt; 20) %&gt;%\n  select(participant_id, pct_missing)\n\nprint(high_missing_participants)\nwrite_csv(high_missing_participants, \"output/data-table-missing-by-participant.csv\")\n\n# 3. Visual Report\n# Generates a map of missingness (Black = Missing, Grey = Present)\n# We use 'print()' to ensure the plot renders when running from a script\nmessage(\"--- Generating Missing Data Map ---\")\nplot_missing &lt;- vis_miss(scale_items) +\n  labs(title = \"Missing Data Map (Scale Items Only)\") +\n  theme(axis.text.x = element_text(angle = 60, hjust = 0, vjust = 0, size = 16),\n        axis.text.x.top = element_text(margin = margin(b = 2)),\n        axis.text.y = element_text(size = 16),\n        plot.title = element_text(size = 16),\n        legend.text = element_text(size = 16),\n        legend.title = element_text(size = 16),\n        plot.margin = margin(t = 10, r = 10, b = 10, l = 10))\n\nggsave(\"output/figure-missing-data-map.png\", plot = plot_missing, width = 20, height = 20, dpi = \"print\")\n\n# Data not altered so no need to save\n\nThis step saves diagnostic outputs to the output/ folder. You can review these to decide whether any participants should be excluded for excessive missing data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-4-create-scales",
    "href": "data-pipeline.html#step-4-create-scales",
    "title": "3  Data Science Pipelines in R",
    "section": "3.10 Step 4: Create Scales",
    "text": "3.10 Step 4: Create Scales\nNow we compute scale scores by averaging items:\n\n# 04-create-scales.R\n\n# Step 4: Scale Creation \n\n# Load Previous Step ------------------------------------------------------\nanalytic_data_survey &lt;- read_rds(\"data-interim/02-cleaned.rds\")\n\n\n# Create Scale Scores -----------------------------------------------------\n# Note: We use rowwise() for accurate mean calculations across columns\nanalytic_data_survey &lt;- analytic_data_survey %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    affective_commitment = mean(c_across(starts_with(\"aff_com\")), na.rm = TRUE),\n    continuance_commitment = mean(c_across(starts_with(\"contin_com\")), na.rm = TRUE),\n    normative_commitment = mean(c_across(starts_with(\"norm_com\")), na.rm = TRUE),\n    job_satisfaction = mean(c_across(starts_with(\"job_aff\")), na.rm = TRUE)\n  ) %&gt;%\n  ungroup() # Always ungroup after rowwise()!\n\n# Clean up Item columns (Optional - keeps dataset clean)\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  select(-starts_with(\"aff_com\"),\n         -starts_with(\"contin_com\"),\n         -starts_with(\"norm_com\"),\n         -starts_with(\"job_aff\")) \n\n# Save Interim File -------------------------------------------------------\nwrite_rds(analytic_data_survey, \"data-interim/03-scales-created.rds\")\n\nImportant: Always call ungroup() after rowwise(). Forgetting this can cause unexpected behavior in subsequent operations.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-5-exclusions",
    "href": "data-pipeline.html#step-5-exclusions",
    "title": "3  Data Science Pipelines in R",
    "section": "3.11 Step 5: Exclusions",
    "text": "3.11 Step 5: Exclusions\nThis step applies your preregistered exclusion criteria:\n\n# 05-exclusions.R\n\n# Step 5: Exclusions\n\n# Rules for excluding participants should be preregistered.\n# In this example, we exclude participants who completed the survey in under 2 minutes.\n\n\n# Load Previous Step ------------------------------------------------------\nanalytic_data_survey &lt;- read_rds(\"data-interim/03-scales-created.rds\")\n\n# Exclusions --------------------------------------------------------------\n# Filter out speeders (Requires 'duration_in_seconds' from Step 1)\ninitial_n &lt;- nrow(analytic_data_survey)\n\n# Only keep participants with duration &gt;= 120 seconds (2 minutes)\nanalytic_data_survey &lt;- analytic_data_survey %&gt;%\n  filter(duration_in_seconds &gt;= 120)\n\n# Print a message telling the student how many were dropped\nfinal_n &lt;- nrow(analytic_data_survey)\nmessage(paste(\"Dropped\", initial_n - final_n, \"participants due to speed checks.\"))\n\n# Final Save --------------------------------------------------------------\nwrite_rds(analytic_data_survey, \"data-processed/analytic-data-final.rds\")\n\n# Display final structure\nglimpse(analytic_data_survey)\n\nNote that this script saves to data-processed/, not data-interim/. This signals that the data is now ready for analysis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-6-analysis-wrapper",
    "href": "data-pipeline.html#step-6-analysis-wrapper",
    "title": "3  Data Science Pipelines in R",
    "section": "3.12 Step 6: Analysis Wrapper",
    "text": "3.12 Step 6: Analysis Wrapper\nThis script runs the analysis script but captures the output.\n\n# 06-analysis-wrapper.R\n\n# Step 6: Analysis Wraper\n\n# This wrapper runs the analysis script and captures its output to a text file\n# The text file is saved in the output directory\n# The analysis script is assumed to be \"07-analysis.R\"\n\ncapture.output(source(\"07-analysis.R\", echo =  TRUE),\n                      file = \"output/analysis-output.txt\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#step-7-analysis",
    "href": "data-pipeline.html#step-7-analysis",
    "title": "3  Data Science Pipelines in R",
    "section": "3.13 Step 7: Analysis",
    "text": "3.13 Step 7: Analysis\nFinally, the analysis script loads the clean data and performs your statistical analyses. Note that this file is not directly run in the 00-script-master.R; instead, it is called via the wrapper in Step 6. We do this so the output can be captered to a text file and placed in the output folder.\n\n# 07-analysis.R\n\n# Step 7: Analysis\n\n# Rules for excluding participants should be preregistered.\n# In this example, we exclude participants who completed the survey in under 2 minutes.\n\n\n# Clear memory to ensure reproducibility\nrm(list = ls()) \n\n# Set random seed for reproducibility (e.g., geom_jitter)\nset.seed(12345)\n\n# 1. Setup Environment for Analyses ----------------------------------------------------\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(skimr)\nlibrary(apaTables)\n\n# Load Previous Step ------------------------------------------------------\nanalytic_data_survey &lt;- read_rds(\"data-processed/analytic-data-final.rds\")\n\n# Analysis ----------------------------------------------------------------\n\n\nskim(analytic_data_survey)\n\n\n\n# Example Analysis: Descriptive Statistics\n\ndata_plot &lt;- analytic_data_survey |&gt;\n  select(contains(\"commitment\")) \n  \n\napa.cor.table(data_plot,\n                  filename = \"output/table-correlation-descriptive-statistics.doc\",\n                  table.number = 1)\n\n\nfont_size &lt;- 10\ncor_plot &lt;- ggpairs(data_plot,\n                    upper = \"blank\",\n                    lower = list(continuous = wrap(\"points\", alpha = 0.3)),\n                    diag = list(continuous = wrap(\"barDiag\",\n                                                  bins = 15,\n                                                  color = \"black\",\n                                                  fill = \"black\",\n                                                  alpha = 1))) +\n  theme_linedraw(font_size) +\n  theme(panel.spacing = unit(.8, \"lines\"))\n\nggsave(\"output/figure-pairs-plot.png\",\n        plot = cor_plot,\n        width = 7,\n        height = 7,\n        units = \"in\",\n        dpi = 300)\n\nprint(cor_plot)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#converting-your-single-script",
    "href": "data-pipeline.html#converting-your-single-script",
    "title": "3  Data Science Pipelines in R",
    "section": "3.14 Converting Your Single Script",
    "text": "3.14 Converting Your Single Script\nTo convert your existing single script to a pipeline:\n\nCreate the folder structure shown above\nIdentify natural breakpoints in your code (import, cleaning, scales, exclusions, analysis)\nMove each section to its own numbered script\nAdd read_rds() at the start of each script (except step 1)\nAdd write_rds() at the end of each script\nCreate a master script that sources each step in order",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#benefits-of-the-pipeline-approach",
    "href": "data-pipeline.html#benefits-of-the-pipeline-approach",
    "title": "3  Data Science Pipelines in R",
    "section": "3.15 Benefits of the Pipeline Approach",
    "text": "3.15 Benefits of the Pipeline Approach\nThe pipeline approach offers several advantages over a single script:\n\n\n\n\n\n\n\nSingle Script\nPipeline Approach\n\n\n\n\nEverything in one file\nModular, numbered scripts\n\n\nDifficult to debug\nEach step is isolated and testable\n\n\nMust re-run everything\nCan re-run from any checkpoint\n\n\nHard to collaborate\nTeam members can work on different steps\n\n\nNo clear progress indicators\nMessages show which step is running\n\n\n\nThe pipeline approach requires a bit more setup, but the benefits for debugging, collaboration, and reproducibility make it well worth the effort—especially as your projects grow in complexity.\n\n\n\n\n\n\nTipUsing AI is Easier with a Pipeline Approach\n\n\n\nThe modular pipeline structure makes it easier to work with AI assistants like ChatGPT or Claude. You can share individual scripts for help without overwhelming the AI with your entire project.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#output-from-the-pipeline",
    "href": "data-pipeline.html#output-from-the-pipeline",
    "title": "3  Data Science Pipelines in R",
    "section": "3.16 Output from the Pipeline",
    "text": "3.16 Output from the Pipeline\nTo run the entire pipeline, simply open script-master.R and run it. You can also run individual scripts if you need to re-do just one step (for example, if you change your exclusion criteria, you only need to re-run steps 5 and 6).\nLet’s run the master script now to see the pipeline in action!\nRecall, running the script places the missing data evaluation in the output folder. Let’s check that folder to see the results of that step.\n\n3.16.1 Missing data by item\nWe can see the percentage of missing data for each item by examining the CSV file created in the output folder called data-table-missing-by-item.csv.\n\n\n\n\n\nvariable\nn_miss\npct_miss\n\n\n\n\ncontin_com2_likert7\n32\n21.333333\n\n\nnorm_com1_likert7\n9\n6.000000\n\n\nnorm_com2_likert7\n8\n5.333333\n\n\nnorm_com3_likert7\n8\n5.333333\n\n\naff_com4_likert7\n7\n4.666667\n\n\naff_com5_likert7\n7\n4.666667\n\n\ncontin_com3_likert7\n7\n4.666667\n\n\ncontin_com4_likert7\n7\n4.666667\n\n\ncontin_com5_likert7\n7\n4.666667\n\n\ncontin_com6_likert7\n7\n4.666667\n\n\naff_com6_likert7\n6\n4.000000\n\n\ncontin_com1_likert7\n6\n4.000000\n\n\naff_com1_likert7\n5\n3.333333\n\n\naff_com2_likert7\n5\n3.333333\n\n\naff_com3_likert7\n5\n3.333333\n\n\nnorm_com4_likert7\n2\n1.333333\n\n\nnorm_com5_likert7\n2\n1.333333\n\n\n\n\n\n\n\n3.16.2 Missing data by person\nWe can see the percentage of missing data for each person by examining the CSV file created in the output folder called data-table-missing-by-participant.csv.\n\n\n\n\n\nparticipant_id\npct_missing\n\n\n\n\n3\n27.27273\n\n\n13\n22.72727\n\n\n21\n68.18182\n\n\n22\n68.18182\n\n\n23\n77.27273\n\n\n24\n68.18182\n\n\n25\n68.18182\n\n\n66\n22.72727\n\n\n\n\n\n\n\n3.16.3 Visual missing data map\nWe can see the visual missing data map created in the output folder called figure-missing-data-map.png. This visual map helps identify patterns in the missing data across items and participants. The shape of the rectange corresponds to the number of participants (rows) and items (columns). The black areas indicate where I deleted cells in the spreadsheet to artifially create missing data for this example.\n\n\n\n\n\n\n\n\n\n\n\n3.16.4 Pairs plot\nWe can see the pairs plot created in the output folder called figure-pairs-plot.png. The ggpairs function lets us see relationships among all the scales at once - and see the histogram for each scale along the diagonal.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "data-pipeline.html#using-spss-data",
    "href": "data-pipeline.html#using-spss-data",
    "title": "3  Data Science Pipelines in R",
    "section": "3.17 Using SPSS Data?",
    "text": "3.17 Using SPSS Data?\nIf your data is in SPSS format (.sav), you can easily read it into R using the haven package. Here’s how to modify the import script to handle SPSS files. Simply replace the read_csv line in 01-import.R with the following code:\n\nlibrary(haven) \n# Read SPSS data\nraw_data &lt;- read_sav(\"data-raw/data-qualtrics.sav\")\n\n# Assign value labels (e.g., 1 in SPSS sex column becomes \"male\" if that's how you set up the value labels in SPSS)\nraw_data &lt;- as_factor(raw_data)\n\n# check which columns are now factors after using as_factor()\nglimpse(raw_data)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science Pipelines in R</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "4  Regression and correlation",
    "section": "",
    "text": "4.1 Population example\nThe following CRAN packages must be installed:\nConsider the following the scenario, we want to examine the extent to which IQ predicts video game scores for people who live in the City of Guelph. We want to make conclusions about people who live in the City of Guelph so we refer to Guelph citizens as our population. Because we are interested in using IQ to predict video game score we refer to IQ as the predictor. The value being predicted is video game score and we refer to that variable as the criterion (i.e., the dependent variable). Imagine, for a moment, that we are actually able to get an IQ and a video game score for everyone in the City of Guelph (N = 100,000).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression and correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#population-example",
    "href": "correlation.html#population-example",
    "title": "4  Regression and correlation",
    "section": "",
    "text": "4.1.1 No predictor\nWe illustrate the range and variability of video game scores for everyone in the population below. There are 100,000 blue dots on this graph. Each blue dot represents a person in the population. The vertical position of the dot indicates each person’s video game.\n\nNotice the large number of dots (i.e., people) - there are so many that it’s hard to see individual dots/people.\nThe dots illustrate the range of video game scores - everyone did not obtain the same score.\nWe want to try to understand why, in this population, some people have higher vs lower video game scores.\nSaid another way, we want to explain, for this population, the variability in video game scores.\nCorrelation/regression can never provide evidence of causation (or explanation) but we can use those analyses to find a pattern in our data that is consistent with a causal relation. Then we conduct a second experimental study to determine if their really is a causal relation.\n\n\n\n\n\n\n\n\n\n\nWithout a predictor variable, our best estimate of a person’s video game score is the population mean. Moreover, without a predictor, we have the same estimate for everyone in the population - the mean video game score for the population. We have no way of creating an individualized estimate of someone’s video game score. The mean video game score is illustrated in the figure below with a horizontal green line.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Weak relation\nWe can plot a variable (e.g., extraversion) against video game score to see if there is a relation between the two. In this case there doesn’t appear to be a relation. Indeed, this graph illustrates a zero correlation between extraversion and video game scores - the weakest possible relation for a predictor. Effectively, there is no linear relation between extraversion and video game scores.\nAs before, we place a horizontal green line on the graph to indicate the mean video game score. We also place a red regression line (i.e., best-fit line) on the graph; however, the red line is completely hidden by the green line representing the mean video game score. In this case, with these data, knowing a person’s extraversion score does not allow us to provide an individualized estimate of a person’s video game score. As a result, extraversion does not help us explain the variability in video game scores. That is, extraversion scores do not allow us to explain why some people have high video game score whereas other people have low video game scores.\n\n\n\n\n\n\n\n\n\n\n\n4.1.3 Strong relation\nWhat if we were to try another variable – like IQ? The graph below illustrates a positive linear relation between IQ and video game score. As before, we place a green horizontal line on the graph to indicate the population mean. Additionally, we place a red regression line (i.e., a best-fit line) on the graph. This red regression line represents, for each person, an individualized estimate of video game score based on their IQ. The population-level regression line has the slope 8.00; which indicate that as IQ increase by 1.0 point video game score increases by 8.00 points. The equation for the regression line is:\n\\[\n\\begin{aligned}\n\\widehat{score} &= 8.00(IQ) + 200.31\n\\end{aligned}\n\\]\nOr using the more generic X/Y notation:\n\\[\n\\begin{aligned}\n\\hat{Y} &= 8.00(X) + 200.31 \\\\\n\\end{aligned}\n\\]\nYou can see in the graph below that, for some people, the individualized estimate of video game score (i.e., the y-axis position of the red line) is higher than the population mean. That is, in some cases the red regression is line is higher than the green line for the population mean. For other people, the individualized estimate of video game score (i.e., the y-axis position of the red line) is lower than the population mean. That is, in some cases the red regression is line is lower than the green line for the population mean. It appears that individuals with a high IQ tend to have a high video game score whereas individuals with a low IQ tend of have a low video game score. The regression line provides a more nuanced estimate for individual’s video game score than you can obtain by simply using the same estimation (i.e., the population mean) for everyone.\n\n\n\n\n\n\n\n\n\nBut how good is this model of the data? There are a variety of way of assessing model fit. We present two below. First, when you are only concerned about how well a single predictor performs, as is the case here, you can use a correlation. The symbol for the population correlation is \\(\\rho\\). In these data, \\(\\rho = .60\\). The correlation coefficient can range from -1 to 1. The further the correlation is from zero - the stronger the relation between the predictor and the criterion. That is, the further the correlation is from zero the better a linear model fits the data. A positive correlation indicates that as one variable increases the other variable also increases. A negative correlation indicates that as one variable increases the other variable decreases.\nCohen’s benchmarks are below:\n\n\n\nCohen (1988) Label\nValue\n\n\n\n\nSmall\n\\(\\rho\\) = .10\n\n\nMedium\n\\(\\rho\\) = .30\n\n\nLarge\n\\(\\rho\\) = .50\n\n\n\nAn alternative, and more general, means of assessing the quality of statistical model is to use \\(R^2\\). This indexes the proportion of video game scores that are accounted for by a statistical model. One important attribute of \\(R^2\\) is that can be used when there are multiple predictors. When there is only one predictor, \\(R^2\\) is simply the correlation squared. Thus, at the population level, when there is only one predictor:\n\\[\n\\begin{aligned}\nR^2  = \\rho^2\n\\end{aligned}\n\\]\nTo summarize, the population-level values (i.e., parameters):\n\nSlope = 8.00\n\\(\\rho = .60\\)\n\\(R^2 = .36\\)\n\nIn the next section we use sample-level data to estimate these population-level values.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression and correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#consider-a-sample",
    "href": "correlation.html#consider-a-sample",
    "title": "4  Regression and correlation",
    "section": "4.2 Consider a sample",
    "text": "4.2 Consider a sample\nUnfortunately, we never/rarely have data for everyone in the population (in this example everyone in the City of Guelph). Consequently, we usually have to select a subset of the population as a sample and use sample data for our analyses. In the figure below there are 100,000 blue dots - each dot represents an individual in the population. Additionally, there are also 9 black dots. These black dots are a random subset of the population – our sample. We will use the data from our sample (i.e., the 9 black dots) to estimate the slope, correlation, and \\(R^2\\) for the population (i.e., the 100,000 blue dots).\n\n\n\n\n\n\n\n\n\nWe always need to remember the values calculated from our sample (statistics) are only estimates of the population-level parameters; estimates that are likely are likely to differ from population parameters due to sampling error.\nLet’s look at our sample in more detail. Notice, in the figure below, that there is one data point (\\(X_i\\), \\(Y_i\\)) for each of the 9 people. We illustrate the mean video game score for the 9 people with the horizontal green line.\n\n\n\n\n\n\n\n\n\nWe can calculate the variance of the video game scores using the formula below.\n\\[\n\\begin{aligned}\ns^2_{score} = \\frac{\\sum{(Y_i - \\bar{Y})^2}}{N-1}\n\\end{aligned}\n\\]\nIt’s often useful to just focus on the numerator of this equation. We call this Sum of Squares Total (SSR):\n\\[\n\\begin{aligned}\nSS_{Total} = \\sum{(Y_i - \\bar{Y})^2}\n\\end{aligned}\n\\]\nThe values used in the Sum of Squares Total calculation are illustrated in the figure below. The vertical blue line indicates the difference between \\(Y_i\\) and \\(\\bar{Y}\\). The \\(SS_{Total}\\) value indexes the variability of the actual video game scores around the sample mean.\n\n\n\n\n\n\n\n\n\nIn the figure below we add the regression line in red. The regression line is a statistical model for the data (a best-fit line). The regression line will always run through the joint mean of the two variables (i.e., the [\\(\\bar{X}\\), \\(\\bar{Y}\\)] point).\n\n\n\n\n\n\n\n\n\nRecall that the regression line represents an individualized estimate of each person’s video game score derived from their IQ (via the regression equation). Later we will show you how to calculate the regression line. For now, accept that the regression equation for the sample in standard notation is:\n\\[\n\\begin{aligned}\n\\hat{Y_i} &= 9.44(X_i) -21.21 \\\\\n\\end{aligned}\n\\]\nAnd contextualized to the variable names is:\n\\[\n\\begin{aligned}\n\\widehat{score_i} &= 9.44(IQ_i) -21.21\n\\end{aligned}\n\\]\nTherefore, the predicted value for Jane is:\n\\[\n\\begin{aligned}\n\\widehat{score_i} &= 9.44(IQ_i) -21.21 \\\\\n&= 9.44(71) - 21.21 \\\\\n&= 649 \\text{(rounded)} \\\\\n\\end{aligned}\n\\]\nYou can see this calculation for everyone in the sample:\n\n\n\n\n\n\n\n\n\nIn the graph below each person is represented by a blue dot. The estimate of each person’s video game score, \\(\\hat{Y_i}\\), derived from the regression equation, is indicated by a red dot on the red regression line. The vertical blue lines are used to indicate, for each person (i.e., blue dot, \\(Y_i\\)), the estimate of their video game score (i.e., red dot, \\(\\hat{Y_i}\\)).\n\n\n\n\n\n\n\n\n\nWe can calculate the extent to which individualized estimates are better than the sample mean for modeling the data. That is, we can calculate the extent to which the regression line is better at modeling the data than the mean line. We do so by calculating the extent to which the individualized estimates on the regression line differ from the sample mean. This is done with the calculation below for the Sum of Squares Regression.\n\\[\n\\begin{aligned}\nSS_{Regression} = \\sum{(\\hat{Y_i} - \\bar{Y})^2}\n\\end{aligned}\n\\]\nThe values used in the Sum of Squares Regression calculation are illustrated in the figure below. The vertical red line indicates the difference between \\(\\hat{Y_i}\\) and \\(\\bar{Y}\\). The \\(SS_{Regression}\\) value indexes the variability of the estimates of video game scores around the sample mean. The longer the vertical red line (i.e., the larger the \\((\\hat{Y_i} - \\bar{Y})\\) difference) the better the model. Longer vertical red lines are associated with models that do a better job of accounting for variability in video scores.\n\n\n\n\n\n\n\n\n\nSo far we have calculated two values, \\(SS_{Regression}\\) and \\(SS_{Total}\\). The \\(SS_{Total}\\) value indexes the variability of actual video game scores about the sample mean (it’s the numerator for the variance calculation). In contrast, \\(SS_{Regression}\\) indexes the variability of estimated video game scores about the sample mean. We can calculate the proportion of the variability in actual scores accounted for the statistical model (i.e., regression line) using \\(R^2\\):\n\\[\n\\begin{aligned}\nR^2 = \\frac{SS_{Regression}}{SS_{Total}}\n\\end{aligned}\n\\] We can also think of this as in terms of variance (because N-1 terms cancel each other out).\n\\[\n\\begin{aligned}\nR^2 &= \\frac{\\text{Variance of predicted scores}}{\\text{Variance of actual scores}} \\\\\n&= \\frac{\\frac{\\sum{(\\hat{Y_i} - \\bar{Y})^2}}{N-1}}{\\frac{\\sum{(Y_i - \\bar{Y})^2}}{N-1}} \\\\\n&= \\frac{\\sum{(\\hat{Y_i} - \\bar{Y})^2}}{\\sum{(Y_i - \\bar{Y})^2}} \\\\\n&= \\frac{SS_{Regression}}{SS_{Total}}\\\\\n\\end{aligned}\n\\]\n\n4.2.1 Regression\nLet’s obtain the actual value for \\(R^2\\), as well as the slope, using R. We can obtain the regression model (i.e.. linear model or lm) using the command below:\n\nlm_object &lt;- lm(video_game ~ iq,\n                data = sample_data)\n\nWe display the result using apaTables:\n\nlibrary(apaTables)\n\napa.reg.table(lm_object,\n              table.number = 1,\n              filename = \"regression_table.doc\")\n\nWhich produces the output:\n\n\n\n\n\n\n\n\n\nIf we examine the fit column on the far right of the output above we see \\(R^2\\) = .74, 95% CI [.17, .86]. This value indicates that in this sample 74% of the variability in video scores is accounted accounted for by the statistical model (i.e., red regression line). The confidence interval suggests a plausible range of values for the \\(R^2\\) at the population-level is .17 to .86. Notice that this range captures that population-level \\(R^2\\) of .36 that we calculated from the entire population previously.\n\\[\n\\begin{aligned}\nR^2 &= .736 = .74\\\\\\\\\n\\end{aligned}\n\\]\nIf we examine the b column in the output we can create the regression equations below:\n\\[\n\\begin{aligned}\n\\hat{Y_i} &= 9.44(X_i) -21.21 \\\\\n\\widehat{score_i} &= 9.44(IQ_i) -21.21\\\\\n\\end{aligned}\n\\]\nThis tells use the slope in our sample is 9.44, 95% CI [4.39, 14.50]. That is, in the sample, each IQ point is associated with an additional 9.44 points in the video game. The population regression line might have a smaller/larger slope. The 95% confidence intervals tells us that a plausible range of values for the slope of the regression line at the population-level is 4.39 to 14.50. Notice that this range captures that population-level slope of 8.00 that we calculated from the entire population previously.\nAdditional regression details are provided with the command below.\n\nsummary(lm_object)\n\n\nCall:\nlm(formula = video_game ~ iq, data = sample_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-201.16  -80.42   58.63   79.79  151.28 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  -21.209    225.855  -0.094  0.92781   \niq             9.443      2.138   4.417  0.00309 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 130.5 on 7 degrees of freedom\nMultiple R-squared:  0.7359,    Adjusted R-squared:  0.6982 \nF-statistic: 19.51 on 1 and 7 DF,  p-value: 0.003093\n\n\n\n\n4.2.2 Correlation\nAs discussed previously, a correlation can be considered a fit index for a linear regression line. That is, a correlation indicates the extent to which the data fit a straight line (i.e., the extent to which the data fit a linear model). Correlation values range between -1 and +1. The further a correlation value is from 0 the more tightly points will cluster around the regression line.\n\nA positive correlation indicates that as one value increases the other value increases. For example, as height increases weight increases.\nA negative correlation indicates that as one value increases the other values decreases. For example, as study time increases the number of errors on an exam decreases.\n\nA few possible positive correlations are illustrated below – notice the relation between the graph and the strength of the correlation.\n\n\n\n\n\n\n\n\n\nYou can obtain the correlation from our sample data with the command below:\n\ncor.test(sample_data$iq, sample_data$video_game, \n         na.action = \"pairwise.complete.obs\")\n\n\n    Pearson's product-moment correlation\n\ndata:  sample_data$iq and sample_data$video_game\nt = 4.4167, df = 7, p-value = 0.003093\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4502656 0.9695860\nsample estimates:\n      cor \n0.8578603 \n\n\nFrom this output we extract the numbers below in APA reporting style:\nThere was a positive relation between IQ and video game score, such that as IQ increased, so did video game score, \\(r\\) = .86, 95% CI[.45, .97], \\(p\\) = .003, N = 9.\n\n\n4.2.3 Graphing\nA scatter plot can be made code below:\n\nmy_plot &lt;- ggplot(data = sample_data, \n                  mapping = aes(x = iq, y = video_game)) + \n  geom_point(color = \"blue\", size = 4) +\n  coord_cartesian(xlim = c(70, 140), ylim = c(400, 1500)) +\n  scale_y_continuous(breaks = seq(400, 1500, by = 200)) + \n  scale_x_continuous(breaks = seq(70, 140, by = 20)) +\n  labs(x = \"IQ\", y = \"Video Game Score\") +\n  theme_classic(24)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression and correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#comparing-correlations",
    "href": "correlation.html#comparing-correlations",
    "title": "4  Regression and correlation",
    "section": "4.3 Comparing correlations",
    "text": "4.3 Comparing correlations\nIn this part of the chapter we compare correlations within and across studies we do so with the cocor package. We begin by obtaining a data set from the psych package. Note that we do not use the library(psych) command due to conflicts with the tidyverse.\n\n# Obtain the bfi data set from the psych package\nbfi &lt;- psych::bfi\n\n# remove empty rows/columns and clean the variable names\nbfi &lt;- bfi %&gt;%\n  remove_empty(\"rows\") %&gt;%\n  remove_empty(\"cols\") %&gt;%\n  clean_names()\n\nCheck out the large number of columns.\n\nglimpse(bfi)\n\nRows: 2,800\nColumns: 28\n$ a1        &lt;int&gt; 2, 2, 5, 4, 2, 6, 2, 4, 4, 2, 4, 2, 5, 5, 4, 4, 4, 5, 4, 4, …\n$ a2        &lt;int&gt; 4, 4, 4, 4, 3, 6, 5, 3, 3, 5, 4, 5, 5, 5, 5, 3, 6, 5, 4, 4, …\n$ a3        &lt;int&gt; 3, 5, 5, 6, 3, 5, 5, 1, 6, 6, 5, 5, 5, 5, 2, 6, 6, 5, 5, 6, …\n$ a4        &lt;int&gt; 4, 2, 4, 5, 4, 6, 3, 5, 3, 6, 6, 5, 6, 6, 2, 6, 2, 4, 4, 5, …\n$ a5        &lt;int&gt; 4, 5, 4, 5, 5, 5, 5, 1, 3, 5, 5, 5, 4, 6, 1, 3, 5, 5, 3, 5, …\n$ c1        &lt;int&gt; 2, 5, 4, 4, 4, 6, 5, 3, 6, 6, 4, 5, 5, 4, 5, 5, 4, 5, 5, 1, …\n$ c2        &lt;int&gt; 3, 4, 5, 4, 4, 6, 4, 2, 6, 5, 3, 4, 4, 4, 5, 5, 4, 5, 4, 1, …\n$ c3        &lt;int&gt; 3, 4, 4, 3, 5, 6, 4, 4, 3, 6, 5, 5, 3, 4, 5, 5, 4, 5, 5, 1, …\n$ c4        &lt;int&gt; 4, 3, 2, 5, 3, 1, 2, 2, 4, 2, 3, 4, 2, 2, 2, 3, 4, 4, 4, 5, …\n$ c5        &lt;int&gt; 4, 4, 5, 5, 2, 3, 3, 4, 5, 1, 2, 5, 2, 1, 2, 5, 4, 3, 6, 6, …\n$ e1        &lt;int&gt; 3, 1, 2, 5, 2, 2, 4, 3, 5, 2, 1, 3, 3, 2, 3, 1, 1, 2, 1, 1, …\n$ e2        &lt;int&gt; 3, 1, 4, 3, 2, 1, 3, 6, 3, 2, 3, 3, 3, 2, 4, 1, 2, 2, 2, 1, …\n$ e3        &lt;int&gt; 3, 6, 4, 4, 5, 6, 4, 4, NA, 4, 2, 4, 3, 4, 3, 6, 5, 4, 4, 4,…\n$ e4        &lt;int&gt; 4, 4, 4, 4, 4, 5, 5, 2, 4, 5, 5, 5, 2, 6, 6, 6, 5, 6, 5, 5, …\n$ e5        &lt;int&gt; 4, 3, 5, 4, 5, 6, 5, 1, 3, 5, 4, 4, 4, 5, 5, 4, 5, 6, 5, 6, …\n$ n1        &lt;int&gt; 3, 3, 4, 2, 2, 3, 1, 6, 5, 5, 3, 4, 1, 1, 2, 4, 4, 6, 5, 5, …\n$ n2        &lt;int&gt; 4, 3, 5, 5, 3, 5, 2, 3, 5, 5, 3, 5, 2, 1, 4, 5, 4, 5, 6, 5, …\n$ n3        &lt;int&gt; 2, 3, 4, 2, 4, 2, 2, 2, 2, 5, 4, 3, 2, 1, 2, 4, 4, 5, 5, 5, …\n$ n4        &lt;int&gt; 2, 5, 2, 4, 4, 2, 1, 6, 3, 2, 2, 2, 2, 2, 2, 5, 4, 4, 5, 1, …\n$ n5        &lt;int&gt; 3, 5, 3, 1, 3, 3, 1, 4, 3, 4, 3, NA, 2, 1, 3, 5, 5, 4, 2, 1,…\n$ o1        &lt;int&gt; 3, 4, 4, 3, 3, 4, 5, 3, 6, 5, 5, 4, 4, 5, 5, 6, 5, 5, 4, 4, …\n$ o2        &lt;int&gt; 6, 2, 2, 3, 3, 3, 2, 2, 6, 1, 3, 6, 2, 3, 2, 6, 1, 1, 2, 1, …\n$ o3        &lt;int&gt; 3, 4, 5, 4, 4, 5, 5, 4, 6, 5, 5, 4, 4, 4, 5, 6, 5, 4, 2, 5, …\n$ o4        &lt;int&gt; 4, 3, 5, 3, 3, 6, 6, 5, 6, 5, 6, 5, 5, 4, 5, 3, 6, 5, 4, 3, …\n$ o5        &lt;int&gt; 3, 3, 2, 5, 3, 1, 1, 3, 1, 2, 3, 4, 2, 4, 5, 2, 3, 4, 2, 2, …\n$ gender    &lt;int&gt; 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, …\n$ education &lt;int&gt; NA, NA, NA, NA, NA, 3, NA, 2, 1, NA, 1, NA, NA, NA, 1, NA, N…\n$ age       &lt;int&gt; 16, 18, 17, 17, 17, 21, 18, 19, 19, 17, 21, 16, 16, 16, 17, …\n\n\nLet’s select a small subset of the columns for our example:\n\nbfi &lt;- bfi %&gt;%\n  select(a1, c1, e1, o1, gender)\n\nYou can confirm the smaller set of columns:\n\nglimpse(bfi)\n\nRows: 2,800\nColumns: 5\n$ a1     &lt;int&gt; 2, 2, 5, 4, 2, 6, 2, 4, 4, 2, 4, 2, 5, 5, 4, 4, 4, 5, 4, 4, 5, …\n$ c1     &lt;int&gt; 2, 5, 4, 4, 4, 6, 5, 3, 6, 6, 4, 5, 5, 4, 5, 5, 4, 5, 5, 1, 4, …\n$ e1     &lt;int&gt; 3, 1, 2, 5, 2, 2, 4, 3, 5, 2, 1, 3, 3, 2, 3, 1, 1, 2, 1, 1, 3, …\n$ o1     &lt;int&gt; 3, 4, 4, 3, 3, 4, 5, 3, 6, 5, 5, 4, 4, 5, 5, 6, 5, 5, 4, 4, 6, …\n$ gender &lt;int&gt; 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, …\n\n\nThese columns are single items from a personality measure.\n\na1 (Agreeableness)\nc1 (Conscientiousness)\ne1 (Extraversion)\no1 (Opennness)\n\nYou can obtain a condensed correlation matrix using the cor() command. You can specify use = “pairwise.complete.obs” for pairwise correlation - the documentation covers other options. The round(2) command rounds the correlations to two decimal places.\n\ncor(bfi, use = \"pairwise.complete.obs\") %&gt;%\n    round(2)\n\n          a1    c1    e1    o1 gender\na1      1.00  0.03  0.11  0.01  -0.16\nc1      0.03  1.00 -0.02  0.17   0.01\ne1      0.11 -0.02  1.00 -0.10  -0.13\no1      0.01  0.17 -0.10  1.00  -0.10\ngender -0.16  0.01 -0.13 -0.10   1.00\n\n\nOr we could use apaTable apa.cor.table() command:\n\nlibrary(apaTables)\n\napa.cor.table(bfi,\n              table.number = 1,\n              filename = \"table_1_bfi.doc\")\n\n\n\n\n\n\n\n\n\n\nInspecting the above table you see that the correlation between a1 and c1 with is r = .03, 95% CI [-.01, .07]. Likewise, the correlation between e1 and o1 is r = -.10, 95% CI [-.14, -.06]. We obtain the p-values for these relations below.\n\n4.3.1 p-values\nThe code below obtains the p-value for the a1/c1 relation - a value of .144.\n\ncor.test(bfi$a1, bfi$c1)\n\n\n    Pearson's product-moment correlation\n\ndata:  bfi$a1 and bfi$c1\nt = 1.4617, df = 2762, p-value = 0.1439\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.009490233  0.065018669\nsample estimates:\n       cor \n0.02780283 \n\n\nThe code below obtains the p-value for the e1/o1 relation - a value sufficiently small we report it as \\(p\\) &lt; .001\n\ncor.test(bfi$e1, bfi$o1)\n\n\n    Pearson's product-moment correlation\n\ndata:  bfi$e1 and bfi$o1\nt = -5.2971, df = 2757, p-value = 1.27e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.13717646 -0.06329333\nsample estimates:\n       cor \n-0.1003733 \n\n\nWith p-values in hand we can write this up as:\nInspecting the above table you see that the correlation between a1 and c1 with is r = .03, 95% CI [-.01, .07], p = .144. Likewise, the correlation between e1 and o1 is r = -.10, 95% CI [-.14, -.06], p &lt; .001.\n\n\n4.3.2 Within a data set\nIn this section we look at comparing correlation within a single data set.\n\n4.3.2.1 Non-overlapping correlations\nWe will compare the correlation to between (a1, c1) to the correlation between (e1, o1) with the cocor package. In this case, because neither of the variables in the first correlation (a1, c1) are in the second correlation (e1, o1) we refer to this as a non-overlapping correlation comparison.\nThe cocor command will provide a lot of output. We are most interested in the last part of the output corresponding to Zou (2007) which provides the confidence interval for the difference in the correlations. But we also want to examine the first part of the output which will show us the two original correlations (a1, c1) = 0.0276, and (e1, o1) = -0.1002 (these are the .03 and -.10 values prior to rounding). As well it also shows us the difference between them, Difference: r.jk - r.hm = 0.1278.\n\nlibrary(cocor)\n\ncocor( ~ a1 + c1 | e1 + o1, data = as.data.frame(bfi))\n\n\n  Results of a comparison of two nonoverlapping correlations based on dependent groups\n\nComparison between r.jk (a1, c1) = 0.0276 and r.hm (e1, o1) = -0.1002\nDifference: r.jk - r.hm = 0.1278\nRelated correlations: r.jh = 0.1036, r.jm = 0.0125, r.kh = -0.0259, r.km = 0.1688\nData: as.data.frame(bfi): j = a1, k = c1, h = e1, m = o1\nGroup size: n = 2724\nNull hypothesis: r.jk is equal to r.hm\nAlternative hypothesis: r.jk is not equal to r.hm (two-sided)\nAlpha: 0.05\n\npearson1898: Pearson and Filon's z (1898)\n  z = 4.7832, p-value = 0.0000\n  Null hypothesis rejected\n\ndunn1969: Dunn and Clark's z (1969)\n  z = 4.7676, p-value = 0.0000\n  Null hypothesis rejected\n\nsteiger1980: Steiger's (1980) modification of Dunn and Clark's z (1969) using average correlations\n  z = 4.7671, p-value = 0.0000\n  Null hypothesis rejected\n\nraghunathan1996: Raghunathan, Rosenthal, and Rubin's (1996) modification of Pearson and Filon's z (1898)\n  z = 4.7676, p-value = 0.0000\n  Null hypothesis rejected\n\nsilver2004: Silver, Hittner, and May's (2004) modification of Dunn and Clark's z (1969) using a backtransformed average Fisher's (1921) Z procedure\n  z = 4.7671, p-value = 0.0000\n  Null hypothesis rejected\n\nzou2007: Zou's (2007) confidence interval\n  95% confidence interval for r.jk - r.hm: 0.0753 0.1800\n  Null hypothesis rejected (Interval does not include 0)\n\n\nWe could write this as:\nThere was a negative weak relation between extraversion (e1) and openness (o1) such that as extraversion increased openness decreased, r = -.10, 95% CI [-.14, -.06], p &lt; .001. In contrast, the relation between agreeableness (a1) and conscientiousness(c1) was non-significant, r = .03, 95% CI [-.01, .07], p = .144. The extraversion/openness relation was stronger than the agreeableness/conscientiousness relation, \\(\\Delta\\)r = .13, 95% CI [.07, .18], p &lt; .001.\n\n\n4.3.2.2 Overlapping correlations\nWe will compare the correlation to between (a1, c1) to the correlation between (a1, e1) with cocor. In this case, because a1 is common to the first correlation (a1, c1) and the second correlation (e1, o1) we refer to this as an overlapping correlation comparison.\nWe obtain the (a1, e1) correlation, below, and find: r = .11, 95% [.07, .14], p &lt; .001.\n\ncor.test(bfi$a1, bfi$e1)\n\n\n    Pearson's product-moment correlation\n\ndata:  bfi$a1 and bfi$e1\nt = 5.6102, df = 2759, p-value = 2.221e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.06917483 0.14294144\nsample estimates:\n      cor \n0.1062043 \n\n\nWe obtain the (a1, c1) correlation, below, and find: r = .03, 95% [-.00, .07], p = .14.\n\ncor.test(bfi$a1, bfi$c1)\n\n\n    Pearson's product-moment correlation\n\ndata:  bfi$a1 and bfi$c1\nt = 1.4617, df = 2762, p-value = 0.1439\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.009490233  0.065018669\nsample estimates:\n       cor \n0.02780283 \n\n\nWe use the cocor command to compare the two relations:\n\nlibrary(cocor)\n\ncocor( ~ a1 + c1 | a1 + e1, data = as.data.frame(bfi))\n\n\n  Results of a comparison of two overlapping correlations based on dependent groups\n\nComparison between r.jk (a1, c1) = 0.0263 and r.jh (a1, e1) = 0.1047\nDifference: r.jk - r.jh = -0.0784\nRelated correlation: r.kh = -0.0248\nData: as.data.frame(bfi): j = a1, k = c1, h = e1\nGroup size: n = 2741\nNull hypothesis: r.jk is equal to r.jh\nAlternative hypothesis: r.jk is not equal to r.jh (two-sided)\nAlpha: 0.05\n\npearson1898: Pearson and Filon's z (1898)\n  z = -2.8820, p-value = 0.0040\n  Null hypothesis rejected\n\nhotelling1940: Hotelling's t (1940)\n  t = -2.8827, df = 2738, p-value = 0.0040\n  Null hypothesis rejected\n\nwilliams1959: Williams' t (1959)\n  t = -2.8793, df = 2738, p-value = 0.0040\n  Null hypothesis rejected\n\nolkin1967: Olkin's z (1967)\n  z = -2.8820, p-value = 0.0040\n  Null hypothesis rejected\n\ndunn1969: Dunn and Clark's z (1969)\n  z = -2.8775, p-value = 0.0040\n  Null hypothesis rejected\n\nhendrickson1970: Hendrickson, Stanley, and Hills' (1970) modification of Williams' t (1959)\n  t = -2.8827, df = 2738, p-value = 0.0040\n  Null hypothesis rejected\n\nsteiger1980: Steiger's (1980) modification of Dunn and Clark's z (1969) using average correlations\n  z = -2.8765, p-value = 0.0040\n  Null hypothesis rejected\n\nmeng1992: Meng, Rosenthal, and Rubin's z (1992)\n  z = -2.8754, p-value = 0.0040\n  Null hypothesis rejected\n  95% confidence interval for r.jk - r.jh: -0.1325 -0.0251\n  Null hypothesis rejected (Interval does not include 0)\n\nhittner2003: Hittner, May, and Silver's (2003) modification of Dunn and Clark's z (1969) using a backtransformed average Fisher's (1921) Z procedure\n  z = -2.8765, p-value = 0.0040\n  Null hypothesis rejected\n\nzou2007: Zou's (2007) confidence interval\n  95% confidence interval for r.jk - r.jh: -0.1317 -0.0250\n  Null hypothesis rejected (Interval does not include 0)\n\n\nThe cocor command provides a lot of output. We are most interested in the last part of the output corresponding to Zou (2007) which provides the confidence interval for the difference: -.13 to -.03. But we also want to examine the first part of the output which will show us the two original correlations \\(r_{(a1, c1)}\\) = 0.0276, and \\(r_{(a1, e1)}\\) = 0.10472 As well, the output also shows us the difference between thesee two correlations, Difference: r.jk - r.jh = -0.0784 (with rounding, -.08).\nWe can write this up as:\nAgreeableness and extraversion were weakly related, r = .11, 95% [.07, .14], p &lt; .001, such that as agreeableness increased so did extraversion. The relation between agreeableness and conscientiousness was non-significant, r = .03, 95% [-.00, .07], p = .14. The agreeableness/extraversion relation was significantly stronger than the agreeableness/conscientiousness relation, \\(\\Delta\\)r = .08, 95% CI [.03, .13], p = .004.\n\n\n\n4.3.3 Between data sets\nIn this section we look at comparing correlations from two data sets.\n\n4.3.3.1 Create seperate data files for men and women (if needed)\nWe begin by creating two separate data sets - one for men and one for women:\n\nbfi_men   &lt;- bfi %&gt;%\n  filter(gender == 1) %&gt;%\n  select(-gender)\n\nbfi_women &lt;- bfi %&gt;%\n  filter(gender == 2) %&gt;%\n  select(-gender)\n\nUse glimpse() to check out the subgroups. Note that it also tells you the number of participants in each subgroup.\n\nglimpse(bfi_men)\n\nRows: 919\nColumns: 4\n$ a1 &lt;int&gt; 2, 2, 2, 4, 4, 4, 2, 5, 4, 4, 5, 5, 1, 4, 1, 4, 5, 1, 1, 1, 1, 5, 1…\n$ c1 &lt;int&gt; 2, 4, 5, 3, 6, 4, 5, 4, 5, 5, 5, 4, 4, 5, 1, 4, 2, 5, 6, 6, 4, 5, 5…\n$ e1 &lt;int&gt; 3, 2, 4, 3, 5, 1, 3, 2, 3, 1, 2, 3, 2, 3, 6, 2, 3, 6, 3, 1, 3, 6, 6…\n$ o1 &lt;int&gt; 3, 3, 5, 3, 6, 5, 4, 5, 5, 6, 5, 6, 6, 6, 6, 4, 4, 5, 5, 6, 4, 3, 6…\n\nglimpse(bfi_women)\n\nRows: 1,881\nColumns: 4\n$ a1 &lt;int&gt; 2, 5, 4, 6, 2, 5, 4, 4, 4, 1, 2, 1, 2, 2, 2, 4, 1, 2, 2, 1, 1, 5, 2…\n$ c1 &lt;int&gt; 5, 4, 4, 6, 6, 5, 4, 5, 1, 5, 3, 5, 6, 4, 5, 5, 5, 5, 4, 6, 4, 5, 5…\n$ e1 &lt;int&gt; 1, 2, 5, 2, 2, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 3, 4, 6, 2…\n$ o1 &lt;int&gt; 4, 4, 3, 4, 5, 4, 5, 4, 4, 5, 6, 6, 5, 6, 2, 4, 4, 5, 5, 5, 4, 3, 5…\n\n\n\n\n4.3.3.2 Check out the subgroup correlations\nFor men, we can obtain the correlation between a1/e1 with the code below. From this we determine, r = .14, 95% [.07, .20], p &lt; .001.\n\ncor.test(bfi_men$a1, bfi_men$e1)\n\n\n    Pearson's product-moment correlation\n\ndata:  bfi_men$a1 and bfi_men$e1\nt = 4.2256, df = 910, p-value = 2.623e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.07447871 0.20182343\nsample estimates:\n      cor \n0.1387245 \n\n\nFor women, we can obtain the correlation between a1/e1 with the code below. From this we determine, r = .06, 95% [.02, .11], p = .007.\n\ncor.test(bfi_women$a1, bfi_women$e1)\n\n\n    Pearson's product-moment correlation\n\ndata:  bfi_women$a1 and bfi_women$e1\nt = 2.6809, df = 1847, p-value = 0.007408\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.01672024 0.10753950\nsample estimates:\n       cor \n0.06225875 \n\n\n\n\n4.3.3.3 Comparison r(a1, e1)\nWe run the R commands below to compare the correlations for men and women.\n\nlibrary(cocor)\nbfi_men_dataframe   &lt;- as.data.frame(bfi_men)\nbfi_women_dataframe &lt;- as.data.frame(bfi_women)\n\ncocor( ~ a1 + e1 | a1 + e1,\n       data = list(bfi_men_dataframe, bfi_women_dataframe))\n\n\n  Results of a comparison of two correlations based on independent groups\n\nComparison between r1.jk (a1, e1) = 0.1387 and r2.hm (a1, e1) = 0.0623\nDifference: r1.jk - r2.hm = 0.0765\nData: list(bfi_men_dataframe, bfi_women_dataframe): j = a1, k = e1, h = a1, m = e1\nGroup sizes: n1 = 912, n2 = 1849\nNull hypothesis: r1.jk is equal to r2.hm\nAlternative hypothesis: r1.jk is not equal to r2.hm (two-sided)\nAlpha: 0.05\n\nfisher1925: Fisher's z (1925)\n  z = 1.9074, p-value = 0.0565\n  Null hypothesis retained\n\nzou2007: Zou's (2007) confidence interval\n  95% confidence interval for r1.jk - r2.hm: -0.0021 0.1543\n  Null hypothesis retained (Interval includes 0)\n\n\nThe output reveals the correlation for men, \\(r_{(a1, e1)}\\) = 0.1387, .14 rounded, and women \\(r_{(a1, e1)}\\)= 0.0623, .06 rounded, in the output. We also see the comparison: Difference: r1.jk - r2.hm = 0.0765. Finally, we see the zou2007 95% confidence interval: -.00 to .15.\nWe write this up as:\nFor men, there was a positive relation between agreeableness (a1) and extraversion (e1), r = .14, 95% [.07, .20], p &lt; .001, such that as agreeableness increased so did extraversion. Likewise, for women, there was a similar positive relation between agreeableness (a1) and extraversion (e1), r = .06, 95% [.02, .11], p = .007. We did not find a significant difference in the strength of these relations, \\(\\Delta\\)r = .08, 95% CI [-.00, .15], p = .057.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regression and correlation</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html",
    "href": "multiple-regression.html",
    "title": "5  Multiple regression",
    "section": "",
    "text": "5.1 Overview\nThe following CRAN packages must be installed:\nThe following GitHub packages must be installed:\nAfter the remotes package is installed, it can be used to install a package from GitHub:\nMultiple regression is a means relating multiple predictor variables to a single criterion variable. We can determine the amount of variance in the criterion accounted for by the set of predictors (\\(R^2\\)), a single predictor on it’s own (\\(r^2\\)), or the extent to which a single predictor accounts for unique variance account for in the criterion that is not accounted for by any of the other predictors (\\(sr^2\\)).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#example",
    "href": "multiple-regression.html#example",
    "title": "5  Multiple regression",
    "section": "5.2 Example",
    "text": "5.2 Example\nIn this chapter, we examine the extent to video game scores are predicted by age and IQ for people who live in the City of Guelph. As before, we treat citizens of Guelph as our population – though in this chapter we move straight to the sample data (without showing the population-level data).\nWe are interested in using both IQ and age to predict video game scores so we refer to these variables as predictor variables. The value being predicted is video game score and we refer to that variable as the criterion (i.e., the dependent variable).\nYou can think of the multiple regression problem using a venn diagram:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#load-the-data",
    "href": "multiple-regression.html#load-the-data",
    "title": "5  Multiple regression",
    "section": "5.3 Load the data",
    "text": "5.3 Load the data\nWe use a data set called “data_mr_ex.csv” in this example. The data can be loaded with the command:\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nmy_data &lt;- read_csv(\"data_mr_ex.csv\")\n\n# ensure column names match desired naming convention\nmy_data &lt;- my_data %&gt;%\n  clean_names()\n\nWe see the structure of the data with the glimpse() command:\n\nglimpse(my_data)\n\nRows: 200\nColumns: 3\n$ video_game &lt;dbl&gt; 122.02, 108.67, 130.44, 123.38, 121.49, 125.67, 122.88, 109…\n$ iq         &lt;dbl&gt; 107.6, 100.9, 89.0, 90.3, 97.1, 108.1, 120.4, 90.5, 118.9, …\n$ age        &lt;dbl&gt; 41.1, 55.1, 43.9, 46.7, 42.1, 41.2, 41.7, 48.3, 48.2, 48.1,…",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#bivariate-relations",
    "href": "multiple-regression.html#bivariate-relations",
    "title": "5  Multiple regression",
    "section": "5.4 Bivariate relations",
    "text": "5.4 Bivariate relations\nWhen you conduct multiple regression analyses you should always report a correlation matrix with your predictors and criterion.\n\nlibrary(apaTables)\n\napa.cor.table(my_data)\n\n\n\nTable 0 \n\nDescriptive Statistics and Correlations\n \n\n  Variable      N   M      SD    1            2           \n  1. video_game 200 119.03 10.75                          \n                                                          \n                                                          \n                                                          \n  2. iq         200 102.00 15.00 .50**                    \n                                 [.39, .60]               \n                                 p &lt; .001                 \n                                                          \n  3. age        200 45.00  6.00  -.30**       -.20**      \n                                 [-.42, -.17] [-.33, -.07]\n                                 p &lt; .001     p = .004    \n                                                          \n\nNote. N = number of cases. M = mean. SD = standard deviation.\nValues in square brackets indicate the 95% confidence interval.\n * indicates p &lt; .05. ** indicates p &lt; .01.\n \n\n\nYou should always check for curvilinear relations when reporting correlations via a graph. We quickly create a graph for doing so with the code below. In this case we don’t see any curvilinear relations.\n\nlibrary(GGally)\n\nggpairs(my_data)\n\n\n\n\n\n\n\n\nYou can think of each bivariate correlation as the shaded areas on the figure below. In this type of figure the degree of overlap between two circles is determined by the correlation squared (i.r., \\(r^2\\)). The value you obtain for \\(r^2\\) indicates the proportion of the criterion that is covered by the predictor. For example, if \\(r\\) = .50 then \\(r^2\\) = .25 which indicates 25% of the criterion should be covered by the circle representing that predictor.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#single-best-predictor",
    "href": "multiple-regression.html#single-best-predictor",
    "title": "5  Multiple regression",
    "section": "5.5 Single best predictor",
    "text": "5.5 Single best predictor\nWhat is the best predictor of video_game? Many researchers incorrectly believe you need multiple regression to answer this question - you do not. To determine the single best predictor in a set of predictors just look at the correlation matrix above - no need for regression (or beta-weights). The strongest correlation is the best predictor. In our current example, video_game_score is predicted by iq (r = .50) and age (r = -.30). The best predictor of video_game_score is iq because it has the strongest correlation (using absolute values .50 is larger than .30).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#multiple-regression",
    "href": "multiple-regression.html#multiple-regression",
    "title": "5  Multiple regression",
    "section": "5.6 Multiple regression",
    "text": "5.6 Multiple regression\nMultiple regression is frequently used to ask two questions:\n\nHow well we can predict the criterion using a set of predictors (see \\(R^2\\))?\nWhat is the unique contribution of a single variable in a set or predictors? In other words, how much does one variable predict the criterion above and beyond another variable? For example, does study time predict exam grades above and beyond iq? Or phrased differently: Does study time predict unique variance in exam grades that is not accounted for by iq? (see \\(sr^2\\)).\n\nWe want to use age and IQ to predict video game score (\\(Y\\)). More specifically, we want to combine age and IQ to create a new variable (\\(\\widehat{Y}\\)) that correlates as highly as possible with video game score. We do with the code below:\n\nlm_object &lt;- lm(video_game ~ age + iq,\n                    data = my_data)\n\nNow look at the brief output:\n\nprint(lm_object)\n\n\nCall:\nlm(formula = video_game ~ age + iq, data = my_data)\n\nCoefficients:\n(Intercept)          age           iq  \n   102.2333      -0.3712       0.3285  \n\n\nThis output shows you how we can combine age, IQ, and a constant to create (\\(\\widehat{Y}\\)).\nMore specifically: \\(\\widehat{Y} = 102.233 - 0.0371(age) + 0.328(iq)\\)\nThe slopes for age and iq are -0.0371 and 0.328, respectively. These are also referred to as the b-weights or unstandardized regression coefficients. The computer picks these weight so that predicted video game scores (\\(\\widehat{Y}\\)) will corresponds as closely as possible to actual video game scores.\nA quick way to get more comprehensive regression output is to use the apa.reg.table function in the apaTables package.\n\nlibrary(apaTables)\n\napa.reg.table(lm_object,\n              filename = \"table_regression.doc\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#b-weights",
    "href": "multiple-regression.html#b-weights",
    "title": "5  Multiple regression",
    "section": "5.7 b-weights",
    "text": "5.7 b-weights\nAn inspection of the b column in the above table reveals the b-weights we previously discussed. The b-weights are also known as the slopes or the unstandardized regression weights. The b-weights are used to create predicted/estimated video game score via the regression equation:\n\\[\n\\begin{aligned}\n\\widehat{Y} &= 102.233 + 0.3285(Z) - 0.3712(X) \\\\\n\\widehat{\\text{video game}} &= 102.233 + 0.3285(iq) - 0.3712(age) \\\\\n\\end{aligned}\n\\]\nYou can think of the regression equation as a receipe for making \\(\\hat{Y}\\). The variables in the regression (e.g., age and iq) are the ingredients. The b-weights (e.g., 0.3285 and 00.3712) are the amount of each ingredient you need to make \\(\\hat{Y}\\).\nAs previously noted, the computer picks the b-weights using a process that ensures the predicted video game scores (\\(\\hat{Y}\\)) corresponds as closely as possible to actual video game scores (\\(Y\\)). Consider the regression calculation for Person 1, below, who is 41.7 years old and has an IQ of 107.6.\n\\[\n\\begin{aligned}\n\\widehat{Y} &= 102.233 + 0.3285(Z) - 0.3712(X) \\\\\n\\widehat{\\text{video game}} &= 102.233 + 0.3285(iq) - 0.3712(age) \\\\\n&= 102.233 + 0.3285(107.6) - 0.3712(41.1) \\\\\n&= 122.3\n\\end{aligned}\n\\]\nThe above calculation reveals an estimated video game score for Person 1 of 122.3 (i.e., \\(\\hat{Y} = 122.3\\)) – which differs only slightly from their actual video game score of 122 (i.e.. \\(Y = 122\\)). You can see the similarity between actual video game scores (\\(Y\\)) and predicted video game scores (\\(\\hat{Y}\\)) for the first several participants in the table below.\n\n\n\n\n\n\n\n\n\nYou can interpret the b-weights as indicating how much the criterion changes when a predictor changes – holding the other predictors constant. In this context, a 0.3285 b-weight for IQ indicates that for each one-unit increase in IQ video game score will increase 0.3285 points – holding the effect of age constant. Don’t forget the b-weight can only be interpreting in context of that specific regression equation. If you replaced the age predictor with, say, height as a predictor, then the b-weight for IQ would change. Context matters when interpreting b-weights.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#r2",
    "href": "multiple-regression.html#r2",
    "title": "5  Multiple regression",
    "section": "5.8 \\(R^2\\)",
    "text": "5.8 \\(R^2\\)\nHow effective is the set of predictors? We can calculate \\(R^2\\) to determine the proportion of variance the criterion that is accounted for by the set of predictors. This value is illustrated graphically below:\n\n\n\n\n\n\n\n\n\nYou will simply obtain \\(R^2\\) from computer output. But how is \\(R^2\\) calculated? Understanding how \\(R^2\\) is calculated can help you to understand how to interpret it. There are two methods for doing so - that produce the same number:\n\n5.8.1 Method 1: Ratio Approach\nWhat does the \\(R^2\\) mean? It is the proportion variability in criterion scores (\\(Y\\)) accounted for by (\\(\\widehat{Y}\\)). In other words, it is the proportion of the variability in criterion scores that can be accounted for by (a linear combination of) iq and age.\nWe begin by obtaining predicted video game scores (\\(\\widehat{Y}\\)) using the regression:\n\\(\\widehat{Y} = 102.233 + 0.3285(iq) - 0.3712(age)\\)\npredicted_video_game_scores \\(= 102.233 + 0.3285(iq) - 0.3712(age)\\)\nThe code below uses the above equation to calculate predicted video game score for each person:\n\npredicted_video_game_scores  &lt;- predict(lm_object)\n\nactual_video_game_scores &lt;- my_data$video_game\n\nRecall the formula for \\(R^2\\):\n\\[\n\\begin{aligned}\nR^2 = \\frac{\\text{Variance of predicted scores}}{\\text{Variance of actual scores}}\n\\end{aligned}\n\\]\nWe implement this formula using the code below:\n\nvar_predicted_video_game_scores &lt;- var(predicted_video_game_scores ) \nvar_actual_video_game_scores   &lt;-  var(actual_video_game_scores)\n\nR2 &lt;- var_predicted_video_game_scores / var_actual_video_game_scores\n\nprint(R2)\n\n[1] 0.2911182\n\n\nThus, 29% of the variability in video game scores is predicted by the combination of age and IQ.\n\n\n5.8.2 Method 2: Correlation Approach\nAn alternative way of thinking about \\(R^2\\) is as the squared correlation between predicted criterion scores and actual criterion scores:\n\\[\n\\begin{aligned}\nR^2 &= r^2_{\\hat{Y}, Y}\\\\\n&= r^2_{(predicted_video_game_scores, actual_video_game_scores)}\\\\\n\\end{aligned}\n\\]\nWe implement this formula with the code below and obtain the same value:\n\nR &lt;- cor(predicted_video_game_scores, actual_video_game_scores)\n\nR2 &lt;- R * R\nprint(R2)\n\n[1] 0.2911182\n\n\n\n\n5.8.3 \\(R^2\\) in practice\nIn practice we simply look at the apa.reg.table() output and obtain the \\(R^2\\) value and 95% CI from this output:\n\n\n\n\n\n\n\n\n\nFrom this table we determine: \\(R^2\\) = .29, 95% CI [.19, .38]. to obtain the required p-value we use the summary() command on the previously calculated lm_object:\n\nsummary(lm_object)\n\n\nCall:\nlm(formula = video_game ~ age + iq, data = my_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.6583  -5.4797   0.6023   6.3278  20.5394 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 102.23331    7.33860  13.931  &lt; 2e-16 ***\nage          -0.37115    0.10983  -3.379 0.000876 ***\niq            0.32846    0.04391   7.480  2.4e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.101 on 197 degrees of freedom\nMultiple R-squared:  0.2911,    Adjusted R-squared:  0.2839 \nF-statistic: 40.45 on 2 and 197 DF,  p-value: 1.912e-15\n\n\nAt the bottom of this output we see that the p-value is 1.912e-15 or 0.000000000000001912. Consequently, we report the \\(R^2\\) value as: \\(R^2\\) = .29, 95% CI [.19, .38], \\(p\\) &lt; .001. Thus, 29% of the variability in video game scores is predicted by the combination of age and IQ.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#semi-partial-sr",
    "href": "multiple-regression.html#semi-partial-sr",
    "title": "5  Multiple regression",
    "section": "5.9 Semi-partial (\\(sr\\))",
    "text": "5.9 Semi-partial (\\(sr\\))\nA semi-partial correlation is represented by the symbol \\(sr\\) and correspondingly a squared semi-partial correlation is represented by the symbol \\(sr^2\\). What is a squared semi-partial correlation and why is it useful?\nSemi-partial correlations are a way of determining the unique contribution of a variable to predicting the criterion (in the context of the other predictors). The semi-partial correlation is the correlation of one predictor (with all the other predictors removed) with the criterion. The semi-partial correlation squared is the amount \\(R^2\\) would drop by if that variable was removed from the regression. It is the percentage of variability in criterion scores that is uniquely accounted for by a predictor. This is illustrated in the venn diagram below:\n\n\n\n\n\n\n\n\n\n\n5.9.1 \\(sr^2\\) in theory\nIn the text below we go “inside the black box” to show you how semi-partial correlations are computed. In practice, they are just displayed in R output - but understanding the text below where we calculate them “old school” will help with you interpret \\(sr^2\\).\nOverall, squared semi-partial correlations provide an index of how much that predictor contributes to the overall \\(R^2\\) (with the effect of the other predictors removed). We calculate \\(sr^2\\) for IQ (removing the effect of age) to demonstrate this fact. We do this with a regression equation in which we make IQ the criterion (\\(Y\\)). Then we predict IQ with age. This produces my_iq_regression which has inside of it a predictor version of IQ, \\(\\widehat{Y_{iq}}\\), which in this case represents a best guess of IQ based on age.\n\nmy_iq_regression &lt;- lm(iq ~ age, data = my_data)\n\nprint(my_iq_regression)\n\n\nCall:\nlm(formula = iq ~ age, data = my_data)\n\nCoefficients:\n(Intercept)          age  \n   124.7626      -0.5059  \n\n\n. Thus, we find: \\(\\widehat{Y_{iq}} = 124.763 - 0.506(age)\\)\nConsequently, when you see \\(\\widehat{Y_{iq}}\\) recognize that it is really just an estimate of IQ created entirely from age. In contrast, \\(Y_{iq}\\) is the actual IQ score we obtained from participants.\nWe want IQ with the effect of age removed. Therefore, we want IQ (i.e., \\(Y_{iq}\\)) with the effect of age (i.e.,\\(\\widehat{Y_{iq}}\\) ) removed.\nThus we want: residual = \\(Y_{iq}\\) - \\(\\widehat{Y_{iq}}\\)\nor another way of thinking of it is:\niq_without_age = \\(Y_{iq}\\) - \\(\\widehat{Y_{iq}}\\)\niq_without_age = iq - (124.763 - 0.506(age) )\nWe do this below:\n\niq_without_age &lt;- resid(my_iq_regression) \n\nThen we correlate IQ without age (i.e., iq_without_age) with video game scores (i.e., video_game). This tells us how IQ correlates with video game scores when the effects of age have been removed from IQ; that is, the semi-partial correlation (i.e., \\(sr\\)). Once again refer to the venn diagram above illustrating \\(sr^2\\).\n\n# apa.reg.table does this for you - this is for learning/illustration only.\n\nsr  &lt;- cor(iq_without_age, my_data$video_game)\nsr2 &lt;- sr * sr\n\n\n\n5.9.2 \\(sr^2\\) in practice\nThe \\(sr^2\\) values with confidence intervals are reported in apa.reg.table() output:\n\n\n\n\n\n\n\n\n\nFrom this table we determine:\n\nage: \\(sr^2\\) = .04 , 95% CI [-.01, .09]\niq: \\(sr^2\\) = .20, 95% CI [.11, .30]\n\nHowever, to obtain the p-value for each \\(sr^2\\) value we need to use the summary() command:\n\nsummary(lm_object)\n\n\nCall:\nlm(formula = video_game ~ age + iq, data = my_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.6583  -5.4797   0.6023   6.3278  20.5394 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 102.23331    7.33860  13.931  &lt; 2e-16 ***\nage          -0.37115    0.10983  -3.379 0.000876 ***\niq            0.32846    0.04391   7.480  2.4e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.101 on 197 degrees of freedom\nMultiple R-squared:  0.2911,    Adjusted R-squared:  0.2839 \nF-statistic: 40.45 on 2 and 197 DF,  p-value: 1.912e-15\n\n\nThe p-value for the b-weight (i.e. Estimate) is the p-value for \\(sr^2\\), Therefore, we simply look in the Pr(&gt;|t|) column to obtain the required p-value. Adding this value to our reporting, we find:\n\nage: \\(sr^2\\) = .04 , 95% CI [-.01, .09], p &lt; .001\niq: \\(sr^2\\) = .20, 95% CI [.11, .30], p &lt; .001\n\nIf a predictor is significant, this indicates that the predictor contributes unique variance to \\(\\widehat{Y_{video game}}\\) that can not be contributed by any of the other predictors. The amount of unique variance contributed by a predictor is indicated by \\(sr^2\\) (semi-partial correlation squared).\n\n\n5.9.3 Blocks regression\nSome researchers are unfamiliar with semi-partial correlations and prefer to think in term of how the \\(R^2\\) value changes over two different regression. This approach is just an indirect way of calculating \\(sr^2\\).\nConsider the example below where the researcher conducts the first regression, block 1, in which age is the predictor. Then he conducts a second regression, block 2, in which both age and iq are the predictors.\n\n# apa.reg.table does this for you - this is for learning/illustration only.\n\nblock1 &lt;- lm(video_game ~ age,\n             data = my_data)\n\nblock2 &lt;- lm(video_game ~ age + iq,\n             data = my_data)\n\nThe goal is to examine the \\(R^2\\) when only age is the predictor and see how much it increases when you have both age and iq as predictors. The resulting difference, \\(\\Delta R^2\\) tells you how much iq predicted video game score beyond age alone. Examine the output below.\n\napa.reg.table(block1, block2,\n              filename = \"table_mr_blocks.doc\")\n\n\n\n\n\n\n\n\n\n\nThis table illustrates that for the first regression when just age was a predictor that \\(R^2\\) = .09. When both age and iq were predictors \\(R^2\\) = .29. That indicates that \\(R^2\\) increased by .20 when we added iq as a predictor. Thus, \\(\\Delta R^2\\) = .20. This is the amount \\(R^2\\) increased by due to adding iq as predictor. Conceptually, and mathematically, this is identical to the \\(sr^2\\) value for iq. Indeed, if you look at this output in detail you see that for iq \\(sr^2\\) = .20.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#beta-weights",
    "href": "multiple-regression.html#beta-weights",
    "title": "5  Multiple regression",
    "section": "5.10 Beta-weights",
    "text": "5.10 Beta-weights\nBeta-weights are often referred to as standardized regression weights. This is a poor description that makes beta weights hard to understand. A better description of beta-weights is the regression weights for standardized variables; that is variables with a mean of 0 and a standard deviation of 1.0.\n\n5.10.1 In practice\nRecall we ran a regression with the command below. This command used the original/raw form of the variables.\n\nlm_object &lt;- lm(video_game ~ age + iq,\n                    data = my_data)\n\nFrom lm_object created we used apa.reg.table() to obtain this output:\n\n\n\n\n\n\n\n\n\nNotice the beta column in this output. It reports beta weights of -.21 and .46 for age and iq, respectively. Where did these values come from?\nTo answer this question, we need to start with the lm_object. The apa.reg.table() command just formats the information contained in the lm_object. We can see an unformatted version of this information with the summary() command:\n\nsummary(lm_object)\n\n\nCall:\nlm(formula = video_game ~ age + iq, data = my_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.6583  -5.4797   0.6023   6.3278  20.5394 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 102.23331    7.33860  13.931  &lt; 2e-16 ***\nage          -0.37115    0.10983  -3.379 0.000876 ***\niq            0.32846    0.04391   7.480  2.4e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.101 on 197 degrees of freedom\nMultiple R-squared:  0.2911,    Adjusted R-squared:  0.2839 \nF-statistic: 40.45 on 2 and 197 DF,  p-value: 1.912e-15\n\n\nNotice that the values in the Estimates column correspond to the b-weights column in the apa.reg.table() output. We will use this fact to create beta-weights.\n\n\n5.10.2 Old school\nTo obtain beta-weights there are two steps. First, we create standardized score versions of each column. Second, we run a normal regression using those columns.\nA set of standardized scores have a mean of 0 and a standard deviation of 1.0. To create the standardized score versions of each column in the regression we use the z-score formula:\n\\[\n\\begin{aligned}\n\\text{standardized scores}=z_{X} = \\frac{X-\\bar{X}}{\\sigma_X}\n\\end{aligned}\n\\]\nConsider the age column. We can calculate the mean for this column, mean(age), and the standard deviation for this column, sd(age). Then for every value in the age column we subtract the column mean and then divide by the column standard deviation. We do so with the calculation: (age-mean(age))/sd(age). The code below creates standardized score versions of the iq, age, and video_game columns called z_iq, z_age, and z_video_game, respectively.\n\nmy_data &lt;- my_data %&gt;% \n  mutate(z_iq = (iq-mean(iq))/sd(iq),\n         z_age = (age-mean(age))/sd(age),\n         z_video_game = (video_game-mean(video_game))/sd(video_game))\n\nWe can confirm a mean of 0 and a standard deviation of 1.0 for these new columns with the skim command:\n\nlibrary(skimr)\nskim(my_data)\n\nNow we conduct the regression again with standardized variables (i.e., z-score versions).\n\nlm_object_zscores &lt;- lm(z_video_game ~ z_iq + z_age,\n                        data = my_data)\n\nWe can obtain the regression weights for analysis using these standardized scores with the summary() command:\n\nsummary(lm_object_zscores) \n\n\nCall:\nlm(formula = z_video_game ~ z_iq + z_age, data = my_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4788 -0.5095  0.0560  0.5884  1.9098 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.732e-16  5.984e-02   0.000 1.000000    \nz_iq         4.582e-01  6.125e-02   7.480  2.4e-12 ***\nz_age       -2.070e-01  6.125e-02  -3.379 0.000876 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8462 on 197 degrees of freedom\nMultiple R-squared:  0.2911,    Adjusted R-squared:  0.2839 \nF-statistic: 40.45 on 2 and 197 DF,  p-value: 1.912e-15\n\n\nNotice that the estimates above are 4.582e-01 -2.070e-01 which are, in decimal form, .46 and -.21, respectively. These are the beta-weights from the apa.reg.table on the previous page. Thus, when you conduct a normal regression but used standardized variables in it you obtain beta-weights.\nInterpretation. The typically reported b-weights describe how a 1 unit change in IQ influences video_game points. Similarly, beta-weights, describe how a 1 unit change in z_iq influences z_video_game. Keep in mind, however, that 1 unit of z_iq (and z_video_game) is 1 standard deviation. As a result, a beta-weight indicates how much the criterion scores will change in SD units when a predictor increases by 1 SD – holding the effect of the other predictors constant. Similar to b-weights, beta-weights can only be interpreted in the context of the other variables in the equation.\nHopefully, this description has made it clear that although beta-weights are often referred to as standardized regression weights; it would be more accurate to describe them as the weights for standardized variables.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#graphing",
    "href": "multiple-regression.html#graphing",
    "title": "5  Multiple regression",
    "section": "5.11 Graphing",
    "text": "5.11 Graphing\nLet’s take a minute to consider the nature of the data we have so far - examine the first few rows of the data below (that includes the predicted value for each person).\n\n\n\n\n\n\n\n\n\nYou can see that each person has three measured variables associated with them: video_game_score, iq, and age. These columns are in blue to indicate the fact they are measured variables. Because we have three measured variables we can’t create a typical 2D scatter plot. That type of plot only work when there is one predictor and one criterion. Now we have two predictors and one criterion. Consequently, we need make a 3D scatter plot.\nCorrespondingly, because we have two predictors, we can’t obtain a regression line (i.e., best-fit line). A regression line is only possible when there is one predictor. Now we have two predictors. Consequently, a regression surface is required to show the predicted values for combinations of age and iq. In this case, when there are two predictor variables, the regression surface is a plane.\nLet’s create the 3D scatter plot with a regression surface. You recall we previously created the lm_object when we ran our regression:\n\nlm_object &lt;- lm(video_game ~ age + iq,\n                    data = my_data)\n\nThe lm_object has the three data point for each person (age, iq, video_game) embedded inside of it. So we can use the lm_object to create the scatter plot with regression plane. We do so using the fastInteraction package. More specifically, we use the fast.plot command as illustrated below.Note: The fast.plot command uses the argument “moderator” which is not appropriate in our context. When you see moderator in the command below just think of it as another predictor.\n\nlibrary(fastInteraction)\n\nsurface_plot &lt;- fast.plot(lm_object,\n                          criterion = video_game,\n                          predictor = iq,\n                          moderator = age)\n\nThen just type:\n\nsurface_plot\n\nYou can see the graph below:\n\n\n\n\n\n\n\n\n\nAll of the predicted scores fall on the regression surface. You can think of the regression surface as a best-fit plane. In some sense you can think of the plane as a collection of best-fit lines. Indeed, two illustrative best-fit lines are place on this surface. For all the best-fit lines on the plane the slopes are the same - just the intercepts differ. You can see the people relative to the predicted surface/plane by looking at the dots. Each dot represents a person.\nTry the interactive version of the graph below. Caveat, sometimes it doesn’t appear correctly on the web. If the graph appears incorrectly (e.g., no data points or no surface) try using the Chrome browser. Safari sometimes has problems with this web object. You can rotate the graph to see a better view of the surface. The graph illustrates that predicted video game scores (i.e., the surface) change as a function of both age and iq.\n\nsurface_plot",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#control-variables",
    "href": "multiple-regression.html#control-variables",
    "title": "5  Multiple regression",
    "section": "5.12 Control variables",
    "text": "5.12 Control variables\nMany people use “control” variables in their multiple regression. Before using this type of analysis I urge you to read:\nWysocki, A. C., Lawson, K. M., & Rhemtulla, M. (2022). Statistical control requires causal justification. Advances in Methods and Practices in Psychological Science, 5(2), 25152459221095823.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "mr-sample-size.html",
    "href": "mr-sample-size.html",
    "title": "6  Sample size for multiple regression",
    "section": "",
    "text": "6.1 Sample size using \\(R^2\\)\nWhen you conduct a multiple regression there are two ways to think about conducting a sample size analysis.\nYou want to run a multiple regression study in an existing research area using 3 predictors. A past study, \\(N\\) = 100, found an \\(R^2=.20\\). How many people do you need in your study to have 80% power for the overall regression equation (i.e., \\(R^2\\)).\nWe need to determine two pieces of information to proceed: 1) the effect size as \\(f^2\\) instead of \\(R^2\\) and 2) the degrees of freedom for the predictors. We use these two pieces of information in the pwr command.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sample size for multiple regression</span>"
    ]
  },
  {
    "objectID": "mr-sample-size.html#sample-size-using-r2",
    "href": "mr-sample-size.html#sample-size-using-r2",
    "title": "6  Sample size for multiple regression",
    "section": "",
    "text": "6.1.1 Determining \\(f^2\\)\nWe need to represent \\(R^2\\) as \\(f^2\\). We do this with the formula:\n\\[\nf^2=\\frac{R^2}{1-R^2}\n\\]\nSo in R we type:\n\nmy_f2 &lt;- .20 / (1 - .20)\nprint(my_f2)\n\n[1] 0.25\n\n\nThus, \\(f^2=.25\\).\n\n\n6.1.2 Determine degrees of freedom\nThere are degrees of freedom for the predictors (\\(u\\)) and error (\\(v\\)) in the original study. The degrees of freedom for the predictors is easy to compute:\nDegrees of Freedom Predictors: \\(u =\\) number of predictors = 3.\n\n\n6.1.3 Calculate sample size\nWith multiple regression we send R the effect size (.25) the degrees of freedom for the predictor (3). The output provide returns the degrees of freedom for the denominator - which requires a bit of work to convert to sample size.\nWe begin with the R code below:\n\nlibrary(pwr)\npwr.f2.test(u = 3,\n            f2 = .25,\n            power = .90)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 56.75331\n             f2 = 0.25\n      sig.level = 0.05\n          power = 0.9\n\n\nWhat does this output mean? It provides us with the degrees of freedom error (i.e., \\(v\\)) for your study (not the original study). We need to use the degrees of freedom error to calculate the \\(N\\) needed.\nDegrees of Freedom Error: \\(v = N - u - 1\\) therefore \\(N = u + v + 1\\).\nWe know \\(u = 3\\) because there were three predictors. Our power analysis revealed we need \\(v = 57\\) in our study.\nTherefore \\(N = u + v + 1 = 3 + 57 + 1\\)\n\nN = 3 + 57 + 1\nprint(N)\n\n[1] 61\n\n\nThus we want an N of 61 in our study.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sample size for multiple regression</span>"
    ]
  },
  {
    "objectID": "mr-sample-size.html#sample-size-using-sr2",
    "href": "mr-sample-size.html#sample-size-using-sr2",
    "title": "6  Sample size for multiple regression",
    "section": "6.2 Sample size using \\(sr^2\\)",
    "text": "6.2 Sample size using \\(sr^2\\)\nYou want to run a multiple regression study in an existing research area using 3 predictors (A, B, and C). A past study, \\(N\\) = 100, found an \\(R^2=.20\\). You are particularly interested in one predictor (predictor C) that you think will account for 2% of the variance in the criterion above and beyond the other two predictors. Said another way you believe .02 of the .20 will be a result of the unique contribution of one predictor. What sample size do you need to ensure you have power of .90 for detecting this increment in variance.\nLet’s think about this scenario in terms of Blocks to make it a bit clear. You are describing a scenario where if you put predictors A and B are in Block 1 you would obtain an overall \\(R^2 = .18\\). Then when you put Predictor A, B, and C into Block 2 you would obtain an overall \\(R^2 = .20\\), an increment of .02 so \\(sr^2\\) for predictor C is .02.\nWe want to conduct a power analysis to determine how many people you need to ensure power of .90 for this incremental prediction effect.\n\n6.2.1 Determine degrees of freedom\nWe are interested in the incremental prediction of one variable so \\(u = 1\\).\n\n\n6.2.2 Determine \\(f^2\\)\nWe know \\(sr^2=.02\\) and \\(R^2  = .20\\). We can use these to compute the needed \\(f^2\\).\n\\[\nf^2=\\frac{sr^2}{1-R^2}\n\\]\nSo we type:\n\nmy_f2 &lt;- .02 / (1 - .20)\n\nprint(my_f2)\n\n[1] 0.025\n\n\n\n\n6.2.3 Calculate power\nWe can calculate the required degrees of freedom with the command below:\n\nlibrary(pwr)\npwr.f2.test(u = 1,\n            f2 = 0.025,\n            power = .90)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 420.2268\n             f2 = 0.025\n      sig.level = 0.05\n          power = 0.9\n\n\nThus, degrees of freedom error (i.e., \\(v\\)) is 421\nWe then calculate \\(N = u + v + 1\\)\nIn R we type:\n\nN = 1 + 421 + 1\nprint(N)\n\n[1] 423\n\n\nThus, you need an \\(N\\) of 423.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sample size for multiple regression</span>"
    ]
  },
  {
    "objectID": "mr-sample-size.html#power-obtained-sr2",
    "href": "mr-sample-size.html#power-obtained-sr2",
    "title": "6  Sample size for multiple regression",
    "section": "6.3 Power obtained \\(sr^2\\)",
    "text": "6.3 Power obtained \\(sr^2\\)\nImagine your power analysis tells you that you need an \\(N\\) of 423 but you only get an \\(N\\) of 75. What is your power? Simply calculate the degrees of freedom for the predictors and error and run the command again. This time you leave out power. It will be calculated for you. You can do this before you collect your data if you know in advance you will have a low/restricted \\(N\\) - as is the case for many theses.\nIn this example, \\(R^2=.20\\) and \\(sr^2=.02\\) are the expected effect sizes.\nDegrees of Freedom Predictors: \\(u = 1\\) as above (incremental prediction of one variable)\nIn terms of error:\nDegrees of Freedom Error: \\(v = N - u - 1 = 75 - 1 - 1 = 73\\).\nIn terms of effect size:\n\\(f^2=\\frac{sr^2}{1-R^2} = \\frac{.02}{1-.20}=.025\\).\n\npwr.f2.test(u = 1,\n            v = 73,\n            f2 = 0.025)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 73\n             f2 = 0.025\n      sig.level = 0.05\n          power = 0.2718443\n\n\nIn this case, power is .27. Thus, there is only a 27% chance of finding the effect if it exists. Given this, would it make sense to spend the time and energy to run the study?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sample size for multiple regression</span>"
    ]
  },
  {
    "objectID": "mmr.html",
    "href": "mmr.html",
    "title": "7  Moderated multiple regression",
    "section": "",
    "text": "7.1 Overview\nThe following CRAN packages must be installed:\nThe following GitHub packages must be installed:\nAfter the remotes package is installed, it can be used to install a package from GitHub:\nIn this chapter we present a brief overview of moderated multiple regression. In an ANOVA you can have two variables interact to predict a dependent variable. In this ANOVA scenario, the predictors are the categorical ANOVA variables. When our predictors are continuous variables (e.g., height, weight, etc) they can still interact to predict the dependent variable (i.e., criterion). In this chapter we primarily focus on how to obtain the required information from R to write up a continous variable interaction (also known as a moderated multiple regression). For an understanding of the underlying theory I strongly encourage you to read Chapter 7: Interactions among continuous variables in Cohen, Cohen, West, and Aiken (2003):\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2013). Applied multiple regression/correlation analysis for the behavioral sciences. Routledge.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Moderated multiple regression</span>"
    ]
  },
  {
    "objectID": "mmr.html#scenario",
    "href": "mmr.html#scenario",
    "title": "7  Moderated multiple regression",
    "section": "7.2 Scenario",
    "text": "7.2 Scenario\nImagine a scenario where we are interested in predicted endurance from participant age and exercise.\nWe can load the data:\n\nlibrary(tidyverse)\n\ndata_endurance &lt;- read_csv(\"data_endurance.csv\")\n\nWe can see the structure of the data:\n\nglimpse(data_endurance)\n\nRows: 245\nColumns: 4\n$ id        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ age       &lt;dbl&gt; 60, 40, 29, 47, 48, 42, 55, 43, 39, 51, 54, 52, 53, 68, 57, …\n$ exercise  &lt;dbl&gt; 10, 9, 2, 10, 9, 6, 8, 19, 9, 14, 15, 4, 3, 17, 24, 4, 4, 16…\n$ endurance &lt;dbl&gt; 18, 36, 51, 18, 23, 30, 8, 40, 28, 15, 49, 27, 12, 43, 47, 2…",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Moderated multiple regression</span>"
    ]
  },
  {
    "objectID": "mmr.html#overview-1",
    "href": "mmr.html#overview-1",
    "title": "7  Moderated multiple regression",
    "section": "7.3 Overview",
    "text": "7.3 Overview\n\n7.3.1 No interaction\nIn a typical two variable regression we would attempt to solve this equation:\n\\[ \\hat{Y} = b_0 + b_1age + b_2exercise \\] We would do so using this R code:\n\nlm_no_int &lt;- lm(endurance ~ age + exercise,\n                data = data_endurance)\n\nThe result would be the a regression surface that fits the data as illustrated below. In this graph we did not assess whether there was an interaction (i.e., a moderating effect). This is just a standard two predictor regression. We illustrate the extent to which exercise and age predict endurance. You can consider the regression surface a series of best-fit lines. All of the lines on this surface have the same slope. That means in this statistical model the relation between exercise and endurance is not influenced by age – because the slopes of the lines on the surface are the same and do not change with age of participants.\n\n\n\n\n\n\n\n\n\n\n\n7.3.2 Interaction\nWe might wonder if the relation between exercise (a predictor) and endurance (the criterion) depends on the age of participants (a predictor). In other words, we might wonder if the relation between exercise and endurance is moderated by age. This is conceptually identical to an interaction effect in an ANOVA.\nWe determine if there is a moderated relation by adding a product term to the regression. This is simply a new data column created by multiplying the age and exercise columns. If the b-weight (i.e., \\(b_3\\)) for for this product column (i.e., age*exercise) is significant - we say there is an interaction or a moderated relation. The regression equation we need to solve is below:\n\\[ \\hat{Y} = b_0 + b_1age + b_2exercise + b_3(age)(exercise)\\]\nWe solve this equation using the code:\n\nlm_int &lt;- lm(endurance ~ age + exercise + I(age*exercise),\n             data = data_endurance)\n\nWhen we examined the output for this regression, we found that that \\(b_3\\) was significant. This indicates there is a moderated relation. The relation between exercise and endurance does depend on age. We can see this moderated relation in the graph below. As before imagine the surface is composed of a series of best-fit lines. Because there is a moderated relation the slopes of the lines change as we move across this surface. You can see this clearly in the graph below. This illustrate the slope for the exercise – endurance relation changes depending on the age of participants. That is, it illustrates the nature of the moderated relation.\n\n\n\n\n\n\n\n\n\n\n\n7.3.3 Comparison\nWe present both graphs below so you can more easily see the difference between them. When you look at the No Interaction graph you can see the best-fit surface is composed of a series of straight lines that are parallel (i.e., all have the same slope) but all orientated a particular angle. In contrast, when you look at the Interaction graph you can see that it is also composed of a series of straight lines but the overall surface looks curves because the lines composing the best-fit surface have different slopes.\nInterpretation note: Notice that the difference between the No Interaction surface and the Interaction surface is the largest near the edges of the surface. Consequently, the inclusion of product terms typically makes the largest improvement in fit for the people who score at the extremes of the surface. In contrast, the inclusion of product terms typically makes a minor improvement in fit for the people who are near the middle of the surface (i.e., the majority of people). Keep that in mind as you interpret the increase in fit that results from the inclusion of the product terms.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Moderated multiple regression</span>"
    ]
  },
  {
    "objectID": "mmr.html#fastinteraction",
    "href": "mmr.html#fastinteraction",
    "title": "7  Moderated multiple regression",
    "section": "7.4 fastInteraction",
    "text": "7.4 fastInteraction\nIf you want to actually conduct a moderated regression and solve the equation below, there is an easy way to do it.\n\\[ \\hat{Y} = b_0 + b_1age + b_2exercise + b_3(age)(exercise)\\]\nYou simply use the fast.int() command in the fastInteraction package does the following:\n\nConducts the regression (i.e., the lm command); including mean centering of predictors if desired (see Cohen, Cohen, West, and Aiken, 2003).\nCreates the 2D graph\nCreates the 3D graph\nCreates two APA style tables to describe the analyses\n\nTo run the analysis you use the code below:\n\nlibrary(fastInteraction)\n\nnew_axis_labels &lt;- list(criterion = \"Endurance\",\n                        predictor = \"Age (centered)\",\n                        moderator = \"Exercise (centered)\")\n\nmmr_output &lt;- fast.int(data = cohen_exercise,\n                       criterion = endurance,\n                       predictor = age,\n                       moderator = exercise,\n                       center.predictors = TRUE,\n                       axis.labels = new_axis_labels,\n                       path = \"tables_mmr.doc\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the fastInteraction package.\n  Please report the issue to the authors.\n\n\n[1] \"Predictor\"\n[1] \"b\"\n[1] \"b_95_CI\"\n[1] \"Unique_R2\"\n[1] \"sr2_95_CI\"\n[1] \"p\"\n[1] \"Fit\"\n[1] \"Predictor\"\n[1] \"b\"\n[1] \"b_95_CI\"\n[1] \"Unique_R2\"\n[1] \"sr2_95_CI\"\n[1] \"p\"\n[1] \"Fit\"\n[1] \"moderator\"\n[1] \"moderator.value\"\n[1] \"b1.slope\"\n[1] \"b1.LL\"\n[1] \"b1.UL\"\n[1] \"b0.intercept\"\n[1] \"b1.SE\"\n[1] \"t\"\n[1] \"p\"\n[1] \"moderator\"\n[1] \"moderator.value\"\n[1] \"b1.slope\"\n[1] \"b1.LL\"\n[1] \"b1.UL\"\n[1] \"b0.intercept\"\n[1] \"b1.SE\"\n[1] \"t\"\n[1] \"p\"\n\n\n\n7.4.1 Graphing in 3D\nYou can obtain the 3D graph (which can be rotated) using the code below. The graph may not appear on this webpage if you are using Chrome.\n\nmmr_output$graph3D\n\n\n\n\n\n\n\n7.4.2 Unformatted 2D graph\nYou can obtain the 2D graph (cross-section of the 3D surface) with the code below. We need to adjust the graph a bit before it’s presentable. But to do so we first need to inspect tables created by the fast.int() command.\n\nunformatted_ggplot_graph &lt;- mmr_output$graph2D.unformatted\n\nprint(unformatted_ggplot_graph)\n\n\n\n\n\n\n\n\n\n\n7.4.3 Tables\nWe inspect MS Word file created by the fast.int() command below. The commands save the table in the file “tables_mmr.doc” – as specified. It presents the results of the various regression in tables corresponding to APA style.\n\n\n\n\n\n\n\n\n\n\n\n7.4.4 Formatted 2D graph\nWe inspect the Table output and find the value for -1/+1 SD of the moderator (age) in Table 2. In this case, we find the value is 4.775. So we use this to set the x-axis ticks That way the ticks on the x-axis correspond to standard deviations.\n\ncustom_formatted_ggplot_graph &lt;- unformatted_ggplot_graph +\n  coord_cartesian(ylim = c(10, 40)) +\n  scale_y_continuous(breaks = seq(10, 40, by = 5)) +\n  scale_x_continuous(breaks = seq(-4.775*2, 4.775*2, by = 4.775)) +\n  labs(x = \"Exercise (centered)\",\n       y = \"Endurance\",\n       linetype = \"Age (centered)\") +\n  theme_classic(18)\n\nprint(custom_formatted_ggplot_graph)\n\n\n\n\n\n\n\n\n\n7.4.4.1 Saving\nWe can save the 2D plot with the following command:\n\nggsave(\"graph_2D_interaction.png\", custom_formatted_ggplot_graph)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Moderated multiple regression</span>"
    ]
  },
  {
    "objectID": "mmr.html#powersample-size-analysis",
    "href": "mmr.html#powersample-size-analysis",
    "title": "7  Moderated multiple regression",
    "section": "7.5 Power/sample size analysis",
    "text": "7.5 Power/sample size analysis\nIf you examine a large number of studies involving moderated multiple regression you will see that the \\(sr^2\\) (i.e., \\(\\Delta R^2\\)) for the product term (e.g., age*exercise) typically ranges from .01 to .04 and only rarely falls out of this range - regardless of the variables involved. Consequently, to conduct a sample size analysis for a moderated mulitple regression you need to do three things:\n\nEstimate the size of the \\(sr^2\\) value (i.e., in the .01 to .04 range) for your study.\nEstimate the overall \\(R^2\\) value for your study.\nPlug both of those values into the sample size calculation provided in the multiple regression lecture.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Moderated multiple regression</span>"
    ]
  },
  {
    "objectID": "oneway-reg-anova.html",
    "href": "oneway-reg-anova.html",
    "title": "8  One-way ANOVA via Regression",
    "section": "",
    "text": "8.1 Using Contrasts",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>One-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "oneway-reg-anova.html#treatementdummy-coding",
    "href": "oneway-reg-anova.html#treatementdummy-coding",
    "title": "8  One-way ANOVA via Regression",
    "section": "8.2 Treatement/Dummy Coding",
    "text": "8.2 Treatement/Dummy Coding\nUse the Treatment contrast ONLY when you are interested in the contrast itself. DO NOT use if you are interested in typical ANOVA results (main effect, main effect, interaction, etc.).\nThis approach is the default approach in R unless you specify otherwise. In most cases, this is NOT what you want in Psychology analyses.\nComparisons are to one specific level of the Independent Variables that we call the reference group.\n\n8.2.1 Original Data\n\nprint(viagra)\n\n   libido      dose\n1       3   placebo\n2       2   placebo\n3       1   placebo\n4       1   placebo\n5       4   placebo\n6       5  low_dose\n7       2  low_dose\n8       4  low_dose\n9       2  low_dose\n10      3  low_dose\n11      7 high_dose\n12      4 high_dose\n13      5 high_dose\n14      3 high_dose\n15      6 high_dose\n\n\nNote the means for the three groups are:\n\nviagra %&gt;% group_by(dose) %&gt;% summarise(group_mean = mean(libido))\n\n# A tibble: 3 × 2\n  dose      group_mean\n  &lt;fct&gt;          &lt;dbl&gt;\n1 placebo          2.2\n2 low_dose         3.2\n3 high_dose        5  \n\n\n\n\n8.2.2 Set Factor with Reference Group\n\nviagra &lt;- viagra %&gt;%\n  mutate(dose = as_factor(dose)) %&gt;%\n  mutate(dose = relevel(dose, ref = \"placebo\"))\n\n\n\n8.2.3 Regression with Treatment Contrast\nThe computer will always use contrasts when there are categorical variables. So you should set the contrast you want. Here we set the contrast as Treatment (or Dummy) Coding. We use treatment contrasts when we are interested in directly interpreting the regression results.\n\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n\nlm_viagra &lt;- lm(libido ~ dose + 1, data = viagra)\n\n\ntidy(lm_viagra)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2.2\n0.6271629\n3.507860\n0.0043189\n\n\ndoselow_dose\n1.0\n0.8869423\n1.127469\n0.2815839\n\n\ndosehigh_dose\n2.8\n0.8869423\n3.156913\n0.0082681\n\n\n\n\n\nWhat is going on here? The single dose column has disappeared. Instead we get \\(b\\)-weights for doselow_dose and dosehigh_dose. How do you interpret that information?\n\n\n8.2.4 Treatment Contrasts Explained\nWhen we used the treatment contrast we converted the use the rules below:\n\ncontr.treatment(3)\n\n  2 3\n1 0 0\n2 1 0\n3 0 1\n\n\n\nThe first contrast row (0 0) indicates the mean of group 1 (placebo) is the intercept plus the 0 times first slope and 0 times the second slope.\n\n\\[\nplacebo-mean = 2.20 + 0(1.00) + 0(2.80) = 2.20\n\\]\n\nThe second contrast row (1 0) indicates the mean of group 2 (low dose) is the intercept plus the 1 times first slope and 0 times the second slope.\n\n\\[\nlow-dose-mean = 2.20 + 1(1.00) + 0(2.80) = 3.20\n\\]\n\nThe third contrast row (0 1) indicates the mean of group 3 (high dose) is the intercept plus the 0 times first slope and 1 times the second slope.\n\n\\[\nlow-dose-mean = 2.20 + 0(1.00) + 1(2.80) = 5.00\n\\]\nRecall the levels of the dose variable:\n\nlevels(viagra$dose)\n\n[1] \"placebo\"   \"low_dose\"  \"high_dose\"\n\n\nWe set the order of the levels previously with the fct_relevel() command.\nWhen we ran the regression we effectively use the predictors below\n\nprint(viagra_dummy_coded)\n\n# A tibble: 15 × 4\n   libido intercept dose_low_dose dose_high_dose\n    &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n 1      3         1             0              0\n 2      2         1             0              0\n 3      1         1             0              0\n 4      1         1             0              0\n 5      4         1             0              0\n 6      5         1             1              0\n 7      2         1             1              0\n 8      4         1             1              0\n 9      2         1             1              0\n10      3         1             1              0\n11      7         1             0              1\n12      4         1             0              1\n13      5         1             0              1\n14      3         1             0              1\n15      6         1             0              1\n\n\nExamine the weights in the above table and see how they can be used to recreate the group means.\n\n\n\n\n\n\n\n\n\n\n\n8.2.5 ANOVA Summary Information\nWith a one-way ANOVA, it’s easy to exact ANOVA information from the Regression output.\n\nglance(lm_viagra)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4603659\n0.3704268\n1.402379\n5.118644\n0.0246943\n2\n-24.68305\n57.3661\n60.1983\n23.6\n12\n15\n\n\n\n\n\nFrom this output you can see that for this one-way ANOVA, \\(F\\)(2, 12) = 5.119, \\(p\\) = .025. In a one-way ANOVA the effect size is \\(\\eta^2 = \\eta_{partial}^2=R^2= .46\\). Note that in a one-way ANOVA, \\(\\eta^2\\) = \\(\\eta_{partial}^2\\) but this is not the case when you move to N-way ANOVA.\n\nsummary(lm_viagra)\n\n\nCall:\nlm(formula = libido ~ dose + 1, data = viagra)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -2.0   -1.2   -0.2    0.9    2.0 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     2.2000     0.6272   3.508  0.00432 **\ndoselow_dose    1.0000     0.8869   1.127  0.28158   \ndosehigh_dose   2.8000     0.8869   3.157  0.00827 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.402 on 12 degrees of freedom\nMultiple R-squared:  0.4604,    Adjusted R-squared:  0.3704 \nF-statistic: 5.119 on 2 and 12 DF,  p-value: 0.02469\n\n\nFrom this output you can (AGAIN) see that for this one-way ANOVA, \\(F\\)(2, 12) = 5.119, \\(p\\) = .025. In a one-way ANOVA the effect size is \\(\\eta^2 = \\eta_{partial}^2=R^2= .46\\).\nNote: A good exam question would be to present a table like this an then ask you the mean for each group. With treatment/dummy coding the regression weight indicate for the reference group the mean of that group. For the other groups, the regression weights indicate the difference from the reference group.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>One-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "oneway-reg-anova.html#sum-contrast-effect-contrast",
    "href": "oneway-reg-anova.html#sum-contrast-effect-contrast",
    "title": "8  One-way ANOVA via Regression",
    "section": "8.3 Sum Contrast / Effect Contrast",
    "text": "8.3 Sum Contrast / Effect Contrast\nWe typically use Sum Coding or Effect Coding when we are not interested in the directly interpretting the regression results. Although the results can be directly interpretted this is not commonly done. Instead we use Sum Coding or Effect Coding when we use regression to run an ANOVA. Here we will directly interpret the results, however, to show that it can be done.\nWith sum coding, the contrasts create \\(b\\)-weight represent comparisons of each group mean to the to the grand mean. The contrasts we use for each group are presented below:\n\ncontr.sum(3)\n\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\n\nWe run the regression with the code below. Notice we take care to set the contrast to sum before the regression.\n\n# Check levels\nlevels(viagra$dose)\n\n[1] \"placebo\"   \"low_dose\"  \"high_dose\"\n\n# select sum coding\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\nlm_viagra_sum_coded &lt;- lm(libido ~ dose + 1, \n                          data = viagra)\n\nWe see the results are below. We use as.data.frame() just to see all the decimals.\n\ntidy(lm_viagra_sum_coded) %&gt;% as.data.frame()\n\n         term   estimate std.error  statistic      p.value\n1 (Intercept)  3.4666667 0.3620927  9.5739760 5.720565e-07\n2       dose1 -1.2666667 0.5120764 -2.4735893 2.930022e-02\n3       dose2 -0.2666667 0.5120764 -0.5207556 6.120112e-01\n\n\nIn the results above the intercept corresponds to the grand mean.\nRecall the sum contrast below:\n\ncontr.sum(3)\n\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\n\n\nThe first contrast row (1 0) indicates the mean of group 1 (placebo) is the intercept plus the 1 times first slope and 0 times the second slope.\n\n\\[\nplacebo-mean = 3.4666667 + 1(-1.2666667) + 0(-0.2666667) = 2.20\n\\]\n\nThe second contrast row (0 1) indicates the mean of group 2 (low dose) is the intercept plus the 0 times first slope and 1 times the second slope.\n\n\\[\nlow-dose-mean = 3.4666667 + 0(-1.2666667) + 1(-0.2666667)= 3.20\n\\]\n\nThe third contrast row (-1 -1) indicates the mean of group 3 (high dose) is the intercept plus -1 times first slope and -1 times the second slope.\n\n\\[\nlow-dose-mean = 3.4666667 + (-1)(-1.2666667) + (-1)(-0.2666667)= 5.00\n\\]\n\n8.3.1 Behind the scenes\nWhat is the grand mean? It’s just the mean of the dependent variable column across all conditions.\n\nsummary_stat = viagra %&gt;%\n  summarise(grand_mean = mean(libido))\n\nprint(summary_stat)\n\n  grand_mean\n1   3.466667\n\n\nIn the above analysis, when we used this code block:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\nlm_viagra_sum_coded &lt;- lm(libido ~ dose + 1, \n                          data = viagra)\n\nWe were doing a regression with the predictors below:\n\nprint(viagra_sum_coded)\n\n   libido intercept dose1 dose2\n1       3         1     1     0\n2       2         1     1     0\n3       1         1     1     0\n4       1         1     1     0\n5       4         1     1     0\n6       5         1     0     1\n7       2         1     0     1\n8       4         1     0     1\n9       2         1     0     1\n10      3         1     0     1\n11      7         1    -1    -1\n12      4         1    -1    -1\n13      5         1    -1    -1\n14      3         1    -1    -1\n15      6         1    -1    -1\n\n\nThat is, when we specified this:\n\nlm_viagra &lt;- lm(libido ~ dose + 1, data = viagra)\n\nThe computer actually ran this:\n\nlm_viagra_sum &lt;- lm(libido ~ dose1 + dose2 + 1,\n                data = viagra_sum_coded)\n\n\ntidy(lm_viagra_sum)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3.4666667\n0.3620927\n9.5739760\n0.0000006\n\n\ndose1\n-1.2666667\n0.5120764\n-2.4735893\n0.0293002\n\n\ndose2\n-0.2666667\n0.5120764\n-0.5207556\n0.6120112\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.2 ANOVA values\n\nglance(lm_viagra_sum)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4603659\n0.3704268\n1.402379\n5.118644\n0.0246943\n2\n-24.68305\n57.3661\n60.1983\n23.6\n12\n15\n\n\n\n\n\nFrom this output you can see that for this one-way ANOVA, F(2,12) = 5.118644, p = 0.0246943.\n\nsummary(lm_viagra_sum)\n\n\nCall:\nlm(formula = libido ~ dose1 + dose2 + 1, data = viagra_sum_coded)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -2.0   -1.2   -0.2    0.9    2.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.4667     0.3621   9.574 5.72e-07 ***\ndose1        -1.2667     0.5121  -2.474   0.0293 *  \ndose2        -0.2667     0.5121  -0.521   0.6120    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.402 on 12 degrees of freedom\nMultiple R-squared:  0.4604,    Adjusted R-squared:  0.3704 \nF-statistic: 5.119 on 2 and 12 DF,  p-value: 0.02469\n\n\nFrom this output you can (again) see that for this one-way ANOVA, F(2,12) = 5.118644, p = 0.0246943.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>One-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "oneway-reg-anova.html#helmert-contrast",
    "href": "oneway-reg-anova.html#helmert-contrast",
    "title": "8  One-way ANOVA via Regression",
    "section": "8.4 Helmert Contrast",
    "text": "8.4 Helmert Contrast\nUse the Helmert Contrast if you are interested in typical ANOVA results (main effect, main effect, interaction, etc.).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>One-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "oneway-reg-anova.html#summary-contrast-types",
    "href": "oneway-reg-anova.html#summary-contrast-types",
    "title": "8  One-way ANOVA via Regression",
    "section": "8.5 Summary: Contrast Types",
    "text": "8.5 Summary: Contrast Types\n\n\n\n\n\n\n\n\n\nName/Synonym\nR command Example\nNature of Comparison\nNote\n\n\n\n\nTreatment Contrast / Dummy Contrast\n\nIntercept is the reference group mean. Unstandardized weights indicate difference between a group’s mean and reference group mean. In this example, group 1 is the reference group. Notice the first contrast column is for the second group - because group 1 is the intercept.\nDefault in R. Do NOT use for ANOVA.\n\n\nSum Contrast / Effect Contrast\n\nIntercept is the grand mean. Unstandardized weights are used to create a predicted score that corresponds to the mean for each group.\nUSE for ANOVA. This works because the intercept is the grand mean.\n\n\nHelmert Contrast\n\nIntercept is the grand mean. First contrast, unstandardized weight indicate difference between Group 2 and Group 1 means. Second contrast, unstandardized weight indicate difference between Group 3 mean and the average of the Group 1 and Group 2 means. Third contrast, unstandardized weight indicate difference between Group 4 mean and the average of the Group 1, Group 2, and Group 3 means. And so on.\nUSE for ANOVA. This works because the intercept is the grand mean.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>One-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html",
    "href": "twoway-reg-anova.html",
    "title": "9  Two-way ANOVA via Regression",
    "section": "",
    "text": "9.1 Conducting a 2-way ANOVA\nOn this page we illustrate what is happening “under the hood” when you run an ANOVA using regression.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#conducting-a-2-way-anova",
    "href": "twoway-reg-anova.html#conducting-a-2-way-anova",
    "title": "9  Two-way ANOVA via Regression",
    "section": "",
    "text": "9.1.1 Activate Packages\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(pracma)\nlibrary(recipes)\nlibrary(forcats)\nlibrary(tidymodels)\nlibrary(apaTables)\n\n\n\n9.1.2 Load Data\n\ngdata = read_csv(\"gdata.csv\")\n\n\n\n9.1.3 Inspect Data\nThis example is from the Andy Field book. The example uses alcohol(0, 2 pints, 4 pints) and sex(male,female) as predictors of attractiveness. See the Discovering Statistics Using R (2012) for the complete example. We use this example to illustrate sum contrasts in an ANOVA context.\n\nglimpse(gdata)\n\nRows: 41\nColumns: 3\n$ attractiveness &lt;dbl&gt; 60, 60, 55, 60, 55, 70, 65, 60, 70, 65, 60, 60, 50, 55,…\n$ gender         &lt;chr&gt; \"female\", \"female\", \"female\", \"female\", \"female\", \"fema…\n$ alcohol        &lt;chr&gt; \"none\", \"none\", \"none\", \"none\", \"none\", \"pint2\", \"pint2…\n\n\n\nprint(gdata)\n\n\n\n   attractiveness gender alcohol\n1              60 female    none\n2              60 female    none\n3              55 female    none\n4              60 female    none\n5              55 female    none\n6              70 female   pint2\n7              65 female   pint2\n8              60 female   pint2\n9              70 female   pint2\n10             65 female   pint2\n11             60 female   pint2\n12             60 female   pint2\n13             50 female   pint2\n14             55 female   pint4\n15             65 female   pint4\n16             70 female   pint4\n17             55 female   pint4\n18             55 female   pint4\n19             60 female   pint4\n20             50 female   pint4\n21             50 female   pint4\n22             50   male    none\n23             55   male    none\n24             80   male    none\n25             65   male    none\n26             70   male    none\n27             75   male    none\n28             75   male    none\n29             65   male    none\n30             45   male   pint2\n31             60   male   pint2\n32             85   male   pint2\n33             65   male   pint2\n34             70   male   pint2\n35             70   male   pint2\n36             80   male   pint2\n37             60   male   pint2\n38             30   male   pint4\n39             30   male   pint4\n40             30   male   pint4\n41             55   male   pint4\n\n\n\n\n9.1.4 Make Factors\n\ngdata &lt;- gdata %&gt;%\n  mutate(gender = as_factor(gender)) %&gt;%\n  mutate(alcohol = as_factor(alcohol))\n\nglimpse(gdata)\n\nRows: 41\nColumns: 3\n$ attractiveness &lt;dbl&gt; 60, 60, 55, 60, 55, 70, 65, 60, 70, 65, 60, 60, 50, 55,…\n$ gender         &lt;fct&gt; female, female, female, female, female, female, female,…\n$ alcohol        &lt;fct&gt; none, none, none, none, none, pint2, pint2, pint2, pint…\n\n\n\n\n9.1.5 Linear Model\nBecause we want to run an ANOVA we use a sum contrast.\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\n\nlm_output &lt;- lm(attractiveness ~  gender*alcohol, \n                data = gdata)\n\nBut note that when we run the command above with gender*alcohol we need to realize is is a shortcut convention for the code below - which implicitly includes an intercept:\n\nlm_output &lt;- lm(attractiveness ~ gender+ alcohol + gender:alcohol, \n                data = gdata)\n\nWhich is in turn a shortcut for the code below which explicitly includes the intercept:\n\nlm_output &lt;- lm(attractiveness ~ gender+ alcohol + gender:alcohol + 1, \n                data = gdata)\n\n\ntable1 &lt;- apa.aov.table(lm_output, table.number = 1)\napa.save(\"table1aov.doc\", table1)\n\n\n\n\n\n\n\n\n\n\nThe table above is helpful for interpretting the data, but, how did we obtain it? There is a lot that happens to get the above table. Especially when you remember that if we look at the results of the regression itself it looks quite different:\n\ntidy(lm_output)\n\n# A tibble: 6 × 5\n  term             estimate std.error statistic  p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)         58         1.50    38.6   2.76e-30\n2 gender1              1.33      1.50     0.888 3.81e- 1\n3 alcohol1             4.44      2.14     2.08  4.54e- 2\n4 alcohol2             6.69      2.01     3.33  2.07e- 3\n5 gender1:alcohol1    -5.77      2.14    -2.70  1.06e- 2\n6 gender1:alcohol2    -3.52      2.01    -1.75  8.85e- 2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#regression-becoming-anova",
    "href": "twoway-reg-anova.html#regression-becoming-anova",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.2 Regression Becoming ANOVA",
    "text": "9.2 Regression Becoming ANOVA\nA bit of magic seems to happen in the above. We conduct a regression and then somehow get an ANOVA table out at the end. How does that work? The key is understanding that when we specify the regression with factors in it - we a really giving the computer a set of instruction and a starting point - rather than an actual analysis. The computer does a few things “under the hood”:\n\nFactors are turned into contrasts columns\nMultiple columns be be required for a single factor\nThe number of contrast columns required for a single factor column is equal to the number levels minus one.\nThe “actual analysis” is conducted using the contrast columns - not the factor column from your data set.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#contrasts-for-categorical-variables",
    "href": "twoway-reg-anova.html#contrasts-for-categorical-variables",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.3 Contrasts for Categorical Variables",
    "text": "9.3 Contrasts for Categorical Variables\nLet’s load a new data set that has some contrast columns created already.\n\ngdata &lt;- read_csv(\"gdata_contrasts.csv\")\n\n\n9.3.1 Gender Contrasts\nIn R when you use the line:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\nIt effectively runs the contr.sum() command on each factor column, when a regression is run, and creates contrasts based on the number of levels of each factor. For example, the sex factor, with levels, causes the command below to be run.\n\ncontr.sum(2)\n\n  [,1]\n1    1\n2   -1\n\n\nThese rules are applied to the gender column. We create a new column called sex where this rule has been applied. In the output below, I have already applied this rule and put the result in the sex column. Normally this happens “under the hood” and you don’t see it. Notice how every female is coded 1 in the sex column where as males are coded -1 in the sex column; consistent with the contr.sum(2) command.\n\ngdata %&gt;%\n  select(attractiveness, gender, sex) %&gt;%\n  as.data.frame()\n\n   attractiveness gender sex\n1              60 female   1\n2              60 female   1\n3              55 female   1\n4              60 female   1\n5              55 female   1\n6              70 female   1\n7              65 female   1\n8              60 female   1\n9              70 female   1\n10             65 female   1\n11             60 female   1\n12             60 female   1\n13             50 female   1\n14             55 female   1\n15             65 female   1\n16             70 female   1\n17             55 female   1\n18             55 female   1\n19             60 female   1\n20             50 female   1\n21             50 female   1\n22             50   male  -1\n23             55   male  -1\n24             80   male  -1\n25             65   male  -1\n26             70   male  -1\n27             75   male  -1\n28             75   male  -1\n29             65   male  -1\n30             45   male  -1\n31             60   male  -1\n32             85   male  -1\n33             65   male  -1\n34             70   male  -1\n35             70   male  -1\n36             80   male  -1\n37             60   male  -1\n38             30   male  -1\n39             30   male  -1\n40             30   male  -1\n41             55   male  -1\n\n\n\n\n9.3.2 Alcohol Contrasts\n\ncontr.sum(3)\n\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\n\nIn the output below, I have already applied this rule and put the result in the alc1 and alc2 columns. Normally this happens “under the hood” and you don’t see it. Notice how every levels of alcohol are coded using this scheme; consistent with the contr.sum(3) command.\n\ngdata %&gt;%\n  select(attractiveness, alcohol, alc1, alc2) %&gt;%\n  as.data.frame()\n\n   attractiveness alcohol alc1 alc2\n1              60    none    1    0\n2              60    none    1    0\n3              55    none    1    0\n4              60    none    1    0\n5              55    none    1    0\n6              70   pint2    0    1\n7              65   pint2    0    1\n8              60   pint2    0    1\n9              70   pint2    0    1\n10             65   pint2    0    1\n11             60   pint2    0    1\n12             60   pint2    0    1\n13             50   pint2    0    1\n14             55   pint4   -1   -1\n15             65   pint4   -1   -1\n16             70   pint4   -1   -1\n17             55   pint4   -1   -1\n18             55   pint4   -1   -1\n19             60   pint4   -1   -1\n20             50   pint4   -1   -1\n21             50   pint4   -1   -1\n22             50    none    1    0\n23             55    none    1    0\n24             80    none    1    0\n25             65    none    1    0\n26             70    none    1    0\n27             75    none    1    0\n28             75    none    1    0\n29             65    none    1    0\n30             45   pint2    0    1\n31             60   pint2    0    1\n32             85   pint2    0    1\n33             65   pint2    0    1\n34             70   pint2    0    1\n35             70   pint2    0    1\n36             80   pint2    0    1\n37             60   pint2    0    1\n38             30   pint4   -1   -1\n39             30   pint4   -1   -1\n40             30   pint4   -1   -1\n41             55   pint4   -1   -1\n\n\n\n\n9.3.3 Interaction Contrasts\nWe also need contrasts for the interaction. We create the interaction contrasts by multiplying the columns for sex, alc1, and alc2. You can see how we do so in the code below.\n\ngdata &lt;- gdata %&gt;%\n  mutate(int1 = sex*alc1,\n         int2 = sex*alc2)\n\nYou can see these new interaction columns below:\n\nprint(gdata)\n\n   attractiveness sex alc1 alc2 int1 int2\n1              60   1    1    0    1    0\n2              60   1    1    0    1    0\n3              55   1    1    0    1    0\n4              60   1    1    0    1    0\n5              55   1    1    0    1    0\n6              70   1    0    1    0    1\n7              65   1    0    1    0    1\n8              60   1    0    1    0    1\n9              70   1    0    1    0    1\n10             65   1    0    1    0    1\n11             60   1    0    1    0    1\n12             60   1    0    1    0    1\n13             50   1    0    1    0    1\n14             55   1   -1   -1   -1   -1\n15             65   1   -1   -1   -1   -1\n16             70   1   -1   -1   -1   -1\n17             55   1   -1   -1   -1   -1\n18             55   1   -1   -1   -1   -1\n19             60   1   -1   -1   -1   -1\n20             50   1   -1   -1   -1   -1\n21             50   1   -1   -1   -1   -1\n22             50  -1    1    0   -1    0\n23             55  -1    1    0   -1    0\n24             80  -1    1    0   -1    0\n25             65  -1    1    0   -1    0\n26             70  -1    1    0   -1    0\n27             75  -1    1    0   -1    0\n28             75  -1    1    0   -1    0\n29             65  -1    1    0   -1    0\n30             45  -1    0    1    0   -1\n31             60  -1    0    1    0   -1\n32             85  -1    0    1    0   -1\n33             65  -1    0    1    0   -1\n34             70  -1    0    1    0   -1\n35             70  -1    0    1    0   -1\n36             80  -1    0    1    0   -1\n37             60  -1    0    1    0   -1\n38             30  -1   -1   -1    1    1\n39             30  -1   -1   -1    1    1\n40             30  -1   -1   -1    1    1\n41             55  -1   -1   -1    1    1",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#regression-command-i.e.-lm-overview",
    "href": "twoway-reg-anova.html#regression-command-i.e.-lm-overview",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.4 Regression command (i.e., lm) overview",
    "text": "9.4 Regression command (i.e., lm) overview\nTo get ANOVA results that are consistent with what are typically used in psychology you need to 1) Specify the contr.sum() contrast 2) Calculate the Sum of Squares using the logic for Type III Sum of Squares\nWhen you run an ANOVA using the command:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\nlm_output &lt;- lm(attractiveness ~ gender + alcohol + gender:alcohol,\n                data = gdata)\n\nYou actually run the regression below:\n\nlm_output &lt;- lm(attractiveness ~ gender1 + alcohol1 + alcohol2 + gender:alcohol1 + gender:alcohol2,\n                data = gdata)\n\nWhich uses these columns - notice there is a column of all ones for the intercept:\n\nprint(gdata)\n\n   attractiveness intercept sex alc1 alc2 int1 int2\n1              60         1   1    1    0    1    0\n2              60         1   1    1    0    1    0\n3              55         1   1    1    0    1    0\n4              60         1   1    1    0    1    0\n5              55         1   1    1    0    1    0\n6              70         1   1    0    1    0    1\n7              65         1   1    0    1    0    1\n8              60         1   1    0    1    0    1\n9              70         1   1    0    1    0    1\n10             65         1   1    0    1    0    1\n11             60         1   1    0    1    0    1\n12             60         1   1    0    1    0    1\n13             50         1   1    0    1    0    1\n14             55         1   1   -1   -1   -1   -1\n15             65         1   1   -1   -1   -1   -1\n16             70         1   1   -1   -1   -1   -1\n17             55         1   1   -1   -1   -1   -1\n18             55         1   1   -1   -1   -1   -1\n19             60         1   1   -1   -1   -1   -1\n20             50         1   1   -1   -1   -1   -1\n21             50         1   1   -1   -1   -1   -1\n22             50         1  -1    1    0   -1    0\n23             55         1  -1    1    0   -1    0\n24             80         1  -1    1    0   -1    0\n25             65         1  -1    1    0   -1    0\n26             70         1  -1    1    0   -1    0\n27             75         1  -1    1    0   -1    0\n28             75         1  -1    1    0   -1    0\n29             65         1  -1    1    0   -1    0\n30             45         1  -1    0    1    0   -1\n31             60         1  -1    0    1    0   -1\n32             85         1  -1    0    1    0   -1\n33             65         1  -1    0    1    0   -1\n34             70         1  -1    0    1    0   -1\n35             70         1  -1    0    1    0   -1\n36             80         1  -1    0    1    0   -1\n37             60         1  -1    0    1    0   -1\n38             30         1  -1   -1   -1    1    1\n39             30         1  -1   -1   -1    1    1\n40             30         1  -1   -1   -1    1    1\n41             55         1  -1   -1   -1    1    1",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#full-and-restricted-models",
    "href": "twoway-reg-anova.html#full-and-restricted-models",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.5 Full and Restricted Models",
    "text": "9.5 Full and Restricted Models\nR actually runs a whole series of regressions for you and combines them into the single output table you saw above. These models fall into two categories Full and Restricted Models.\n\n9.5.1 Full Model\nFirst, the Full Model is run that includes all of the predictor columns:\n\nlm_full &lt;- lm(attractiveness ~ sex + alc1 + alc2 + int1 + int2,\n              data = gdata)\n\n\n\n9.5.2 Restricted Models\nNext a series of restricted models are run that excluded an effect of interest for each restricted model.\n\nlm_restricted_no_sex &lt;- lm(attractiveness ~ alc1 + alc2 + int1 + int2,\n                           data = gdata)\n\nlm_restricted_no_alcohol &lt;- lm(attractiveness ~ sex + int1 + int2,\n                               data = gdata)\n\nlm_restricted_no_interaction &lt;- lm(attractiveness ~ sex + alc1 + alc2,\n                                   data = gdata)\n\nlm_restricted_no_intercept &lt;- lm(attractiveness ~ sex + alc1 + alc2 + int1 + int2 - 1,\n                                 data = gdata)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#logic-model-comparison",
    "href": "twoway-reg-anova.html#logic-model-comparison",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.6 Logic: Model Comparison",
    "text": "9.6 Logic: Model Comparison\nThe ANOVA table is created by comparing each of these restricted models to the full model. For example, to determine the main effect for gender we compare the model lm_restricted_no_sex to the model lm_full. If lm_full accounts for substantially more variance than lm_restricted_no_sex it is significant.\nThis is effectively identical to when we looked at comparing two regression models previous. Using that logic, we could just write the code:\n\n# try this, it works!\nlibrary(apaTables)\napa.reg.table(lm_restricted_no_sex, lm_restricted_all)\n\nThe result would tell us if the main effect of sex is significant. The logic of calculating things this way is the Type III Sum of Squares logic. HOWEVER, we don’t tend to use the output in the form provided in this type of table. Rather the output if reformatted to by consistent with the way ANOVA’s are typically presented. The next few sections show you how the table below is created:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#explanation-1-comparing-models",
    "href": "twoway-reg-anova.html#explanation-1-comparing-models",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.7 Explanation 1: Comparing Models",
    "text": "9.7 Explanation 1: Comparing Models\n\n9.7.1 Sex\n\nlm_restricted_no_sex &lt;- lm(attractiveness ~ alc1 + alc2 + int1 + int2,\n                           data = gdata)\n\nlm_full &lt;- lm(attractiveness ~ sex + alc1 + alc2 + int1 + int2,\n              data = gdata)\n\nanova(lm_restricted_no_sex, lm_full)\n\nAnalysis of Variance Table\n\nModel 1: attractiveness ~ alc1 + alc2 + int1 + int2\nModel 2: attractiveness ~ sex + alc1 + alc2 + int1 + int2\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1     36 3059.9                           \n2     35 2992.5  1    67.368 0.7879 0.3808\n\n\nCompare the \\(F-\\) and \\(p\\)-values in the above output to those in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.7.2 Alcohol\n\nlm_restricted_no_alcohol &lt;- lm(attractiveness ~ sex + int1 + int2,\n                               data = gdata)\n\nlm_full &lt;- lm(attractiveness ~ sex + alc1 + alc2 + int1 + int2,\n              data = gdata)\n\nanova(lm_restricted_no_alcohol, lm_full)\n\nAnalysis of Variance Table\n\nModel 1: attractiveness ~ sex + int1 + int2\nModel 2: attractiveness ~ sex + alc1 + alc2 + int1 + int2\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     37 5223.3                                  \n2     35 2992.5  2    2230.8 13.045 5.843e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCompare the \\(F-\\) and \\(p\\)-values in the above output to those in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.7.3 Interaction\n\nlm_restricted_no_interaction &lt;- lm(attractiveness ~ sex + alc1 + alc2,\n                                   data = gdata)\n\nlm_full &lt;- lm(attractiveness ~ sex + alc1 + alc2 + int1 + int2,\n              data = gdata)\n\nanova(lm_restricted_no_interaction, lm_full)\n\nAnalysis of Variance Table\n\nModel 1: attractiveness ~ sex + alc1 + alc2\nModel 2: attractiveness ~ sex + alc1 + alc2 + int1 + int2\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     37 4501.2                                  \n2     35 2992.5  2    1508.7 8.8225 0.0007896 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCompare the \\(F-\\) and \\(p\\)-values in the above output to those in the table below.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#degrees-of-freedom",
    "href": "twoway-reg-anova.html#degrees-of-freedom",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.8 Degrees of Freedom",
    "text": "9.8 Degrees of Freedom\nWhen you look at the the columns in the above output notice the number of columns we use for each predictor corresponds the degrees of freedom for that predictor.\n\n\n\n\n\n\n\n\n\nPredictor\ndf\nNumber of contrast columns\nContrast column names\n\n\n\n\nsex\n\\(df_a = a-1 = 2 -1 = 1\\)\n1\nsex\n\n\nalcohol\n\\(df_b = b-1 = 3 -1 = 2\\)\n2\nalc1, alch2\n\n\nsex by alcohol\n\\(df_{int} = df_a * df_b = (a-1)(b-1)=1(2)=2\\)\n2\nint1, int2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "twoway-reg-anova.html#explanation-2-sum-of-squares-to-anova",
    "href": "twoway-reg-anova.html#explanation-2-sum-of-squares-to-anova",
    "title": "9  Two-way ANOVA via Regression",
    "section": "9.9 Explanation 2: Sum of Squares to ANOVA",
    "text": "9.9 Explanation 2: Sum of Squares to ANOVA\nNotice the first column of the ANOVA table above is the Sum of Squares column. How are those values calculated? Let’s consider the example of alcohol as a predictor. We want to determine the Sum of Squares for alcohol.\nWe begin by calculating predicted scores for the Full Model (lm_full):\n\\[\n\\hat{y}_{\\text{full}} = b_0 +b_1sex + b_2alc1 + b_3alc2 + b_4int1 + b_5int2\n\\]\nNext, we calculate the predicted scores for the alcohol restricted model (lm_restricted_no_alcohol) \\[\n\\hat{y}_{\\text{restricted no alcohol}}= b_0 +b_1sex + b_2int1 + b_3int2\n\\]\nThen we calculated the difference between these two sets of predicted scores:\n\\[\n\\hat{y}_{\\text{difference}} = \\hat{y}_{\\text{full}} - \\hat{y}_{\\text{restricted no alcohol}}\n\\]\nThen we square these values and add them up.\n\\[\nSS_{alcohol} =  \\sum \\hat{y}_{\\text{difference}}^2\n\\]\nWe follow this process below for each predictor (including the intercept).\n\n9.9.1 Intercept\n\n## Sum of squares intercept\nsum( ( predict(lm_full) - predict(lm_restricted_no_intercept) )^2 )\n\n[1] 127477.9\n\n\nCompare the Sum of Squares values in the above output to the one in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.9.2 Sex\n\n## Sum of squares sex\nsum( ( predict(lm_full) - predict(lm_restricted_no_sex) )^2 )\n\n[1] 67.36842\n\n\nCompare the Sum of Squares values in the above output to the one in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.9.3 Alcohol\n\n## Sum of squares alcohol\nsum( ( predict(lm_full) - predict(lm_restricted_no_alcohol) )^2 )\n\n[1] 2230.757\n\n\nCompare the Sum of Squares values in the above output to the one in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.9.4 Interaction\n\n## Sum of squares interaction\nsum( ( predict(lm_full) - predict(lm_restricted_no_interaction) )^2 )\n\n[1] 1508.651\n\n\nCompare the Sum of Squares values in the above output to the one in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.9.5 Error\n\n## Sum of squares error\nsum( lm_full$residuals^2 )\n\n[1] 2992.5\n\n\nCompare the Sum of Squares values in the above output to the one in the table below.\n\n\n\n\n\n\n\n\n\n\n\n9.9.6 SS to ANOVA\nBased on the above analyses we know the Sum of Squares and the degrees of freedom for everything. We can put that information in the table below.\n\n\n\n\n\n\n\n\n\n\n\nPredictor\n\\(SS\\)\n\\(df\\)\nMS\\(=\\frac{SS}{df}\\)\nF\\(=\\frac{MS}{MS_{error}}\\)\np\n\n\n\n\n(Intercept)\n127477.89\n1\n\n\n\n\n\nsex\n67.37\n1\n\n\n\n\n\nalcohol\n2230.76\n2\n\n\n\n\n\nsex by alcohol\n1508.65\n2\n\n\n\n\n\nError\n2992.5\n35\n\n\n\n\n\n\nA few hand calculations, and an \\(F\\) to \\(p\\)-value look-up table, provides us with the rest of the information we need:\n\n\n\n\n\n\n\n\n\n\n\nPredictor\n\\(SS\\)\n\\(df\\)\nMS\\(=\\frac{SS}{df}\\)\nF\\(=\\frac{MS}{MS_{error}}\\)\np\n\n\n\n\n(Intercept)\n127477.89\n1\n\\(\\frac{127477.89}{1}=127477.89\\)\n\\(\\frac{127477.89}{85.5}= 1490.97\\)\n&lt;.001\n\n\nsex\n67.37\n1\n\\(\\frac{67.37}{1}=67.37\\)\n\\(\\frac{67.37}{85.5}= 0.79\\)\n.381\n\n\nalcohol\n2230.76\n2\n\\(\\frac{2230.76}{2}=1115.38\\)\n\\(\\frac{1115.38}{85.5}=13.05\\)\n&lt;.001\n\n\nsex by alcohol\n1508.65\n2\n\\(\\frac{1508.65}{2}= 754.325\\)\n\\(\\frac{754.325}{85.5}=8.82\\)\n.001\n\n\nError\n2992.5\n35\n\\(\\frac{2992.5}{35}= 85.5\\)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Two-way ANOVA via Regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baker, M. 2016. “1500 Scientists Lift the Lid on\nReproducibility.” Nature 533. https://doi.org/10.1038/533452a.\n\n\nMeyer, John P, Natalie J Allen, and Catherine A Smith. 1993.\n“Commitment to Organizations and Occupations: Extension and Test\nof a Three-Component Conceptualization.” Journal of Applied\nPsychology 78 (4): 538.\n\n\nMiyakawa, T. 2020. “No Raw Data, No Science: Another Possible\nSource of the Reproducibility Crisis.” Mol Brain 13\n(24). https://doi.org/10.1186/s13041-020-0552-2.\n\n\nNosek. 2015. “Estimating the Reproducibility of Psychological\nScience.” Science 349. http://doi.org/10.1126/science.aac4716.\n\n\nPatil P., & Leek J. T, Peng R. D. 2019. “A Visual Tool for\nDefining Reproducibility and Replicability.” Nat Hum\nBehav 3: 650–52. https://doi.org/10.1038/s41562-019-0629-z.\n\n\nSimmons, Joseph P, Leif D Nelson, and Uri Simonsohn. 2011.\n“False-Positive Psychology: Undisclosed Flexibility in Data\nCollection and Analysis Allows Presenting Anything as\nSignificant.” Psychological Science 22 (11): 1359–66.\n\n\nThompson, Edmund R, and Florence TT Phua. 2012. “A Brief Index of\nAffective Job Satisfaction.” Group & Organization\nManagement 37 (3): 275–307.\n\n\nWickham, Hadley. 2014. “Tidy Data.” The Journal of\nStatistical Software 59. http://www.jstatsoft.org/v59/i10/.",
    "crumbs": [
      "References"
    ]
  }
]